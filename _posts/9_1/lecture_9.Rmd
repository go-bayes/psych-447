---
title: "Ordinal responses, monotonic predictors, mediation, and group-level intercepts"
description: 
author:
  - name: Joseph Bulbulia
    url: https://josephbulbulia.netlify.app
    affiliation: Victoria University of Wellington
    affiliation_url: https://www.wgtn.ac.nz
    orcid_id: 0000-0002-5861-2056
date: 2021-MAY-04 
output:
  distill::distill_article:
    self_contained: false
    toc: true
    code_folding: true
    highlight: kate
bibliography: bib.bib
---

```{r echo=F}
knitr::include_graphics("op2.png")
```


```{r setup, include=FALSE}
# setup
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  layout = "l-body-outset",
  fig.width = 12,
  fig.height = 10,
  collapse = TRUE,
  R.options = list(width = 60
  )
)
```

```{r  libraries, echo=FALSE}
### Libraries
library("tidyverse")
library("ggplot2")
library("patchwork")
library("lubridate")
library("kableExtra")
library("gtsummary")
library("lubridate")
library("equatiomatic")
library("ggdag")
library("brms")
library("rstan")
library("rstanarm")
library("bayesplot")
library("easystats")
library("kableExtra")
library("broom")
library("tidybayes")
library("bmlm")
if (!require(tidyLPA)) {
  install.packages("tidyLPA")
}
# rstan options
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores ())
theme_set(theme_classic())
```

```{r  nzdata, include=FALSE}
# read data


nz_0 <- as.data.frame(readr::read_csv2(
  url(
    "https://raw.githubusercontent.com/go-bayes/psych-447/main/data/nzj.csv"
  )
))

# to relevel kessler 6 variables
f <-
  c(
    "None Of The Time",
    "A Little Of The Time",
    "Some Of The Time",
    "Most Of The Time",
    "All Of The Time"
  )

# Relevel covid timeline longitudional
# ord_dates_class <- c(
#   "Baseline",
#   "PreCOVID",
#   "JanFeb",
#   "EarlyMarch",
#   "Lockdown",
#   "PostLockdown")

# Relevel covid timeline 2019
ord_dates_class_2019_only <- c("PreCOVID",
                               "JanFeb",
                               "EarlyMarch",
                               "Lockdown",
                               "PostLockdown")
# get data into shape
nz_cr <- nz_0 %>%
  dplyr::mutate_if(is.character, factor) %>%
  select(
    -c(
      SWB.Kessler01,
      SWB.Kessler02,
      SWB.Kessler03,
      SWB.Kessler04,
      SWB.Kessler05,
      SWB.Kessler06
    )
  ) %>%
  dplyr::mutate(Wave = as.factor(Wave)) %>%
  dplyr::mutate(FeelHopeless = forcats::fct_relevel(FeelHopeless, f)) %>%
  dplyr::mutate(FeelDepressed = forcats::fct_relevel(FeelDepressed, f)) %>%
  dplyr::mutate(FeelRestless = forcats::fct_relevel(FeelRestless, f)) %>%
  dplyr::mutate(EverythingIsEffort = forcats::fct_relevel(EverythingIsEffort, f)) %>%
  dplyr::mutate(FeelWorthless = forcats::fct_relevel(FeelWorthless, f)) %>%
  dplyr::mutate(FeelNervous = forcats::fct_relevel(FeelNervous, f)) %>%
  dplyr::mutate(Wave = as.factor(Wave)) %>%
  dplyr::mutate(male_id = as.factor(Male)) %>%
  dplyr::mutate(date = make_date(year = 2009, month = 6, day = 30) + TSCORE) %>%
  dplyr::mutate(
    FeelWorthless_int = as.integer(FeelWorthless),
    FeelNervous_int =  as.integer(FeelNervous),
    FeelHopeless_int =  as.integer(FeelHopeless),
    EverythingIsEffort_int =  as.integer(EverythingIsEffort),
    FeelRestless_int =  as.integer(FeelRestless),
    FeelDepressed_int =  as.integer(FeelDepressed),
    HLTH.Fatigue_int = as.integer(HLTH.Fatigue + 1)
  ) %>%
  dplyr::mutate(yearS = TSCORE - min(TSCORE, na.rm = TRUE)) %>%
  dplyr::mutate(KESSLER6sum = as.integer(KESSLER6sum))



nz <- nz_cr %>%
  dplyr::filter(YearMeasured == 1) %>%
  dplyr::filter(Wave == 2019) %>%
  dplyr::group_by(Id) %>%
  dplyr::ungroup(Id) %>%
  dplyr::mutate(Covid_Timeline_cr =
                  as.factor(ifelse(
                    TSCORE %in% 3896:3921,
                    # feb 29 - march 25th
                    "EarlyMarch",
                    ifelse(
                      TSCORE %in% 3922:3954,
                      "Lockdown",
                      #march 26- Mon 27 April 2020
                      ifelse(
                        TSCORE > 3954,
                        # after april 27th 20202
                        "PostLockdown",
                        ifelse(TSCORE %in% 3842:3895,
                               # jan 6 to feb 28
                               "JanFeb",
                               "PreCOVID")
                      )
                    )
                  ))) %>%
  dplyr::mutate(Covid_Timeline_cr = forcats::fct_relevel(Covid_Timeline_cr, ord_dates_class_2019_only))

dplyr::glimpse(nz)


## Long data #####################
ord_dates_class <- c("Baseline",
                     "PreCOVID",
                     "JanFeb",
                     "EarlyMarch",
                     "Lockdown",
                     "PostLockdown")

nzl <- nz_cr %>%
  dplyr::filter(YearMeasured == 1) %>%
  dplyr::filter(Wave == 2018 | Wave == 2019) %>%
  dplyr::group_by(Id) %>%
  dplyr::filter(n() > 1) %>%
  dplyr::filter(n() != 0) %>%
  dplyr::ungroup(Id) %>%
  dplyr::mutate(yearS = TSCORE - min(TSCORE, na.rm = TRUE)) %>%
  dplyr::mutate(WSCORE = as.factor(WSCORE)) %>%
  dplyr::mutate(Covid_Timeline =
                  as.factor(ifelse(
                    TSCORE %in% 3896:3921,
                    # feb 29 - march 25th
                    "EarlyMarch",
                    ifelse(
                      TSCORE %in% 3922:3954,
                      "Lockdown",
                      #march 26- Mon 27 April 2020
                      ifelse(
                        TSCORE > 3954,
                        # after april 27th 20202
                        "PostLockdown",
                        ifelse(
                          TSCORE %in% 3842:3895,
                          # jan 6 to feb 28
                          "JanFeb",
                          ifelse(TSCORE %in% 3665:3841 &
                                   Wave == 2019,
                                 "PreCOVID",
                                 "Baseline"  # 3672 TSCORE or  20 July 2019))))))))
                          )
                        )
                      )
                    ))) %>%
                  dplyr::mutate(Covid_Timeline = forcats::fct_relevel(Covid_Timeline, ord_dates_class))
                
                

```


## Ordinal outcomes



### Example 

An ordinal model assumes that an observed ordinal indicator measures a latent continuous outcome \cite{Burkner2019-ie,Hadfield2012-hi}. 


<!-- In our NZ-jitter dataset, the Kessler-6 has five ordinal response options for indicating frequency of feeling distress during the past 30 days: "None Of The Time", "A Little Of The Time", "Some Of The Time", "Most Of The Time", "All Of The Time" hence six thresholds.  -->

<!-- The Kessler-6 distress indicators are: "Feeling Hopelessness;" "Feeling so Depressed Nothing Could Cheer You Up;" "Feeling Nervous or Fidgety;" "Feeling Everything is an Effort;" "Feeling Worthless;" "Feeling Nervous." We simultaneously modelled each of these six outcomes within a single model.  -->

During the past 30 datys do you feel Fatigue... "None Of The Time", "A Little Of The Time", "Some Of The Time", "Most Of The Time", "All Of The Time." 

## Model 

$$\begin{align}
y_{i}^k \sim \text{Ordered}(\mu_{i}^k) \\
\text{CumLogit}(\mu_{i}^k) = \alpha^k +\beta X_i \\
\alpha^k \sim \text{StudentT}(3,0,10)\\
\boldsymbol{\beta}\sim \text{Normal}(0,1) 
\end{align}$$



Below, the superscript $k$ is denotes the $k = 1\dots5$ outcomes (five thresholds). Residuals for cumulative categorical models are not identified, so are fixed to 1. $\alpha_{0}^k$ denotes the $t = 1\dots 5$ intercepts estimated for the ordinal model, which assumed a cumulative logit distribution for the outcome, and where the lowest response level is modelled as zero, hence four intercepts are estimated. $$\mathbf{\beta}$$ denotes the individual-level predictors in this case the time categories of the `Covid_Timeline` indicator.


## Ordinal outcomes

```{r cache = TRUE}
system.time(
  m1 <- brm(
    bf(HLTH.Fatigue_int  ~
      Covid_Timeline_cr),
    family = cumulative(link = "logit"),
    data = nz,
    file = here::here("models", "ordinal_fatigue"),
    silent = FALSE
  )
)
par_m1 <-parameters::model_parameters(m1)
par_m1
plot(par_m1)
```

Plot of the predicted effects, We can see changes in the response across the different time points, with reductio fatigue levels during Lockdown 

Here is a graph of using the ggeffects package, revealing that the movements where subtle, but evident, across the range of responses:


This is the graph using the BRMS package plotting features, setting "categorical" to FALSE. We only do this to show the average drop.


```{r}
plot(
  conditional_effects(
    m1,
    categorical = FALSE,
    prob = 0.89,
    re_formula = NA,
  ),
  points = TRUE,
  point_args = list(
    alpha = 0.1,
    width = .1,
    size = .2
  )
) 
```


We can plot all the individual intercepts this way:


```{r}
plot(
  conditional_effects(
    m1,
    categorical = TRUE,
    prob = 0.89,
    re_formula = NA,
  ),   # WE cannot graph points when the points arg = TRUE
  points = TRUE,
  point_args = list(
    alpha = 0.1,
    width = .1,
    size = .2
  )
) 
```

This is another method for graphing, where the individual facits denote our expected response thresholds

```{r}
table(nzl$HLTH.Fatigue_int)
```


```{r eval = FALSE}
plot(ggeffects::ggpredict(
  m1, 
  effects = "Covid_Timeline_cr")
  )
```


## Ordinal Predictors

Suppose we wanted to assess whether fatigue predicts psychological distress. We'll use a smaller subsample to speed up computing time:

```{r cache = TRUE}
# Create small sample to improve computing time
snzl <- nzl %>%
  dplyr::filter(Wave == 2019) # Only one wave


set.seed(123)
nm <-
  sample(snzl$Id, size = 300) # randomly select a smaller sample of individuals.
sub_nzl <- snzl %>%
  filter(Id %in% nm)
```

Let's compare models

```{r cacht = TRUE}
# ordinary predictor
mo_0 <- brm(
  bf(KESSLER6sum  ~ HLTH.Fatigue,
     family = "poisson"),
  data = sub_nzl,
  file = here::here("models", "monotonic_0"),
  silent = FALSE
)

# table
par_mo_0 <-parameters::model_parameters(mo_0)
par_mo_0

# coefficient plot
plot(par_mo_0) + labs(title = "Distress on Fatigue, no monotonic effects")
```


The expected increase in distress from a one unit increase in Fatige is .45 units of Kessler 6 distress on the log scale. 

We exponentiate this to obtain expected changes on the data scale, recalling that we should include the intercept:

A one unit change in fatigue leads to an expected change in distress of:

```{r}
exp(.75 + .45)
```

We can plot the entire range of the response scale: 

```{r}
p_mo_0 <- plot(
  conditional_effects(mo_0),
  points = TRUE,
  point_args = list(alpha = 0.1,
                    width = .2)
)[[1]] 

p_mo_0 + labs(title = "Predicted Distress by Fatigue: Poisson model")
```


We model the relationship of Fatigue on Distress by thinking of Fatigue as as a monotonic predictor, using the `mo` command, as follows:

```{r cache = TRUE}
mo_1 <- brm(
  bf(KESSLER6sum  ~ mo(HLTH.Fatigue),
     family = "poisson"),
  data = sub_nzl,
  file = here::here("models", "monotonic_1"),
  silent = FALSE
)

# table
par_mo_1 <-parameters::model_parameters(mo_1)
par_mo_1

# coefficient plot
plot(par_mo_1) + labs(title = "Distress on Fatigue, monotonic effects") 
```

Note that we have 4 x Betas for Fatigue, which each level of Fatigue receiving its own beta. 

Graphing the results:

```{r cache = TRUE}
p_mo_1 <- plot(
  conditional_effects(mo_1),
  points = TRUE,
  point_args = list(alpha = 0.1,
                    width = .2)
)[[1]] + labs(title = "Predicted Distress by Fatigue: monotonic effects model")
p_mo_1
```

Compare our models, in this instance it appears that we do not require predicting Distress by Fatigue using monotonic effects:

```{r cache = TRUE}
compare_mo_0 <- add_criterion(mo_0, "loo")
compare_mo_1 <- add_criterion(mo_1, "loo")

compare_mo <-
  loo_compare(compare_mo_0, compare_mo_1, criterion = "loo")
compare_mo
```


We can visually inspect the posterior predictions, and they not look too different: 

Without monotonic predictors

```{r}
brms::pp_check(mo_0)
```


With monotonic predictors 

```{r}
brms::pp_check(mo_1)
```



## Distributional model

Paul Bruckner, the author of the BRMS package, offers the following distributional model (see the explanation {here](https://cran.r-project.org/web/packages/brms/vignettes/brms_distreg.html))


```{r}
group <- rep(c("treat", "placebo"), each = 30)
symptom_post <- c(rnorm(30, mean = 1, sd = 2), rnorm(30, mean = 0, sd = 1))
dat1 <- data.frame(group, symptom_post)
head(dat1)
```

Note that you can fit a model in which the variation in reponse, and not merely the average response, is estimated. Paul does so as follows:

```{r cache = TRUE}
fit1 <- brm(bf(symptom_post ~ group,
               sigma ~ group),
            data = dat1,
            family = gaussian())
```


Paul's workflow includes visualing the chains of the bayesian model, a point to which we'll return next week: 

```{r}
summary(fit1)
plot(fit1, N = 2, ask = FALSE)
```

Here we have the prediction plot

```{r}
plot(conditional_effects(fit1), points = TRUE)
```

BRMS allows us to estemate whether both parameters (the mean) and the standard deviations of the mean, differ:

```{r}
hyp <- c("exp(sigma_Intercept) = 0",
         "exp(sigma_Intercept + sigma_grouptreat) = 0")
hypothesis(fit1, hyp)
```

Both the mens, and the variances, differ. 

We can graph these differences:

```{r}
hyp <- "exp(sigma_Intercept + sigma_grouptreat) > exp(sigma_Intercept)"
(hyp <- hypothesis(fit1, hyp))
plot(hyp)
```

When might this model apply? 

> Suppose we have two groups of patients: One group receives a treatment (e.g., an antidepressive drug) and another group receives placebo. Since the treatment may not work equally well for all patients, the symptom variance of the treatment group may be larger than the symptom variance of the placebo group after some weeks of treatment. (Paul Bruckner, BRMS vignette)



## Random intercept: CLUSTERING


Let's consider distress responses by week in our NZAVS jitter dataset for 2018-2020. 

```{r}
# 506 weekss betwen 530 June 2009 and 15 March 2019
ri_weeeks <- brm(
  bf(Warm.Muslims  ~
       (1 | WSCORE)),
  data = nzl,
  file = here::here("models", "random_intercept_"),
  silent = FALSE
)

glimpse(nzl)
```

Graph of week variances. 

```{r}
par_ri_weeeks <-parameters::model_parameters(ri_weeeks,
                                             dispersion = TRUE, 
                                             effects = "random")

## CONTEXT
# 556 weeks 3 days
# 30 June 2009 â€“ 28 February 2020
plot(par_ri_weeeks, sort = FALSE, type = "re")
```


```{r}
plot(par_ri_weeeks,   sort = TRUE) 

plot(
  conditional_effects(
    m_k6_p,
    spaghetti = TRUE,
    nsamples = 100,
    categorical = F,
    prob = 0.89,
    re_formula = NA
  ),
  points = TRUE,
  point_args = list(alpha = 0.1,
                    width = .02)
) # 
```








## Random intercept: Fatigue

$$\begin{align}
y_{ij}^k \sim \text{Ordered}(\mu_{ij}^k) \\
\text{CumLogit}(\mu_{ij}^k) = \alpha_{ij}^k +\beta X_i \\
\alpha_{ij}^k = \alpha_{0}^k +\alpha_j\\
\alpha_{0}^k \sim \text{StudentT}(3,0,10)\\
\alpha_j \sim \text{StudentT}^+(3,0,10)\\
\boldsymbol{\beta}\sim \text{Normal}(0,1) 
\end{align}$$

Below, the superscript $k$ is denotes the $k = 1\dots6$ outcomes (five thresholds). Residuals for cumulative categorical models are not identified, so are fixed to 1. $\alpha_{0}^k$ denotes the $t = 1\dots 5$ intercepts estimated for the ordinal model, which assumed a cumulative logit distribution for the outcome, and where the lowest response level is modelled as zero, hence four intercepts are estimated. $$\mathbf{\beta}$$ denotes the individual-level predictors in this case the time categories of the `Covid_Timeline` indicator.

```{r}
system.time(
  m1_l <- brm(
    bf(HLTH.Fatigue_int  ~
      Covid_Timeline + (1|Id),
    family = cumulative(link = "logit")),
    data = nzl,
    file = here::here("models", "ordinal_fatigue_longitudinal"),
    silent = FALSE
  )
)
par_m1_l <-parameters::model_parameters(m1_l)
par_m1_l
plot(par_m1_l)

plot(
  conditional_effects(
    m1_l,
   # spaghetti = TRUE,
  #  nsamples = 100,
    categorical = F,
    prob = 0.89,
    re_formula = NA,
  ),
  points = TRUE,
  point_args = list(alpha = 0.1,
                    width = .02)
) #  note this command controls which facet 

plot(ggeffects::ggpredict(m1_l), add.data= F, dot.alpha = .1)
```




```{r}
system.time(
  m_k6_s <- brm(
    bf(KESSLER6sum  ~
      Covid_Timeline + (1|Id)),
      data = nzl,
    file = here::here("models", "k6_longitudinal_gaussian"),
    silent = FALSE
  )
)

par_m_k6_s <-parameters::model_parameters(m_k6_s,dispersion = TRUE)
par_m_k6_s
plot(par_m_k6_s,  sort = TRUE) 

```


## Random Intercept



```{r}
system.time(m_k6_p <- brm(
  bf(KESSLER6sum  ~
       Covid_Timeline + (1 | Id),
     family = "poisson"),
  data = nzl,
  file = here::here("models", "k6_longitudinal_p"),
  silent = FALSE
))
summary(m_k6_p)
summary(m_k6_s0)

par_m_k6_p <-parameters::model_parameters(m_k6_p,dispersion = TRUE)
par_m_k6_p
plot(par_m_k6_p, sort = TRUE) 
plot(par_m_k6_s,  type = "fe", sort = TRUE, horizontal = TRUE) 

plot(
  conditional_effects(
    m_k6_p,
    spaghetti = TRUE,
    nsamples = 100,
    categorical = F,
    prob = 0.89,
    re_formula = NA
  ),
  points = TRUE,
  point_args = list(alpha = 0.1,
                    width = .02)
) # 



plot(
  conditional_effects(
    m_k6_s0,
    spaghetti = TRUE,
    nsamples = 100,
    categorical = F,
    prob = 0.89,
    re_formula = NA
  ),
  points = TRUE,
  point_args = list(alpha = 0.1,
                    width = .02)
) # 

plot(ggeffects::ggpredict(m_k6_p), add.data= TRUE, dot.alpha = .1)

```

```{r}
wg <- add_criterion(m_k6_s, "loo")
wp <- add_criterion(m_k6_p, "loo")

w <-loo_compare(wg, wp, criterion = "loo")
w
```



```{r}
brms::pp_check(m_k6_s) + xlim(0, 5)
```

```{r}
brms::pp_check(m_k6_p) + xlim(0, 5)
```


## Multivariate Outcomes 


```{r}

# Create smaller data frame
snzl <- nzl %>%
  dplyr::filter(Wave == 2019) # Only one wave

set.seed(123)
nm <- sample(snzl$Id, size = 300) # randomly select a smaller sample of individuals. 

# create the data frame
sub_nzl<- snzl%>%
 filter(Id %in% nm)


f_mv <- brm(
  mvbind(Warm.Immigrants, Warm.Muslims) ~  log(Hours.News + 1),
  data = sub_nzl,
  file = here::here("models", "multivariate_warmth"), 
)
summary(f_mv)
```

```{r}
brms::stanplot(f_mv, 
               type = "areas",
               prob = .89)
```



A different formulation


```{r}
library(splines)

bf_mus <- bf(Warm.Muslims ~ Hours.News + s(yearS)  + (1|p|Id))
             
bf_imm <- bf(Warm.Immigrants ~ Hours.News + s(yearS)  + (1|p|Id))


f_mv2 <- brm(
  bf_mus + bf_imm + set_rescor(FALSE), 
  data = nzl,
  file = here::here("models", "multivariate_warmth2"), 
  control = list(adapt_delta = 0.95)
)
summary(f_mv2)
```


```{r}
pp_check(f_mv, resp = "Warm.Immigrants")
```

```{r}
pp_check(f_mv, resp = "Warm.Muslims")
```



```{r}
conditional_effects(f_mv2, "Hours.News", resp = "WarmImmigrants")
```





##  Mediation

-   Manipulate X, measure M and Y
-   Regress M on X; Y on X and M

```{r, layout = "l-body-outset", cache =TRUE}
bmlm::mlm_path_plot(xlab = "Condition\n(X)",
              mlab = "Mediator\n(M)",
              ylab = "Distress\n(Y)")
```

## Assumptions

-   Y does not affect M
-   No 3rd variable on M to Y relationship
-   M is measured without error
-   Y and M residuals are not correlated [@vuorre2020multilevel]


## Set up

```{r echo = TRUE, eval = FALSE}
path_m <- bf(
  mF ~ x + (1 | c | id)
  )
path_y <- bf(
  y ~ x + mF_w + mF_b +
               (1 | c | id)
  )
m1 <- brm(
  path_m + path_y + set_rescor(FALSE),
  data = datF,
  file = here("models/mediation-k6-covid-fatigue")
)
```


## Model form 
```{r echo = FALSE}
x <-nzl$Covid_Timeline
mF <-nzl$HLTH.Fatigue_int
y<- nzl$KESSLER6sum
id <-nzl$Id
datF <-data.frame(x,mF, y,id)
```

```{r echo = FALSE}
path_m <- bf(
  mF ~ x + (1 | c |  id)
  )
path_y <- bf(
  y ~ x + mF +  (1 | c |  id)
  )
f1 <- brm(
  path_m + path_y + set_rescor(FALSE),
  data = datF,
  file = here::here("models/mediation-k6-covid-fatigue")
)

summary(f1)
```



```{r echo=FALSE, cache = FALSE}
post1F <- brms::posterior_samples(f1)
post_marF <- post1F %>% 
  transmute(
    a = b_mF_xLockdown,
    b = b_y_mF,
    cp = b_y_xLockdown,
    me = a * b,
    c = cp + me#,
   # pme = me / c
  )
# posterior_summary(post_marF)
```
```{r}
mcmc_intervals(post_marF)
```

## Hypothesis 

## Excercise: March vs. L4

```{r}
h1 <- c(
  a = "mF_xLockdown  = 0",
  b = "y_mF = 0",
  cp = "y_xLockdown = 0",
  me = "mF_xLockdown * y_xLockdown = 0",
  c = "mF_xLockdown * y_mF + y_xLockdown = 0"
)

plot(
  hypothesis(f1, h1)
)

```






## Bonus: Latent Profile Analysis

## Latent Profile Analysis

```{r  cache = TRUE}
library(tidyLPA)
# nzf<-nz %>%
#   select( FeelHopeless, 
#           FeelDepressed,
#           FeelRestless, 
#           EverythingIsEffort,
#           FeelWorthless, 
#           FeelNervous) %>%
#   mutate_if(., is.factor, ~ as.numeric(as.integer(.x)))

# convert to standard deviation units

out<-nzl_2019 %>%
  dplyr::select(Hours.Internet, 
          Hours.Exercise,
       #   Hours.CompGames, 
       #   Hours.News,
          Hours.Work)%>%
  dplyr::mutate_all(., scale)

out%>%
  single_imputation() %>%
  tidyLPA::estimate_profiles(3) %>%
    plot_profiles(add_line = TRUE)
```
