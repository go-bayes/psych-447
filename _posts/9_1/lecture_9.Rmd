---
title: "Ordinal responses, monotonic predictors, mediation, and group-level intercepts"
description: 
author:
  - name: Joseph Bulbulia
    url: https://josephbulbulia.netlify.app
    affiliation: Victoria University of Wellington
    affiliation_url: https://www.wgtn.ac.nz
    orcid_id: 0000-0002-5861-2056
date: 2021-MAY-04 
output:
  distill::distill_article:
    self_contained: false
    toc: true
    code_folding: true
    highlight: kate
bibliography: bib.bib
---

```{r echo=F, include = F}
knitr::include_graphics("op2.png")
```

```{r setup, include=FALSE}
# setup
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  layout = "l-body-outset",
  fig.width = 12,
  fig.height = 10,
  collapse = TRUE,
  R.options = list(width = 60
  )
)
```

```{r  libraries, echo=FALSE}
### Libraries
library("tidyverse")
library("ggplot2")
library("patchwork")
library("lubridate")
library("kableExtra")
library("gtsummary")
library("lubridate")
library("equatiomatic")
library("ggdag")
library("brms")
library("rstan")
library("rstanarm")
library("bayesplot")
library("easystats")
library("kableExtra")
library("broom")
library("tidybayes")
library("bmlm")
if (!require(tidyLPA)) {
  install.packages("tidyLPA")
}
# rstan options
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores ())
theme_set(theme_classic())
```

```{r  nzdata, include=FALSE, cache  = TRUE}
# read data


nz_0 <- as.data.frame(readr::read_csv2(
  url(
    "https://raw.githubusercontent.com/go-bayes/psych-447/main/data/nzj.csv"
  )
))

# to relevel kessler 6 variables
f <-
  c(
    "None Of The Time",
    "A Little Of The Time",
    "Some Of The Time",
    "Most Of The Time",
    "All Of The Time"
  )

# Relevel covid timeline longitudional
# ord_dates_class <- c(
#   "Baseline",
#   "PreCOVID",
#   "JanFeb",
#   "EarlyMarch",
#   "Lockdown",
#   "PostLockdown")

# Relevel covid timeline 2019
ord_dates_class_2019_only <- c("PreCOVID",
                               "JanFeb",
                               "EarlyMarch",
                               "Lockdown",
                               "PostLockdown")
# get data into shape
nz_cr <- nz_0 %>%
  dplyr::mutate_if(is.character, factor) %>%
  select(
    -c(
      SWB.Kessler01,
      SWB.Kessler02,
      SWB.Kessler03,
      SWB.Kessler04,
      SWB.Kessler05,
      SWB.Kessler06
    )
  ) %>%
  dplyr::mutate(Wave = as.factor(Wave)) %>%
  dplyr::mutate(FeelHopeless = forcats::fct_relevel(FeelHopeless, f)) %>%
  dplyr::mutate(FeelDepressed = forcats::fct_relevel(FeelDepressed, f)) %>%
  dplyr::mutate(FeelRestless = forcats::fct_relevel(FeelRestless, f)) %>%
  dplyr::mutate(EverythingIsEffort = forcats::fct_relevel(EverythingIsEffort, f)) %>%
  dplyr::mutate(FeelWorthless = forcats::fct_relevel(FeelWorthless, f)) %>%
  dplyr::mutate(FeelNervous = forcats::fct_relevel(FeelNervous, f)) %>%
  dplyr::mutate(Wave = as.factor(Wave)) %>%
  dplyr::mutate(male_id = as.factor(Male)) %>%
  dplyr::mutate(date = make_date(year = 2009, month = 6, day = 30) + TSCORE) %>%
  dplyr::mutate(
    FeelWorthless_int = as.integer(FeelWorthless),
    FeelNervous_int =  as.integer(FeelNervous),
    FeelHopeless_int =  as.integer(FeelHopeless),
    EverythingIsEffort_int =  as.integer(EverythingIsEffort),
    FeelRestless_int =  as.integer(FeelRestless),
    FeelDepressed_int =  as.integer(FeelDepressed),
    HLTH.Fatigue_int = as.integer(HLTH.Fatigue + 1)
  ) %>%
  dplyr::mutate(yearS = TSCORE - min(TSCORE, na.rm = TRUE)) %>%
  dplyr::mutate(KESSLER6sum = as.integer(KESSLER6sum))



nz <- nz_cr %>%
  dplyr::filter(YearMeasured == 1) %>%
  dplyr::filter(Wave == 2019) %>%
  dplyr::group_by(Id) %>%
  dplyr::ungroup(Id) %>%
  dplyr::mutate(Covid_Timeline_cr =
                  as.factor(ifelse(
                    TSCORE %in% 3896:3921,
                    # feb 29 - march 25th
                    "EarlyMarch",
                    ifelse(
                      TSCORE %in% 3922:3954,
                      "Lockdown",
                      #march 26- Mon 27 April 2020
                      ifelse(
                        TSCORE > 3954,
                        # after april 27th 20202
                        "PostLockdown",
                        ifelse(TSCORE %in% 3842:3895,
                               # jan 6 to feb 28
                               "JanFeb",
                               "PreCOVID")
                      )
                    )
                  ))) %>%
  dplyr::mutate(Covid_Timeline_cr = forcats::fct_relevel(Covid_Timeline_cr, ord_dates_class_2019_only))

dplyr::glimpse(nz)


## Long data #####################
ord_dates_class <- c("Baseline",
                     "PreCOVID",
                     "JanFeb",
                     "EarlyMarch",
                     "Lockdown",
                     "PostLockdown")

nzl <- nz_cr %>%
  dplyr::filter(YearMeasured == 1) %>%
  dplyr::filter(Wave == 2018 | Wave == 2019) %>%
  dplyr::group_by(Id) %>%
  dplyr::filter(n() > 1) %>%
  dplyr::filter(n() != 0) %>%
  dplyr::ungroup(Id) %>%
  dplyr::mutate(yearS = TSCORE - min(TSCORE, na.rm = TRUE)) %>%
  dplyr::mutate(WSCORE = as.factor(WSCORE)) %>%
  dplyr::mutate(Covid_Timeline =
                  as.factor(ifelse(
                    TSCORE %in% 3896:3921,
                    # feb 29 - march 25th
                    "EarlyMarch",
                    ifelse(
                      TSCORE %in% 3922:3954,
                      "Lockdown",
                      #march 26- Mon 27 April 2020
                      ifelse(
                        TSCORE > 3954,
                        # after april 27th 20202
                        "PostLockdown",
                        ifelse(
                          TSCORE %in% 3842:3895,
                          # jan 6 to feb 28
                          "JanFeb",
                          ifelse(TSCORE %in% 3665:3841 &
                                   Wave == 2019,
                                 "PreCOVID",
                                 "Baseline"  # 3672 TSCORE or  20 July 2019))))))))
                          )
                        )
                      )
                    ))))%>%
  dplyr::mutate(Covid_Timeline = forcats::fct_relevel(Covid_Timeline, ord_dates_class))
                
glimpse(nzl)
```

## Objectives

To develop the following skills:

-   modelling ordinal (cumulative logit) responses
-   modelling ordinal (monotonic) predictors
-   distributional models in which we estimate predictors for the variance as well as for the mean response.
-   group-level intercept models (aka "random" intercept models).
-   multiple response models estimating multivariate outcomes (i.e. two or more)
-   mediation models
-   interpret and report the results for these models using graphical methods.

## Ordinal responses

An ordinal model is a cumulative logistic model. Instead of binary outcomes, we assume there are n \> 2 outcomes \cite{Burkner2019-ie,Hadfield2012-hi}.

<!-- In our NZ-jitter dataset, the Kessler-6 has five ordinal response options for indicating frequency of feeling distress during the past 30 days: "None Of The Time", "A Little Of The Time", "Some Of The Time", "Most Of The Time", "All Of The Time" hence six thresholds.  -->

<!-- The Kessler-6 distress indicators are: "Feeling Hopelessness;" "Feeling so Depressed Nothing Could Cheer You Up;" "Feeling Nervous or Fidgety;" "Feeling Everything is an Effort;" "Feeling Worthless;" "Feeling Nervous." We simultaneously modelled each of these six outcomes within a single model.  -->

Consider the `HLTH.Fatigue` indicator from the NZAVS jitter dataset. The item reads:

> "During the past 30 days have you felt fatigue... "

and the responses are:

> "None Of The Time",

> "A Little Of The Time",

> "Some Of The Time",

> "Most Of The Time",

> "All Of The Time."

A priori, we might think that Fatigue is better approached as an ordered categorical indicator rather than as a continuous indicator:

```{r}
hist(nzl$HLTH.Fatigue)
```

### Model equation for an ordinal response model

We can write the model equation for an ordinal (or cumulative logistic) model of Fatigue s follows

$$\begin{align}
y_{i}^c \sim \text{Ordered}(p_i) \\
\text{CumLogit}(\boldsymbol{p_i}) = \alpha^c +\beta X_i \\
\alpha^c \sim Normal(0,10)\\
\boldsymbol{\beta}\sim \text{Normal}(0,1) 
\end{align}$$

For an ordinal response model, where there are $R$ responses for our outcome indicator, there are $C = R-1, c = 1\dots C$ thresholds or "cutpoints."

As with binary logistic regression, residuals for cumulative logistic models are not identified, so are fixed to 1. $\alpha^c$ denotes the $c^{th}$ intercept estimated in the model. Where the lowest response level is modeled as zero, hence four intercepts are estimated. $\mathbf{\beta}$ is the esitmate for the$X$ parameter measured on $i...N$ individuals. In this case the time categories of the `Covid_Timeline` indicator.

```{r cache = TRUE}
m1 <- brm(
  bf(HLTH.Fatigue_int  ~
       Covid_Timeline_cr),
  family = cumulative(link = "logit"),
  data = nz,
  file = here::here("models", "ordinal_fatigue"),
  silent = FALSE
)

par_m1 <- parameters::model_parameters(m1)
par_m1
plot(par_m1)
```

Hre we can see that the log-odds of Fatigue dropped during Lockdown. But how exactly did Fatigue drop?

As with logistic regression, the coefficients here are not obvious. To interpret results, we should graph the predicted outcomes at specific values.

### Interpreting results of an ordinal model using graphical methods

To understand what is happening, we plot all the individual intercepts by setting `categorical = TRUE`. Following McElreath's Statistical Rethinking, we will predict outcomes using the .89 probability credible interval:

```{r}
plot(
  conditional_effects(
    m1,
    categorical = TRUE,
    prob = 0.89,
    re_formula = NA,
  ),   # WE cannot graph points when the points arg = TRUE
  points = TRUE,
  point_args = list(
    alpha = 0.1,
    width = .1,
    size = .2
  )
) 
```

Here we see the separation occurring during `Lockdown` as compared with the baseline `PreCOVID`

This is another method for graphing, where the individual facets denote our expected response thresholds:

```{r}
plot(ggeffects::ggpredict(
  m1, 
  effects = "Covid_Timeline_cr")
  )
```

Finally, for the purposes of exploration, we can obtain an average response using the BRMS `conditional_effects` function, with the setting `categorical = FALSE`

```{r}
plot(
  conditional_effects(
    m1,
    categorical = FALSE,
    prob = 0.89,
    re_formula = NA,
  ),
  points = TRUE,
  point_args = list(
    alpha = 0.1,
    width = .1,
    size = .2
  )
) 
```

## Ordinal (or monotonic) predictors

Reference, here (<https://psyarxiv.com/9qkhj/>) also the BRMS documentation [here](https://cran.r-project.org/web/packages/brms/vignettes/brms_monotonic.html)

> A predictor, which we want to model as monotonic (i.e., having a monotonically increasing or decreasing relationship with the response), must either be integer valued or an ordered factor. As opposed to a continuous predictor, predictor categories (or integers) are not assumed to be equidistant with respect to their effect on the response variable. Instead, the distance between adjacent predictor categories (or integers) is estimated from the data and may vary across categories.

### Model equation for a monotonic predictor model:

For an ordinal predictor model, where there are $R$ indicator responses, there are $C = R-1, c = 1\dots C$ thresholds to estimate for the the ordered reponses predictors

-   $b^c$ locates the direction and size of effect, as with an ordinary regression solution. We consider $b^c$ as the expected average difference between two adjacent categories of the ordinal predictor.
-   $\zeta^c$ locates the normalized distances between consecutive predictor categories, producing the shape of the monotonic effect

$$g(y_i) = \alpha + b^c \zeta^c $$

Suppose we wanted to assess whether fatigue predicts psychological distress. We'll use a smaller sub-sample of the NZAVS jitter dataset to speed up computing time:

```{r cache = TRUE}
# Create small sample to improve computing time
snzl <- nzl %>%
  dplyr::filter(Wave == 2019) # Only one wave
set.seed(123)
nm <-
  sample(snzl$Id, size = 300) # randomly select a smaller sample of individuals.
sub_nzl <- snzl %>%
  filter(Id %in% nm)
```

First we estimate a model without a monotonic effect:

```{r cacht = TRUE, code_folding=FALSE}
# ordinary predictor
mo_0 <- brm(
  bf(KESSLER6sum  ~ HLTH.Fatigue,
     family = "poisson"),
  data = sub_nzl,
  file = here::here("models", "monotonic_0"),
  silent = FALSE
)

# table
par_mo_0 <-parameters::model_parameters(mo_0)
par_mo_0

# coefficient plot
plot(par_mo_0) + labs(title = "Distress on Fatigue, no monotonic effects")
```

The expected increase in distress from a one unit increase in Fatigue is .45 units of Kessler 6 distress on the log scale.

To translate this expectation to the data scale recall that we must exponentiate our result.

A one unit change in fatigue at the intercept leads to an expected change in distress of:

```{r}
exp(.75 + .45)
```

We plot the entire range of the response scale:

```{r}
p_mo_0 <- plot(
  conditional_effects(mo_0),
  points = TRUE,
  point_args = list(alpha = 0.1,
                    width = .2), 
  ask = FALSE
)[[1]]
```

We next model the relationship of Fatigue on Distress by thinking of Fatigue as as a monotonic predictor, using the `mo` command, as follows:

```{r cache = TRUE, code_folding=FALSE}
mo_1 <- brm(
  bf(KESSLER6sum  ~ mo(HLTH.Fatigue),
     family = "poisson"),
  data = sub_nzl,
  file = here::here("models", "monotonic_1")
)

# table
par_mo_1 <-parameters::model_parameters(mo_1)
par_mo_1

# coefficient plot
plot(par_mo_1) + labs(title = "Distress on Fatigue, monotonic effects") 
```

Note that we have 4 x betas for Fatigue. What do these mean?

Graphing the results:

```{r cache = TRUE}
p_mo_1 <- plot(
  conditional_effects(mo_1),
  points = TRUE,
  point_args = list(alpha = 0.1,
                    width = .2)
)[[1]] 
```

The monotonic predictor, here, doesn't look to make all that much a difference.

We can formally compare the two models:

```{r cache = TRUE}
compare_mo_0 <- add_criterion(mo_0, "loo")
compare_mo_1 <- add_criterion(mo_1, "loo")

compare_mo <-
  loo_compare(compare_mo_0, compare_mo_1, criterion = "loo")
compare_mo
```

No real difference.

And can visually inspect the posterior predictions, and they not look too different:

Without monotonic predictors

```{r}
brms::pp_check(mo_0)
```

With monotonic predictors

```{r}
brms::pp_check(mo_1)
```

Again, no real difference. However, our model isn't fitting well. What would you do to improve the model fit?

There are no default strategies. Modelling requires a combination of reasoning and art.

## Distributional model

A distributional model predicts the variance as well as the mean of a response.

Paul Bruckner, the author of the BRMS package, offers the following simulated data for a distributional model (see the explanation {here](<https://cran.r-project.org/web/packages/brms/vignettes/brms_distreg.html>))

```{r code_folding=FALSE}
group <- rep(c("treat", "placebo"), each = 30)
symptom_post <-
  c(rnorm(30, mean = 1, sd = 2), rnorm(30, mean = 0, sd = 1))
dat1 <- data.frame(group, symptom_post)
head(dat1)
```

Fitting the model we have:

```{r cache = TRUE, message = FALSE, warnings = FALSE, code_folding=FALSE}
fit1 <- brm(bf(symptom_post ~ group,
               sigma ~ group),
            data = dat1,
            file = here::here("models", "distributional"),
            family = gaussian())

par_fit1 <-parameters::model_parameters(fit1)
par_fit1

# coefficient plot
plot(par_fit1) 
```

Here we have the prediction plot

```{r}
plot(conditional_effects(fit1), points = TRUE)
```

We can see the variance in the treatment group:

<!-- BRMS allows us to estemate whether both parameters (the mean) and the standard deviations of the mean, differ: -->

<!-- ```{r} -->

<!-- hyp <- c("exp(sigma_Intercept) = 0", -->

<!--          "exp(sigma_Intercept + sigma_grouptreat) = 0") -->

<!-- hypothesis(fit1, hyp) -->

<!-- ``` -->

<!-- Both the mens, and the variances, differ.  -->

<!-- We can graph these differences: -->

<!-- ```{r} -->

<!-- hyp <- "exp(sigma_Intercept + sigma_grouptreat) > exp(sigma_Intercept)" -->

<!-- (hyp <- hypothesis(fit1, hyp)) -->

<!-- plot(hyp) -->

<!-- ``` -->

When might this model apply?

> Suppose we have two groups of patients: One group receives a treatment (e.g., an antidepressive drug) and another group receives placebo. Since the treatment may not work equally well for all patients, the symptom variance of the treatment group may be larger than the symptom variance of the placebo group after some weeks of treatment. (Paul Bruckner, BRMS vignette)

## Random intercept model (clustering)

Typically our model has clustering. Often this clustering arises from dependencies owning to unmeasured grouping factors, students within schools, or repeated measures within students.

However, recall a fundamental assumption of regression:

> The simple regression model assumes that the errors from the prediction line are independent, an assumption that is violated in time series, spatial, and multilevel settings [@gelman_regression_2020, p.153]

Let's look at environmental concern as predicted by religious group membership:

```{r code_folding=FALSE}
# 506 weekss betwen 530 June 2009 and 15 March 2019
nzl_11 <- nzl %>%
  dplyr::filter(Wave == 2019)

ri_relgroups <- brm(
  bf(Env.ClimateChgConcern    ~
       (1 | Religious_Group)),
  data = nzl_11,
  file = here::here("models", "ri_relgroups"),
  silent = FALSE
)

summary(ri_relgroups)
```

### Model equation for a random intercept model

$$ g(y_{ig}) \sim N(\mu_{ig}, \sigma)\\
\mu_i = \boldsymbol{\alpha} + \beta x_{ig}\\
 \boldsymbol{\alpha} = \alpha_o + \alpha_g\\
 \alpha_o \sim N(3.5,10)\\
 \alpha_g \sim N(0,\sigma_g)\\
 \sigma_g \sim Exp(1)\\
  \sigma \sim Exp(1)
$$

We can calculate the intraclass correlation coefficient for religious groups, which is the ration of group variance devited by the total variance or in this case:

$$\frac{\sigma^2_{religious groups}}{\sigma^2_{religious groups} + \sigma^2_{indiviuals}}$$

```{r code_folding=FALSE}
performance::icc(ri_relgroups)
```

The authors of the performance package write (performance package documentation)

> While the adjusted ICC only relates to the random effects, the conditional ICC also takes the fixed effects variances into account (see Nakagawa et al. 2017). Typically, the adjusted ICC is of interest when the analysis of random effects is of interest.

We can plot the group-level variances:

```{r}
par_ri_relgroups <-parameters::model_parameters(ri_relgroups,
                                             effects = "random")
plot(par_ri_relgroups,   sort = TRUE) 
```

References: See: <https://m-clark.github.io/mixed-models-with-R/>

## Random intercept: Fatigue

With longitudinal data, we have repeated measures within individuals. This leads to clustering. We can adjust for this clustering by including group-level intercept for individuals.

Let's return to the Fatigue \~ Covid_Timeline model.

$$\begin{align}
y_{ij}^c \sim \text{Ordered}(\mu_{ij}^c) \\
\text{CumLogit}(\mu_{ij}^c) = \boldsymbol{\alpha}^c +\beta X_i \\
\boldsymbol{\alpha}^c  = \alpha_{0}^c +\alpha_j\\
\alpha_{0}^c \sim N(0,10)\\
\alpha_j \sim N(0,\sigma_j)\\
\sigma_j \sim exp(1)\\
\boldsymbol{\beta}\sim \text{Normal}(0,1) \\
\end{align}$$

```{r code_folding=FALSE}
  m1_l <- brm(
    bf(HLTH.Fatigue_int  ~
      Covid_Timeline + (1|Id),
    family = cumulative(link = "logit")),
    data = nzl,
    file = here::here("models", "ordinal_fatigue_longitudinal"),
    silent = FALSE
  )
summary(m1_l)
```

We graph the results

```{r cache = TRUE}
plot(
  conditional_effects(
    m1_l,
   # spaghetti = TRUE,
  #  nsamples = 100,
    categorical = T,
    prob = 0.89,
    re_formula = NA,
  ),
  points = TRUE,
  point_args = list(alpha = 0.1,
                    width = .02)
) #  note this command controls which facet
```

## Multiple response models

### Model equation

$$ g(y^n_{ig}) \sim N(\mu^n_{ig}, \sigma^n)\\
\mu^n_i = \boldsymbol{\alpha^n} + \beta^n x_{ig}\\
 \boldsymbol{\alpha} = \alpha_o + \alpha_g\\
 \alpha^n_o \sim N(3.5,10)\\
 \alpha^n_g \sim N(0,\sigma_g^n)\\
 \sigma_g^n \sim exp(1)\\
 \sigma^{n_1} \sim exp(1)\\
 \sigma^{n_2}\sim exp(1) \\
\begin{bmatrix}
\sigma^{n_1} \\
\sigma^{n_2} 
\end{bmatrix}
\sim 
\boldsymbol{RESCOR} \begin{pmatrix}
1 &  \sigma^{n_1}\sigma^{n_2} \rho    \\
\sigma^{n_1}\sigma^{n_2}\rho   &  1
\end{pmatrix}\\
\boldsymbol{RESCOR}\sim \text{LKJcorr}(2)
$$

```{r}
# Create smaller data frame
snzl <- nzl %>%
  dplyr::filter(Wave == 2019) # Only one wave

set.seed(123)
nm <- sample(snzl$Id, size = 300) # randomly select a smaller sample of individuals. 

# create the data frame
sub_nzl<- snzl%>%
 filter(Id %in% nm)
```

```{r code_folding=FALSE}
f_mv <- brm(
  mvbind(Warm.Immigrants, Warm.Muslims) ~  log(Hours.News + 1),
  data = sub_nzl,
  file = here::here("models", "multivariate_warmth"), 
)
summary(f_mv)
```

Coefficient plot

```{r code_folding=FALSE}
brms::mcmc_plot(f_mv, 
               type = "areas",
               prob = .89)
```

## Mediation

-   Manipulate X, measure M and Y
-   Regress M on X; Y on X and M

```{r, layout = "l-body-outset", cache =TRUE}
bmlm::mlm_path_plot(xlab = "Condition\n(X)",
              mlab = "Mediator\n(M)",
              ylab = "Distress\n(Y)")
```

## Assumptions

-   Y does not affect M
-   No 3rd variable on M to Y relationship
-   M is measured without error
-   Y and M residuals are not correlated [@vuorre2020multilevel]

## Set up

```{r echo = TRUE, eval = FALSE, code_folding=FALSE}
path_m <- bf(
  mF ~ x + (1 | c | id)
  )
path_y <- bf(
  y ~ x + mF_w + mF_b +
               (1 | c | id)
  )
m1 <- brm(
  path_m + path_y + set_rescor(FALSE),
  data = datF,
  file = here("models/mediation-k6-covid-fatigue")
)
```

## Model form

```{r echo = FALSE, code_folding=FALSE}
x <-nzl$Covid_Timeline
mF <-nzl$HLTH.Fatigue_int
y<- nzl$KESSLER6sum
id <-nzl$Id
datF <-data.frame(x,mF, y,id)
```

```{r echo = FALSE, code_folding=FALSE}
path_m <- bf(
  mF ~ x + (1 | c |  id)
  )
path_y <- bf(
  y ~ x + mF +  (1 | c |  id)
  )
f1 <- brm(
  path_m + path_y + set_rescor(FALSE),
  data = datF,
  file = here::here("models/mediation-k6-covid-fatigue")
)

summary(f1)
```

```{r echo=FALSE, cache = FALSE, code_folding=FALSE}
post1F <- brms::posterior_samples(f1)
post_marF <- post1F %>% 
  transmute(
    a = b_mF_xLockdown,
    b = b_y_mF,
    cp = b_y_xLockdown,
    me = a * b,
    c = cp + me#,
   # pme = me / c
  )
# posterior_summary(post_marF)
```

```{r}
mcmc_intervals(post_marF)
```

## Hypothesis

```{r, code_folding=FALSE}
h1 <- c(
  a = "mF_xLockdown  = 0",
  b = "y_mF = 0",
  cp = "y_xLockdown = 0",
  me = "mF_xLockdown * y_xLockdown = 0",
  c = "mF_xLockdown * y_mF + y_xLockdown = 0"
)

plot(
  hypothesis(f1, h1)
)

```

## Bonus: Latent Profile Analysis

## Latent Profile Analysis

Distinct profiles or clusters... tbc...

<!-- # nzf<-nz %>% -->

<!-- #   select( FeelHopeless,  -->

<!-- #           FeelDepressed, -->

<!-- #           FeelRestless,  -->

<!-- #           EverythingIsEffort, -->

<!-- #           FeelWorthless,  -->

<!-- #           FeelNervous) %>% -->

<!-- #   mutate_if(., is.factor, ~ as.numeric(as.integer(.x))) -->

<!-- # convert to standard deviation units -->

```{r  cache = TRUE, code_folding=FALSE}
library(tidyLPA)


out<-nzl %>%
  dplyr::select(Hours.Internet, 
          Hours.Exercise,
          Hours.Work)%>%
  dplyr::mutate_all(., scale)

out%>%
  single_imputation() %>%
  tidyLPA::estimate_profiles(3) %>%
    plot_profiles(add_line = TRUE)
```
