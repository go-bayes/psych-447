---
title: "Multiple regression (ANOVA, ANOVCA, MANOVA)"
description: 
author:
  - name: Joseph Bulbulia
    url: https://josephbulbulia.netlify.app
    affiliation: Victoria University of Wellington
    affiliation_url: https://www.wgtn.ac.nz
    orcid_id: 0000-0002-5861-2056
date: 2021-APRIL-20 
output:
  distill::distill_article:
    self_contained: false
    toc: true
bibliography: references.bib
---

```{r echo=F}
knitr::include_graphics("op_A.png")
```

## Required readings

Required readings are as follows:

-   @rohrer2018 [link](https://journals.sagepub.com/doi/full/10.1177/2515245917745629)
-   @barrett2021 [link](https://cran.r-project.org/package=ggdag)
-   @mcelreath2020[link](https://tewaharoa.victoria.ac.nz/discovery/fulldisplay?docid=alma99179374299902386&context=L&vid=64VUW_INST:VUWNUI&search_scope=MyInst_and_CI&tab=all&lang=en)

## Preamble

Make sure that you install the `rethinking` package and the `ggdag` package. Note that the rethinking package is not on cran.

```{r echo = TRUE, include = FALSE}
# packages
# ```{r install_rethinking}
# function for installing dependencies
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE) 
sapply(pkg, require, character.only = TRUE)
}
# usage
packages <- c("coda", "plyr", "mvtnorm", "scales", "dagitty")
ipak(packages)

# next install rethinking
if (!require(rethinking)) {
  devtools::install_github("rmcelreath/rethinking")
}

#next install ggdag
if (!require(rethinking)) {
  devtools::install_github("malcolmbarrett/ggdag")
}

if (!require(rethinking)) {
  devtools::install_github("larmarange/labelled")
}
# installed from previous lectures
library("equatiomatic")
library("tidyverse")
library("ggdag")
library("brms")
library("rstan")
library("rstanarm")
# library("tidybayes")
library("bayesplot")
library("easystats")
# rstan options
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores ())
theme_set(theme_classic())
```

## What is a regression model

Before the break, we introduced basic concepts in statistical regression.

To refresh your memory, let's focus on the relationship between the speed of a car and the distance that it takes for a car to stop. We'll use the `cars` dataset which is automatically loaded when you start R. Note: the data were collected in the 1920s

Here is our model

```{r}
model_simple <- lm(dist ~ speed, data = cars)
```

Here we have the output:

```{r}
parameters::parameters(model_simple)
```

How do we interpret the results?

We can write this output in the following way:

```{r eval = FALSE, include = FALSE}
# this is how to quickly generate the equation
equatiomatic::extract_eq(model_simple,  use_coefs = TRUE)
```

$$
\operatorname{\widehat{dist}} = -17.58 + 3.93(\operatorname{speed})
$$

The model says that the expected stopping distance for a car is -17.58 feet when the speed of the car is set to zero, plus an additional 3.93 feet for each additional unit of speed (here in miles per hour).

What strikes you about this model?

If you are like me you probably feel confusion when you see the number "-17.58" predicting speed. Did car manufacturers of the 1920s invent a method for traversing space and time as we know it? Or is regression a hopeless tool for understanding the world and should you demand your money back for this course?

Let's look at the data more carefully:

```{r}

cars%>%
  dplyr::arrange(speed)%>%
  tibble()
```

Here we find that the lowest speed measured in this dataset is 4 miles per hour, at which distance the car stopped in 2 feet. Another car travelling at 4 mph took 10 feet to stop.

Let's plug these two numbers into the regression equation that we just estimated.

```{r}
coef(model_simple)[[1]] + coef(model_simple)[[2]] * min(cars$speed, na.rm = FALSE)
```

Is this any better? We're still getting a negative speed.

Plotting the data we have:

```{r}
ggplot2::ggplot(data = cars, 
                aes( x = speed,  y = dist )) +
  geom_smooth(method = "lm") + 
  geom_point()
```

Here, our linear model is minimising the average distance between between observed speed and observed distance in the sample. The model hits at most a few points in the dataset. Otherwise it estimates a response that is either too high or two low.

In this case, we render the meaningless intercept term `r coef(model_simple)[[1]]` interpretable by setting centering our predictor variable speed:

```{r}
# center and create new dataframe
schmars <- cars%>%
  dplyr::mutate(speed_s = scale(speed, center = TRUE, scale = FALSE))

model_simple2 <- lm(dist ~ speed_s, data = schmars)
parameters::parameters(model_simple2)
```

Notice that the estimated coefficient for speed is the same:

```{r}
# evaluate whether the two coefficients are the same at least to five decimal places
round(coef(model_simple)[[2]],5) == round(coef(model_simple2)[[2]],5)
```

And the graph is the same:

```{r}
ggplot2::ggplot(data = cars, 
                aes( x = speed,  y = dist )) +
  geom_smooth(method = "lm") + 
  geom_point()
```

This examples serves as a reminder about how a regression model works. However it also makes an important point to which we'll return repeatedly throughout this course:



## Multiple regression 

We have already encountered multiple regression. Perhaps the most familiar case is prediction. Suppose we want to predict someones expected income based on their gender identification. Suppose we theory is true there might be an added income advantage from height.  We can include an additional term in our model and evaluate whether or theory is true.   Let's assess this question using the jittered NZAVS dataset 

```{r echo = FALSE}
nz_0 <- as.data.frame(readr::read_csv2(url("https://raw.githubusercontent.com/go-bayes/psych-447/main/data/nzj.csv")))
```

```{r echo = FALSE}
df<- nz_0 %>%
  dplyr::filter(Wave == 2019) %>%
  dplyr::mutate(age = Age) %>%
  dplyr::select(age, HLTH.Height, Household.INC, Male, Employed, Edu, Id, Wave) %>% # collect variables
  dplyr::filter(Employed == 1) %>% # restrict inference to people who are employed
  dplyr::rename(income = Household.INC, # shorter names
                not_male = Male) 

df['height_cm_c'] = as.data.frame(scale(df$HLTH.Height, center = TRUE, scale = FALSE)*1000) # work around for a bug - center and convert meter units to cmd
# not working
df['age_10_c'] = as.data.frame(scale(df$age, center = TRUE, scale = FALSE)/10) # work around for a bug - center and convert to decade units

df['edu_s'] = as.data.frame(scale(df$Edu) )# work around for a bug - center and convert to decade units

```


```{r}
# turn off scienitific notation
options(scipen = 0)

# model
model_theory <- lm(income ~ height_cm_c + not_male, data = df)
sjPlot::tab_model(model_theory)
```

```{r}
mean(nz_0$HLTH.Height, na.rm=TRUE)
```

The model tells us the following. The expected household income is `r coef(model_theory)[[1]]` for men at sample average height, which is `r mean(nz_0$HLTH.Height, na.rm=TRUE)`meters. The expected increase in income for each additional centimeter of height is `r coef(model_theory)[[2]]`. The expected reduction in income for people who do not identify as male is `r coef(model_theory)[[3]]`

Are men expected to make `r coef(model_theory)[[3]]` more than woman? No because on average woman are shorter. If we focus on male-id but remove height we have: 

```{r}
model_theory2 <- lm(income ~ not_male, data = df)
sjPlot::tab_model(model_theory2)
```

We find that women (and others who do not identify as male) are are expected to make `r coef(model_theory2)[[2]]` less than men. 

Note that regression allows us to stratify across other segments of a population by adding more covariates. Let's add education to the model. In the NZAVS education `Edu` is a 10-level factor.  However, for now, we'll think of it as numeric. A standard deviation of `Edu` is `r sd(df$Edu, na.rm = TRUE)` out of `r min(df$Edu, na.rm = TRUE)` to `r max(df$Edu, na.rm = TRUE)`.  Adding `edu_s` to the model we find:

### Futher adjustments 

```{r}
model_theory3 <- lm(income ~ height_cm_c + not_male + edu_s, data = df)
sjPlot::tab_model(model_theory3)
```

Do height differences make more of a difference for male-id's than non-male-id's?  To assess this we add an interaction term. **NOTE: we should always center and preferably also scale our interaction terms for the same reason that we should center polynomials: otherwise the multi-collinearity renders the model unstable**


### Interactions

```{r}
# model
model_theory4 <- lm(income ~ height_cm_c * not_male, data = df)
```

Note that this model is equivalent to:

```{r eval = FALSE}
model_theory4 <- lm(income ~ height_cm_c + not_male + not_male:height_cm_c, data = df)
```


The `*` in the model is merely shorthand for the two main effects `height_cm_c + not_male` $+$ their interaction `not_male:height_cm_c`.   Note that if we merely wanted to estimate the interaction without also estimating the main effects we would write:

```{r}
model_theory5<- lm(income ~ not_male:height_cm_c, data = df)
```
```{r}
parameters::parameters(model_theory5)
```


Such a model tells us that the population household average is about NZD 131,000, and the slope difference for height by gender is three times greater for male-id's than for non-male-id's in the population.

```{r}
plot(ggeffects::ggpredict(model_theory5, terms = c("not_male", "height_cm_c")))
```

Generally you should include the main effects and the interactions of your indicator:

```{r eval = FALSE}
model_theory4 <- lm(income ~ height_cm_c * not_male, data = df)
```

Which gives us:

```{r}
sjPlot::tab_model(model_theory4)
```

Whoooah what just happened?! There's huge uncertainty about the main effect of male-id -- it is no longer a reliable predictor in this model. 

To assess the magnitude of the uncertainty let's plot the regression coefficients:

```{r}
sjPlot::plot_model(model_theory4)
```

The main effect of not_male is nearly 35k per year!  What's going on here? Recall that multi-collinearity -- or when two indicators are highly correlated, tend to result in large uncertainty in coefficient estimates. Is the interaction messing up the model?  Let's check:

```{r}
z<-performance::check_collinearity(model_theory4)
z ## looks ok
plot(z) ## looks ok
```
As indicated in the graph, the problem isn't multi-collinearity.  

Does this mean that income is really predicted by height, and gender is a red herring? I have seen regression models interpreted that way. 

It looks that way:


```{r}
modelbased::estimate_means(model_theory4)
```

However this is comparing male-ids and not-male ids at equivalent levels of height, but we know that non-male-id's tend to be shorter. 
 
However **wherever you have interactions it is essential to graph the results**.  This is so important I'm going to write it again: **wherever you have interactions it is essential to graph the results**.  Tables are notoreously difficult to interpret. So let's probe further by graphing the model predictions. Recall that we can do this using the `ggeffects` package.


```{r}
pp1 <- plot(ggeffects::ggpredict(model_theory4, terms = c("not_male","height_cm_c")))
pp1
```



The following graph makes it easier to see how male-id fails to predict income whereas the interaction of male-id x income does predict income:

```{r}
x <- ggeffects::ggpredict(model_theory4, terms = c("height_cm_c","not_male"))
pp2 <- plot( x )
pp2
```

Or consider this graph

```{r}
pp3 <- plot( x,
      add.data = TRUE, 
      jitter = 0.2, 
      dot.alpha =.05
      ) + scale_y_continuous(limits = c(0,5e+5))

pp3
```

This graph graphs height along the x-axis, and plots two different line. What we find is a non-linearity.  The model predicts that, on average, short men are expected to make much less than short women. Among non male-ids, height differences are not a reliable predictor of household income. By contrast among male-ids, height differences are a reliable predictor. non-male-ids tend to be shorter than men by about 13cm

Sample averages:

```{r}
df%>%
  summarise(mean(HLTH.Height, na.rm = TRUE))
```

Sample differences by gender-id:

```{r}
df%>%
  group_by(not_male)%>%
  summarise(mean(HLTH.Height, na.rm = TRUE))
```


Let's plug in the values for male-id and not male-id at the population average for each population:

```{r eval = FALSE, include = FALSE}
# this is how to quickly generate the equation
equatiomatic::extract_eq(model_theory4,  use_coefs = TRUE)
```

$$
\operatorname{\widehat{income}} = 134509.3 + 233.14(\operatorname{height\_cm\_c}) - 5311.89(\operatorname{not\_male}_{\operatorname{Not\_Male}}) - 161.81(\operatorname{height\_cm\_c} \times \operatorname{not\_male}_{\operatorname{Not\_Male}})
$$
To get the expected average for the male-id population we compute the regression equation as follows

```{r}
coef(model_theory4)[[1]] + # intercept about 170 cm
  coef(model_theory4)[[2]] * 80 + # male-id are 8 cm taller than sample average # note we include this even though the coefficient is unreliable
  coef(model_theory4)[[3]]* 0 + # male-id are coded as zero  + 
  coef(model_theory4)[[4]]* 80 * 0 # 8cm difference * male-id are coded as zero  (which zeros this out)
```

For the female-id population we compute the regression equation as follows 

```{r}
coef(model_theory4)[[1]] + # intercept about 170 cm
  coef(model_theory4)[[2]] * -50 + # not male-id are 5 cm shorter than sample average # 
  coef(model_theory4)[[3]]* 1 + # not male-id are coded as 1  + 
  coef(model_theory4)[[4]] * -50 # 5cm shorter * male-id are coded as zero  (which zeros this out)
```

Compare these estimates with the model in which we did not have the interaction but only the additive predictors of male-id and height. We can do this quickly using the `modelbased` package.

```{r}
modelbased::estimate_means(model_theory2)
```

We find that the estimates are similar. 


### Model selection 

Which model should we prefer?  Recall that we can use the AIC or BIC information criterion to select a model, with a decrease in the absolute values of either as affording a reason to prefer one over the other.

```{r}
performance::compare_performance(model_theory, 
                                 model_theory2,
                                 model_theory3,
                                 model_theory4,
                                 model_theory5)
```

We can graph the models along different criteria

```{r}

xx <- performance::compare_performance(model_theory, 
                                 model_theory2,
                                 model_theory3,
                                 model_theory4,
                                 model_theory5)

plot(xx)
```

We find that model three performed the best. Recall that this is the model that included education:

```{r eval = FALSE}
model_theory3 <- lm(income ~ height_cm_c + not_male + edu_s, data = df)
```

What if we were to include an interaction with height and male-id? 

```{r}
model_theory6 <- lm(income ~ height_cm_c * not_male + edu_s, data = df)
```

There's no improvement in this model. After adjusting for education, height, and male-id, we do not see an improvement from including a non-linear ajustment for the height effect for the different male-id factors: 

```{r}
performance::compare_performance(model_theory3,model_theory6)
```

What about if we were to include age? 


```{r}
library("splines")
model_theory7 <- lm(income ~ bs(age_10_c) + height_cm_c * not_male + edu_s, data = df)
parameters::parameters(model_theory7)
```


The model has an improved fit, and explains more, the AIC decreases, but the BIC increases. This is because the BIC penalises the extra parameters.


```{r}
za<-performance::compare_performance(model_theory3, model_theory7) # age, benefit but only if polynomial
za
plot(za)
```

The predicted effect of age (splines)

```{r}
plot( ggeffects::ggpredict(model_theory7, terms = c("age_10_c")) ) 
```


```{r}
plot( ggeffects::ggpredict(model_theory7, terms = c("height_cm_c","not_male")) ) 
```


### Anova and T-test

You can write these as linear models.

This is a one-way anova in which the grouping variable "not_male" is the condition and "income" is the outcome.

Anova
```{r}
#anova
m2 <- aov(income ~ not_male, data = df)
parameters::parameters(m2)
```

This is how the report package says you should report. I've tweaked the wording because I cannot write "statistically significant" without vomitting:
```{r include = FALSE}
report::report(m2)
```

The ANOVA (formula: income ~ not_male) suggests that:

  - The main effect of not_male is statistically significant (F(1, 1734) = 23.52, p < .001; Eta2 = 0.01, 90% CI [5.87e-03, 0.02])

Effect sizes were labelled following Field's (2013) recommendations.

I recommend the `modelbased` package, which comes as part of `easystats` to explore your model

These are the estimated means
```{r}
modelbased::estimate_relation(m2)
```

Compare this against the linear model:

```{r}
m2l <- lm(income ~ not_male, data = df)
parameters::parameters(m2l)
```

This is how the report package says you should report. I've tweaked the wording because I cannot write "statistically significant" without vomiting. 

```{r include = FALSE}
report::report(m2l)
```

We fitted a linear model (estimated using OLS) to predict income with not_male (formula: income ~ not_male). The model explains a statistically significant proportion of variance (R2 = 0.01, F(1, 1734) = 23.52, p < .001, adj. R2 = 0.01). The model's intercept, corresponding to not_male = 0, is at 1.54e+05 (95% CI [1.45e+05, 1.63e+05], t(1734) = 33.03, p < .001). Within this model:

  - The effect of not_male [Not_Male] is significantly negative (beta = -28349.98, 95% CI [-39814.07, -16885.89], t(1734) = -4.85, p < .001; Std. beta = -0.24, 95% CI [-0.34, -0.14])

Standardized parameters were obtained by fitting the model on a standardized version of the dataset.


These are the estimated means, which are identical to the ANOVA. 

```{r}
modelbased::estimate_relation(m2l)
```

I'm not goint to spend any more time with ANOVA.  This isn't because I'm dimissive of ANOVA. It can be a useful framework for certain questions. However, it is never going to produce different answers than you would obtain in a linear regression framework. Moreover the linear regression framework is much more flexible, and can be extending However in case you are required to formulate your regression model, I've included some R syntax for you here.


#### One way ANOVA

```{r eval = FALSE}
aov(Y ~ Grp, data = data)
```

Assumptions:

- normal distribution of the of the DV's within each group
- homogeneity of variances within each group
- random sample from the population
- independent observations

#### Two way ANOVA

```{r eval = FALSE}
aov(Y ~ Grp * Male, data = data)
```

This model can be written

```{r eval = FALSE}
aov(Y ~ Grp + Male + Grp:Male, data = data)
```

- normal distribution of the of the DV's within each group
- homogeneity of variances within each group
- random sample from the population
- independent observations




