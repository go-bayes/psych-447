---
title: "Consolidation of skills"
description: |
author:
  - name: Joseph Bulbulia
    url: https://josephbulbulia.netlify.app
    affiliation: Victoria University of Wellington
    affiliation_url: https://www.wgtn.ac.nz
    orcid_id: 0000-0002-5861-2056
  - name: Johannes Karl
    url: https://johannes-karl.com
    affiliation: Victoria University of Wellington
    affiliation_url: https://www.wgtn.ac.nz
    orcid_id: 0000-0001-5166-0728
date: 2021-MAR-16
output:
  distill::distill_article:
    self_contained: false
    toc: true
---

```{r spss-old, echo=F}
knitr::include_graphics("op.png")
```

```{r echo = FALSE}
library("tidyverse")
# install if you don't have
library("lubridate") # usful for dates

nz <- readr::read_csv2(url("https://raw.githubusercontent.com/go-bayes/psych-447/main/data/nz/nz.csv"))
str(nz)

nz <-nz %>%
  dplyr::mutate_if(is.character, factor)


```

## Preamble

### Assigned reading: workflow Advice: read this

Advice on how to name your files (by Danielle Navarro) [here](https://slides.djnavarro.net/project-structure/#1)

### Something useful

The hash symbol `#` is for commenting

```{r}
r_comments <- 200 # here I am creating the variable for the number of time Jack says R is great

jill_roll <- 199 # here I'm creating a variable for the number of times Jill rolls here eyes

outcome <- log(r_comments) * sqrt(jill_roll) * pi # here I am illustrating some functions in r using the variables I just created

outcome # print outcome

round(outcome, digits = 2) # illustrate the useful `round` function.
```


## Data Carpentry  

### Different ways to select variables

Task: 3 different ways to select the variables that start with `Believe`.

#### Explicit selection
```{r}
names(nz)
nz %>%
  select("Believe.God", "Believe.Spirit")%>%
  as_tibble()
```

#### `starts_with` 

```{r}
nz %>%
  select(starts_with("Believe"))%>%
  as_tibble()
```

#### `contains`

```{r}
nz %>%
  select(contains("Believe"))%>%
  as_tibble()
```
#### whoops, so we try something else

This is a hack. 

```{r}
nz %>%
  select(contains("Believe") &  -  Religion.Believe.Cats)%>%
  as_tibble()
```

Lesson: think about your interests and purposes. 

### Re-leveling a factor

```{r}
nz %>%
  dplyr::select(BigDoms)%>%
  table() 

## suppose we want "Not_Rel" as the base category, and rearrange the other levels
library(forcats)
nz %>%
  dplyr::select(BigDoms) %>%
  dplyr::mutate(BigDoms =  
                  forcats::fct_relevel(BigDoms, c("Not_Rel","Christian","Buddhist","Muslim","TheOthers")))%>%
  table()
```


### Mutate by cutting

```{r}
nz <-nz %>%
  dplyr::mutate(k6cats = cut(
    KESSLER6sum,
    breaks = c(-Inf, 5, 13, Inf),   # create Kessler 6 diagnostic categories
    labels = c("Low Distress", "Moderate Distress", "Serious Distress"), 
    right = TRUE
  ))

```

### Preferable: use `ifelse` to do the same

Personally I find the following method better, because it gives me explicit control of how I am making the categories.

```{r}
nz %>%
  dplyr::mutate(k6cats1 =  as.factor(ifelse(
    KESSLER6sum <= 5,
    "Low Distress",
    ifelse(KESSLER6sum <= 13,  "Moderate Distress", "Serious Distress")
  ))) %>%
  group_by(k6cats1) %>%
  count()

#check this is the same as the previous method
nz %>%
  group_by(k6cats)%>%
  count()
```

### Using logical operators to create factors

### Create a table. 

```{r designtable,  tab.cap="\\label{tab:designtable}"}

library(kableExtra)
nz %>%
  select(k6cats, Wave) %>%
  filter(!is.na(k6cats))%>%
  group_by( Wave, k6cats) %>%
  summarise(n = n())%>%
  kbl(caption = "Distress by Year") %>%
   kable_classic_2(c("striped", "hover"), full_width = TRUE)%>%
  collapse_rows()
```

### Create and work with dates a date

```{r}
nz <- nz %>%
  dplyr::mutate(date = make_date(year = 2009, month = 6, day = 30) + TSCORE)  # first data of data collection in this study
```

We can analyze dates, for example, for how many minutes were data collected? 


```{r}
nz %>%
  select(date)%>%
  summary()

int<-lubridate::interval(ymd("2018-01-02"), ymd("2020-10-06"))

#time in years
time_length(int, "year")

#time in minutes
time_length(int, "minutes")
```




### Create a graph showing the number of responses each day for the years of data collection? 

```{r}
library(lubridate)
library(ggplot2)

datrep <- nz %>%
  count(day = floor_date(date, "day")) %>%
  dplyr::mutate(Year = factor(ifelse(
    day < "2010-01-01",
    2009,
    ifelse(
      day < "2011-01-01",
      2010,
      ifelse(
        day < "2012-01-01",
        2011,
        ifelse(
          day < "2013-01-01",
          2012,
          ifelse(
            day < "2014-01-01",
            2013,
            ifelse(
              day < "2015-01-01",
              2014,
              ifelse(
                day < "2016-01-01",
                2015,
                ifelse(
                  day < "2017-01-01",
                  2016,
                  ifelse(
                    day < "2018-01-01",
                    2017,
                    ifelse(day < "2019-01-01", 2018,
                           ifelse(day < "2020-01-01", 2019, 2020))
                  )
                )
              )
            )
          )
        )
      )
    )
  ))) %>%
  arrange(day)

# create graph
ggplot(datrep, aes(day, n)) +
  geom_col(aes(fill = Year)) + scale_x_date(date_labels = "%b/%Y")  +
  xlab("Days") + ylab("Count of Responses") + ggtitle("Our Dataset's Daily Counts")  + theme_classic()  +  scale_fill_viridis_d()

```

Arrange by date with the most responses

```{r}
datrep%>%
  arrange(desc(n))
```


There are no inherently stressful days. To see this, we can take average stress levels by day, and then see where the high average stress days fall.   

```{r}
tn<-nz %>%
  select(date,KESSLER6sum,Id) %>%
  group_by(date)%>%
  summarise(
   av_distress =  mean(KESSLER6sum, na.rm = TRUE),
   n = n_distinct(Id)
  ) %>%
  arrange(desc(av_distress))
tn
```

We can all graph the densities
```{r}
tn%>%
  ggplot(., aes(date, av_distress)) + 
  geom_col(aes(fill =(n))) + scale_x_date(date_labels = "%b/%Y")  + theme_classic() + scale_fill_viridis_c()
```


Converting dates to days of the week.


```{r}
nz %>%
  select(Id, date, KESSLER6sum) %>%
  mutate(weekdays = wday(date, label = TRUE)) %>%
  group_by(weekdays) %>%
  summarise(
    mn_k6 =  mean(KESSLER6sum, na.rm = TRUE),
    sd_k6 =  sd(KESSLER6sum, na.rm = TRUE),
    n_k6w = n()
  ) %>%
  mutate(
    se_k6 = sd_k6 / sqrt(n_k6w),
    lw_ci = mn_k6 - qt(1 - (0.05 / 2), n_k6w - 1) * se_k6,
    up_ci = mn_k6 + qt(1 - (0.05 / 2), n_k6w - 1) * se_k6
  ) %>%
  ggplot(., aes(x = weekdays, y = mn_k6, colour = mn_k6)) +
  geom_errorbar(aes(ymin = lw_ci, ymax = up_ci), width = .1) +
  geom_point(size = 3)  +
  scale_y_continuous(limits = c(0,7)) + 
  theme_classic() + scale_fill_viridis_d()
```

### `Slice`

Dplyr's slice function can be handy. Say we only want the first six rows

```{r}
datrep%>%
  arrange(desc(n)) %>%
  slice(1:6)
```

Say we only want the 1st row, the 3rd row, and the 20th row

```{r}
datrep%>%
  dplyr::arrange(desc(n)) %>%
  dplyr::slice(c(1,3,20))
```


## Data Summaries

### boxplots
```{r}
boxplot(nz$Age, notch = TRUE)
boxplot(KESSLER6sum ~ Wave, data = nz, notch = TRUE, col = c("cadetblue1","orange"))
nz$KESSLER6sum
```


### R has loads of canned solutions

#### `skimr`

The skimmer package can be helpful in detecting problems. A drawback note that it is interpreting all factors as numbers).

For example, "spiritual identification" was not measured in 2019/2020.

```{r}
library("skimr")

nz %>%
  dplyr::group_by(Wave) %>%
  skim()

```

We can use skimr to find outlier

```{r}
nz %>%
  dplyr::group_by(Wave) %>%
  skim(KESSLER6sum)
```


Try a workflow similar to what we used above

```{r}
nz%>%
  select(date, KESSLER6sum) %>%
  mutate(weekdays = wday(date, label = TRUE)) %>%
  group_by(weekdays) %>%
  skim()
```


### What is the variation in my indicators? 


### Which values are most common (and most rare?)


### shortcuts

```{r}
library("report")
library("dplyr")
head(nz)
nz %>%
  select(-starts_with("Sepal")) %>% 
  group_by(Species) %>% 
  report() %>% 
  summary()
```

