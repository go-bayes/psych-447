---
title: "Consolidation of skills"
description: |
author:
  - name: Joseph Bulbulia
    url: https://josephbulbulia.netlify.app
    affiliation: Victoria University of Wellington
    affiliation_url: https://www.wgtn.ac.nz
    orcid_id: 0000-0002-5861-2056
  - name: Johannes Karl
    url: https://johannes-karl.com
    affiliation: Victoria University of Wellington
    affiliation_url: https://www.wgtn.ac.nz
    orcid_id: 0000-0001-5166-0728
date: 2021-MAR-16
output:
  distill::distill_article:
    self_contained: false
    toc: true
---

```{r spss-old, echo=F}
knitr::include_graphics("op.png")
# let's set our theme too
theme_set(theme_classic())
```

```{r}
#libraries
if (!require(skimr)) install.packages('skimr')
if (!require(lubridate)) install.packages('lubridate')

if (!requireNamespace("devtools")) {
  install.packages("devtools")
}
if (!require(easystats)) devtools::install_github("easystats/easystats")
if (!require(ggthemes)) install.packages('ggthemes')
if (!require(pmdplyr)) install.packages("pmdplyr")

# this should be part of easystats but in case not:
if (!require(report)) install.packages('report')

# load tidyverse
library("tidyverse")
```


```{r echo = FALSE}

nz_0 <- readr::read_csv2(url("https://raw.githubusercontent.com/go-bayes/psych-447/main/data/nz/nz.csv"))

# take all characters and make them factors
# also get rid of duplicate rows
# Note the convention of renaming dataframe when creating a new one:
# ` nz <-nz_0 %>%... `

nz <-nz_0 %>%
  dplyr::mutate_if(is.character, factor) %>%
  select(-c(SWB.Kessler01,SWB.Kessler02,SWB.Kessler03,SWB.Kessler04,SWB.Kessler05,
            SWB.Kessler06))
```

## Preamble

### Assigned reading: workflow Advice: read this

Advice on how to name your files (by Danielle Navarro) [here](https://slides.djnavarro.net/project-structure/#1)

### Something useful

The hash symbol `#` is for commenting

```{r}
r_comments <- 200 # here I am creating the variable for the number of time Jack says R is great

jill_roll <- 199 # here I'm creating a variable for the number of times Jill rolls here eyes

outcome <- log(r_comments) * sqrt(jill_roll) * pi # here I am illustrating some functions in r using the variables I just created

outcome # print outcome

round(outcome, digits = 2) # illustrate the useful `round` function.
```


## Data Carpentry  

### Different ways to select variables

Task: 3 different ways to select the variables that start with `Believe`.

#### Explicit selection

It is generally sensible to select the variables you need.
```{r}
# names(nz) # uncomment the first `#` and run this code to check names
nz %>%
  select("Believe.God", "Believe.Spirit")%>%
  as_tibble()
```


#### `starts_with` 

Sometimes, you know that you want to select all instances of a column that start with a certain name. For this you can use `starts_with`


```{r}
nz %>%
  select(starts_with("Believe"))%>%
  as_tibble()
```


By the same token, `ends_with`

```{r}
nz %>%
  select(ends_with("conditions"))%>%
  as_tibble()
```

#### `contains`

To cast a broader net we can use `contains`:

```{r}
nz %>%
  select(contains("Believe"))%>%
  as_tibble()
```

The net was too broad. We don't want the `Religion.Believe.Cats`. In R, you can hack your way out of this as follows:

```{r}
nz %>%
  select(contains("Believe") &  -  Religion.Believe.Cats)%>%
  as_tibble()
```

However, a better approach would be to drop `contains` and revert to another method. 


### Re-leveling a factor

Let's look at the `BigDoms` variable in this dataset, which corresponds to large religious denominations:

```{r}
nz %>%
  dplyr::select(BigDoms)%>%
  table()
```

Suppose we wanted to make "Not Rel" the base category. We could do so as follows:


```{r}
## suppose we want "Not_Rel" as the base category, and rearrange the other levels
library(forcats) # this is part of the tidyverse package. 
nz %>%
  dplyr::select(BigDoms) %>%
  dplyr::mutate(BigDoms =  
                  forcats::fct_relevel(BigDoms, c("Not_Rel","Christian","Buddhist","Muslim","TheOthers")))%>%
  count(BigDoms) 
```


### Mutate by cutting

```{r}
nz <-nz %>%
  dplyr::mutate(k6cats = cut(
    KESSLER6sum,
    breaks = c(-Inf, 5, 13, Inf),   # create Kessler 6 diagnostic categories
    labels = c("Low Distress", "Moderate Distress", "Serious Distress"), 
    right = TRUE
  ))

```

### Preferable: use `ifelse` to do the same

Personally I find the following method better, because it gives me explicit control of how I am making the categories.

```{r}
nz %>%
  dplyr::mutate(k6cats1 =  as.factor(ifelse(
    KESSLER6sum <= 5,
    "Low Distress",
    ifelse(KESSLER6sum <= 13,  "Moderate Distress", "Serious Distress")
  ))) %>%
  group_by(k6cats1) %>%
  count()

#check this is the same as the previous method
nz %>%
  group_by(k6cats)%>%
  count()
```

### Using logical operators to create factors

### Create a table. 

```{r designtable,  tab.cap="\\label{tab:designtable}"}
library(kableExtra)
nz %>%
  select(k6cats, Wave) %>%
  filter(!is.na(k6cats))%>%
  group_by( Wave, k6cats) %>%
  summarise(n = n())%>%
  kbl(caption = "Distress by Year") %>%
   kable_classic_2(c("striped", "hover"), full_width = TRUE)%>%
  collapse_rows()
```

### Create and work with dates a date

```{r}
nz <- nz %>%
  dplyr::mutate(date = make_date(year = 2009, month = 6, day = 30) + TSCORE)  # first data of data collection in this study
```

We can analyze dates, for example, for how many minutes were data collected? 


```{r}
nz %>%
  select(date)%>%
  summary()

int<-lubridate::interval(ymd("2018-01-02"), ymd("2020-10-06"))

#time in years
time_length(int, "year")

#time in minutes
time_length(int, "minutes")
```




### Create a graph showing the number of responses each day for the years of data collection? 

```{r}
library(lubridate)
library(ggplot2)

datrep <- nz %>%
  count(day = floor_date(date, "day")) %>%
  dplyr::mutate(Year = factor(ifelse(
    day < "2010-01-01",
    2009,
    ifelse(
      day < "2011-01-01",
      2010,
      ifelse(
        day < "2012-01-01",
        2011,
        ifelse(
          day < "2013-01-01",
          2012,
          ifelse(
            day < "2014-01-01",
            2013,
            ifelse(
              day < "2015-01-01",
              2014,
              ifelse(
                day < "2016-01-01",
                2015,
                ifelse(
                  day < "2017-01-01",
                  2016,
                  ifelse(
                    day < "2018-01-01",
                    2017,
                    ifelse(day < "2019-01-01", 2018,
                           ifelse(day < "2020-01-01", 2019, 2020))
                  )
                )
              )
            )
          )
        )
      )
    )
  ))) %>%
  arrange(day)

# create graph
ggplot(datrep, aes(day, n)) +
  geom_col(aes(fill = Year)) + scale_x_date(date_labels = "%b/%Y")  +
  xlab("Days") + ylab("Count of Responses") + ggtitle("Our Dataset's Daily Counts")  + theme_classic()  +  scale_fill_viridis_d()

```

Arrange by date with the most responses

```{r}
datrep%>%
  arrange(desc(n))
```


There are no inherently stressful days. To see this, we can take average stress levels by day, and then see where the high average stress days fall.   

```{r}
tn<-nz %>%
  select(date,KESSLER6sum,Id) %>%
  group_by(date)%>%
  summarise(
   av_distress =  mean(KESSLER6sum, na.rm = TRUE),
   n = n_distinct(Id)
  ) %>%
  arrange(desc(av_distress))
tn
```

We can all graph the densities

```{r}
tn%>%
  ggplot(., aes(date, av_distress)) + 
  geom_col(aes(fill =(n))) + scale_x_date(date_labels = "%b/%Y")  + theme_classic() + scale_fill_viridis_c()
```


Converting dates to days of the week.


```{r}
nz %>%
  select(Id, date, KESSLER6sum) %>%
  mutate(weekdays = wday(date, label = TRUE)) %>%
  group_by(weekdays) %>%
  summarise(
    mn_k6 =  mean(KESSLER6sum, na.rm = TRUE),
    sd_k6 =  sd(KESSLER6sum, na.rm = TRUE),
    n_k6w = n()
  ) %>%
  mutate(
    se_k6 = sd_k6 / sqrt(n_k6w),
    lw_ci = mn_k6 - qt(1 - (0.05 / 2), n_k6w - 1) * se_k6,
    up_ci = mn_k6 + qt(1 - (0.05 / 2), n_k6w - 1) * se_k6
  ) %>%
  ggplot(., aes(x = weekdays, y = mn_k6, colour = mn_k6)) +
  geom_errorbar(aes(ymin = lw_ci, ymax = up_ci), width = .1) +
  geom_point(size = 3)  +
  scale_y_continuous(limits = c(0,7)) + 
  theme_classic() + scale_fill_viridis_d()
```

### `Slice`

Dplyr's slice function can be handy. Say we only want the first six rows

```{r}
datrep%>%
  arrange(desc(n)) %>%
  slice(1:6)
```

Say we only want the 1st row, the 3rd row, and the 20th row

```{r}
datrep%>%
  dplyr::arrange(desc(n)) %>%
  dplyr::slice(c(1,3,20))
```

### Lags and leads using timeseries data


Create a difference variable for change in Kessler 6

```{r}
library("pmdplyr")
df <-nz %>%
   mutate(diff_k6 = KESSLER6sum - tlag(KESSLER6sum,
    .i = Id, # id variable
    .t = Wave # time series variable
  ))%>%
  select(Id,Wave,KESSLER6sum,diff_k6,Emp.JobSecure)%>%
  arrange(desc(diff_k6)) 
head(df)
head(nz)
```


```{r}
df %>%
  filter(diff_k6 > 5) %>%
  ggplot(data = ., aes(x = diff_k6, fill = factor(Emp.JobSecure )) )+
   geom_histogram() + 
  xlab("Difference in K6 eleveation (cases above 5)") + 
  ylab("Counts of cases") + 
  ggtitle("Exploration of relationship between employment insecurity and distress")+
  scale_fill_discrete(name="Employment Security 1-7") + 
  scale_fill_viridis_d() + theme_classic()
```



## Data Summaries

### Bar graphs

```{r}
ggplot(nz) + 
  geom_bar(mapping = aes(x = BigDoms))
```


Note that we can reorder the graph to produce a nicer output


```{r}
ggplot(nz) + 
  geom_bar(mapping = aes(x = fct_infreq(BigDoms))  )
```


### boxplots
```{r}
boxplot(nz$Age, notch = TRUE)
boxplot(KESSLER6sum ~ Wave, data = nz, notch = TRUE, col = c("cadetblue1","orange"))
```


### R has loads of canned solutions

#### `skimr`

The skimmer package can be helpful in detecting problems. A drawback note that it is interpreting all factors as numbers).

For example, "spiritual identification" was not measured in 2019/2020.

```{r}
library("skimr")
nz %>%
  dplyr::group_by(Wave) %>%
  skim()
```

We can use skimr to find outlier

```{r}
nz %>%
  dplyr::group_by(Wave) %>%
  skim(KESSLER6sum)
```


Try a workflow similar to what we used above

```{r}
nz%>%
  select(date, KESSLER6sum) %>%
  mutate(weekdays = wday(date, label = TRUE)) %>%
  group_by(weekdays) %>%
  skim()
```


### What is the variation in my indicators? 


### Which values are most common (and most rare?)


### Packages that create summaries

There are some great packages that automate workflow for you. The following package is called [report]() and it is brought to you from [easystats](https://github.com/easystats/easystats) 



```{r}
library("report")
nz %>%
  group_by(Wave)%>%
  report() %>% 
  summary()
```

