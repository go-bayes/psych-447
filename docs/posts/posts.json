[
  {
    "path": "posts/12_1/",
    "title": "Missing data, measurement error, and the future of probability",
    "description": {},
    "author": [
      {
        "name": "Johannes Karl",
        "url": "https://johannes-karl.com"
      },
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      }
    ],
    "date": "2021-05-25",
    "categories": [],
    "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple-Imputation as a way of handling Missing Data (JB)\nReading for Multiple-Imputation:\nHonaker, King, and Blackwell (2011)\nBhaskaran and Smeeth (2014)\nBlackwell, Honaker, and King (2017)\nMcElreath (2020)\nhttps://gking.harvard.edu/category/research-interests/methods/missing-data\nMissing data poses a problem. Missingness biases inference. However missingness it is not intractable problem if we assume that the mechanism giving rise to the missing data is random conditional on known features of the datset. Statistitians call this assumption “MAR: Missing at Random.”1\nLet us visualise in a subset of the the longitudional NZ dataset\nFirst how many Id’s per wave in this dataset:\n\n\ndf <- nz12 %>%\n  select(\n    Id,\n    CharityDonate,\n    Emp.JobSecure,\n    Male,\n    Employed,\n    Relid,\n    Wave,\n    yearS,\n    KESSLER6sum,\n    Age,\n    yearS\n  )\n\n# always inspect your dataframe\nglimpse(df)\n\n\nRows: 4,140\nColumns: 10\n$ Id            <fct> 15, 15, 15, 15, 15, 15, 15, 15, 15, …\n$ CharityDonate <dbl> 20, 0, 5, 10, 70, 0, 170, 160, 80, 1…\n$ Emp.JobSecure <dbl> 4, 6, 6, NA, 7, 5, NA, 7, NA, 7, NA,…\n$ Male          <fct> Male, Male, Male, Male, Male, Male, …\n$ Employed      <dbl> 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, …\n$ Relid         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, …\n$ Wave          <fct> 2010, 2011, 2012, 2013, 2014, 2015, …\n$ yearS         <dbl> 27, 347, 834, 1200, 1608, 2037, 2336…\n$ KESSLER6sum   <int> 4, 4, 4, 4, 3, 4, 5, 4, 3, 5, 1, 2, …\n$ Age           <dbl> 38.82820, 39.70431, 41.03765, 42.036…\n\n\n\nnz12 %>%\n  group_by(Wave) %>%\n  summarise(Unique_Id = n_distinct(Id))\n\n\n# A tibble: 10 x 2\n   Wave  Unique_Id\n   <fct>     <int>\n 1 2010        414\n 2 2011        414\n 3 2012        414\n 4 2013        414\n 5 2014        414\n 6 2015        414\n 7 2016        414\n 8 2017        414\n 9 2018        414\n10 2019        414\n\nThat’s not many, but the data will be useful to explore the multiple-imputation approach\nWe can visualise the data, using the naniar package\n\n\nlibrary(naniar)\nvis_miss(df)\n\n\n\n\nWe can see substantial missingness for Emp.JobSecure.\nLet’s explore this:\n\n\ndf%>%\n  select(Wave, Emp.JobSecure) %>%\n  group_by(Wave)%>%\n  tally(is.na(Emp.JobSecure))\n\n\n# A tibble: 10 x 2\n   Wave      n\n   <fct> <int>\n 1 2010     89\n 2 2011    106\n 3 2012    118\n 4 2013    117\n 5 2014    129\n 6 2015    133\n 7 2016    414\n 8 2017    167\n 9 2018    172\n10 2019    183\n\nLot’s of missingness in Emp.JobSecure and the question was not included in 2016\n\n\ntable1::table1(~ Wave|Emp.JobSecure, data = df, overall = FALSE)\n\n\n\n1(N=90)\n2(N=96)\n3(N=139)\n4(N=268)\n5(N=403)\n6(N=731)\n7(N=785)\nWave\n\n\n\n\n\n\n\n2010\n12 (13.3%)\n12 (12.5%)\n18 (12.9%)\n31 (11.6%)\n68 (16.9%)\n90 (12.3%)\n94 (12.0%)\n2011\n16 (17.8%)\n14 (14.6%)\n15 (10.8%)\n45 (16.8%)\n43 (10.7%)\n84 (11.5%)\n91 (11.6%)\n2012\n11 (12.2%)\n10 (10.4%)\n17 (12.2%)\n41 (15.3%)\n43 (10.7%)\n86 (11.8%)\n88 (11.2%)\n2013\n11 (12.2%)\n11 (11.5%)\n17 (12.2%)\n35 (13.1%)\n44 (10.9%)\n90 (12.3%)\n89 (11.3%)\n2014\n10 (11.1%)\n10 (10.4%)\n16 (11.5%)\n28 (10.4%)\n40 (9.9%)\n91 (12.4%)\n90 (11.5%)\n2015\n5 (5.6%)\n10 (10.4%)\n18 (12.9%)\n27 (10.1%)\n46 (11.4%)\n78 (10.7%)\n97 (12.4%)\n2016\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n2017\n7 (7.8%)\n9 (9.4%)\n12 (8.6%)\n21 (7.8%)\n46 (11.4%)\n71 (9.7%)\n81 (10.3%)\n2018\n8 (8.9%)\n12 (12.5%)\n13 (9.4%)\n23 (8.6%)\n35 (8.7%)\n73 (10.0%)\n78 (9.9%)\n2019\n10 (11.1%)\n8 (8.3%)\n13 (9.4%)\n17 (6.3%)\n38 (9.4%)\n68 (9.3%)\n77 (9.8%)\n\n\nThere are various methods for multiple imputation. First, let’s look at the Amelia package\n\n\nlibrary(Amelia)\n# set seed\nset.seed(1234)\n\n# we need to pass a dataframe to Amelia\nprep <- as.data.frame(df) # tibble won't run in amelia !!\n\n\n# this is the key code\nprep2 <- Amelia::amelia(\n  prep,\n  #dataset to impute\n  m = 10,\n  # number of imputations\n  cs = c(\"Id\"),\n  # the cross sectional variable\n  ts = c(\"yearS\"),\n  # Time series, allowing polynomials\n  #ords =  none in this dataset, but use this command for ordinal data\n  #logs = ,  # big numbers better to use the natural log\n  sqrt = c(\"KESSLER6sum\", \"CharityDonate\"),\n  # skewed positive data such as K6\n  noms = c(\"Male\",  # nominal vars\n           \"Employed\"),\n  idvars = c(\"Wave\"),\n  # not imputing outcomes\n  polytime = 3\n) #https://stackoverflow.com/questions/56218702/missing-data-warning-r\n\n\n-- Imputation 1 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40\n 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60\n 61 62\n\n-- Imputation 2 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25 26 27 28\n\n-- Imputation 3 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24\n\n-- Imputation 4 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23\n\n-- Imputation 5 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25\n\n-- Imputation 6 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40\n 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60\n 61 62 63 64 65 66 67 68 69 70\n\n-- Imputation 7 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40\n 41 42 43\n\n-- Imputation 8 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n\n-- Imputation 9 --\n\n  1  2  3  4  5\n\n-- Imputation 10 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25 26 27 28 29 30\n\nWe can use trace plots to examine how Amelia imputed and with how much uncertainty:\nHere are the imputations for Job Security (a random selection)\n\n\nAmelia::tscsPlot(\n  prep2,\n  cs = c(\"15\", \"19\", \"20\", \"39\", \"549\", \"1078\"),\n  main = \"Imputation of Job security\",\n  var = \"Emp.JobSecure\",\n  ylim = c(0, 30)\n)\n\n\n\n\nHere are the imputations for Charity (another random selection). Note that there is a fair amount of uncertainty here:\n\n\nAmelia::tscsPlot(\n  prep2,\n  cs = c(\"394\", \"1039\", \"1082\", \"340\", \"365\", \"1149\", \"1238\" , \"1253\",\"1229\"),\n  main = \"Impuatation of Charity\",\n  var = \"CharityDonate\",\n  ylim = c(0, 10000)\n)\n\n\n\n\nWe can center and scale our variables using the following code head(df)\n\n\nprep3 <- Amelia::transform.amelia(\n  prep2,\n  Id = as.factor(Id),\n  # redundant\n  Age.10yrs = (Age / 10),\n  years_s = scale(yearS, center = TRUE, scale = TRUE),\n  years = yearS,\n  KESSLER6sum_S = scale(KESSLER6sum, center = TRUE, scale =TRUE),\n  Employed = factor(Employed),\n  Relid = scale(Relid, scale = TRUE, center = TRUE),\n  Male = as.factor(Male),\n  Emp.JobSecure_S = scale(Emp.JobSecure, center = TRUE, scale = FALSE),\n  CharityDonate = as.integer(CharityDonate)\n)\n\n# center an d scale age\nout <- Amelia::transform.amelia(prep3, Age_in_Decades_C = scale(Age.10yrs,scale =FALSE, center=TRUE))\n\n\n\nWhich variables do we need to include to estimate the causal effect of job security on charity?\nWrite your dag!\n\n\nlibrary(ggdag)\ndg <-\n  dagify(\n    charity ~ jobsecure + employed + age + male + relid + years,\n    jobsecure ~ employed + distress + male + years + age,\n    distress ~ male  + employed + years + age,\n    relid ~ male + years,\n    age ~ years,\n    labels = c(\n      \"charity\" = \"charity\",\n      \"jobsecure\" = \"job security\",\n      \"employed\" = \"employed\",\n      \"age\" = \"age\",\n      \"male\" = \"male\",\n      \"relid\" = \"religious identity\",\n      \"years\" = \"years\"\n    ),\n    exposure = \"jobsecure\",\n    outcome = \"charity\"\n  ) %>%\n  tidy_dagitty(layout = \"nicely\")\n\nggdag::ggdag_adjustment_set(dg)\n\n\n\n\nTo obtain an unbiased estimate of jobsecurity on charity we must condition on employed, male, age, and years.\nWe can write the model using the lme4 package, which is fast. I wrote a little function, recall that we have 8 data sets\n\n\n# first write out the model equation\nlibrary(lme4)\nmod_eq <-  'CharityDonate  ~  Emp.JobSecure_S  + Employed + Age_in_Decades_C +  Male  +  years_s +  (1|Id)' \n\n# run models iterating over imputed data\nloop_glmer_model <-\n  function(x, y) {\n    # x is the mod equation, y is the data\n    m <- 10\n    mod <- NULL\n    for (i in 1:m) {\n      mod[[i]] <- glmer(x, data = y$imputations[[i]], family = \"poisson\")\n    }\n    return(mod)\n  }\n\nm_list <- loop_glmer_model(mod_eq, out)\n\n\n\nHere is a function for obtaining the results:\n\n\n# table of effects\nloop_lmer_model_tab <- function(x) {\n  mp <- lapply(x, model_parameters)\n  out <- parameters::pool_parameters(mp)\n  return(out)\n}\n\n# create table\ntab_impute <- loop_lmer_model_tab(m_list)\ntab_impute\n\n\n# Fixed Effects\n\nParameter         | Coefficient |   SE |         95% CI | Statistic |      p\n----------------------------------------------------------------------------\n(Intercept)       |        6.27 | 0.50 | [ 5.28,  7.26] |     12.42 | < .001\nEmp.JobSecure_S   |        0.03 | 0.03 | [-0.03,  0.08] |      0.95 | 0.342 \nEmployed [1]      |        0.16 | 0.03 | [ 0.09,  0.23] |      4.56 | < .001\nAge_in_Decades_C  |       -4.41 | 1.27 | [-6.90, -1.92] |     -3.47 | < .001\nMale [Not_Male]   |       -1.33 | 0.69 | [-2.69,  0.02] |     -1.92 | 0.054 \nyears_s           |        1.26 | 0.37 | [ 0.53,  1.98] |      3.41 | < .001\nSD (Intercept)    |        6.31 |      |                |           |       \nSD (Observations) |        1.00 |      |                |           |       \n\n\n# create graph\nplot_impute <- plot(tab_impute)\nplot_impute\n\n\n\n\nWe can plot the effects using a coefficient plot\n\n\nlibrary(ggeffects)\nlibrary(gghighlight) # not used here, useful for interactions \ngraph_predictions_imputed <- function(x, y) {\n  # x = model objects\n  m <- 10\n  out <- NULL\n  for (i in 1:m) {\n    out[[i]] <-\n      ggeffects::ggpredict(x[[i]], terms = c(\"Emp.JobSecure_S\"))\n  }\n  plots <- NULL\n  for (i in 1:m) {\n    plots[[i]] <-\n      plot(out[[i]], facets = T) # + scale_y_continuous(limits=c(6.35,6.85) )\n  }\n  plots[[10]] +\n    gghighlight::gghighlight() +\n    ggtitle(y)\n}\n\n# graph\ngraph_predictions_imputed(m_list,\"Effect of Jobsecurity on Charity (not reliable\")\n\n\n\n\nIf you want a LaTeX table, you can use this code:\n\n\nlibrary(huxtable)\n\nhuxtable::as_hux( your_model_here ) %>%\n  select(\"Parameter\", \"Coefficient\", \"CI_low\", \"CI_high\", \"p\") %>%\n  set_number_format(3) %>%\n  set_left_padding(20) %>%\n  set_bold(1, everywhere) %>%\n  quick_latex()\n\n\n\n\nCompare imputation results with row-wise deleted results\nWhen you run a regression with missing data, R automateically deletes the missing cases.\nLet’s look at the results from the row-wise deleted data:\n\n\n# prepare data as we did for the imputated dataset\ndf2 <- df %>%\n  dplyr::mutate(\n    Age.10yrs = (Age / 10),\n    Age_in_Decades_C = scale(Age.10yrs, scale = FALSE, center = TRUE),\n    years_s = scale(yearS, center = TRUE, scale = TRUE),\n    years = yearS,\n    KESSLER6sum_S = scale(KESSLER6sum, center = TRUE, scale = TRUE),\n    Employed = factor(Employed),\n    Relid = scale(Relid, scale = TRUE, center = TRUE),\n    Male = as.factor(Male),\n    Emp.JobSecure_S = scale(Emp.JobSecure, center = TRUE, scale = FALSE)\n  )\n\n# run model\nm_no_impute <- glmer(mod_eq, data = df2, family = \"poisson\")\n\n# create table\ntab_no <-\n  parameters::model_parameters(m_no_impute, effects = c(\"all\"))\ntab_no\n\n\n# Fixed Effects\n\nParameter        |  Log-Mean |       SE |         95% CI |      z |      p\n--------------------------------------------------------------------------\n(Intercept)      |      5.26 |     0.08 | [ 5.09,  5.42] |  62.00 | < .001\nEmp.JobSecure_S  | -5.65e-03 | 5.87e-04 | [-0.01,  0.00] |  -9.61 | < .001\nEmployed [1]     |      0.19 | 6.46e-03 | [ 0.18,  0.20] |  29.18 | < .001\nAge_in_Decades_C |     -0.89 |     0.04 | [-0.96, -0.81] | -21.86 | < .001\nMale [Not_Male]  |     -0.64 |     0.11 | [-0.86, -0.43] |  -5.79 | < .001\nyears_s          |      0.18 |     0.01 | [ 0.16,  0.21] |  15.41 | < .001\n\n# Random Effects\n\nParameter          | Coefficient\n--------------------------------\nSD (Intercept: Id) |        1.00\nSD (Residual)      |        1.00\n\n\n# create graph\nplot_no <- plot(tab_no)\nplot_no\n\n\n\n\nWhen we compare the graphs, we see that the multiply imputed datasets shrink estimates towards zero.\nMultiple imputation is sometimes avoided because people don’t like to “invent” data. However, creating multiply imputed datasets and integrating over their uncertainty during model tends to increase uncertainty in a model. That’s generally a good thing when we want to predict features of the population.\n\n\nlibrary(patchwork)\n\nplot_impute / plot_no +\n  plot_annotation(title = \"Comparison of regressions using (a) multiple-imputed  and (b) row-wise deleted datasets\",\n                  tag_levels = 'a')\n\n\n\n\nHowever it would be a mistake to think that multiple imputation is sufficient. Note that the case-wise deleted data is confident that men give less to charity than do women and other genders. However the model is tending to inflate estimates for men, perhaps because men tend to disproportionately leave this question unanswered. Let’s check this intuition:\n\n\ndf %>%\n  dplyr::mutate(CharityNa = is.na(CharityDonate)) %>%\n  count(Male, CharityNa) %>%\n  group_by(Male) %>%\n  mutate(freq = n / sum(n))\n\n\n# A tibble: 4 x 4\n# Groups:   Male [2]\n  Male     CharityNa     n   freq\n  <fct>    <lgl>     <int>  <dbl>\n1 Male     FALSE      1506 0.972 \n2 Male     TRUE         44 0.0284\n3 Not_Male FALSE      2462 0.951 \n4 Not_Male TRUE        128 0.0494\n\nNo, the intution was wrong. However, it is important to realise that missingness might not be completely at random conditional on variables in the model. In this case, you dataset cannot avoid its biases by multiple imputation.\nRecall that it is generally useful to include more variables for accurate prediction. For this reason, when multiply imputing outcomes it is generally useful to include more variables.\nAppendix 1: Imputation using BRMS\nMultiple imputation in BRMS (warning: these models take 10x longer)\n\n\n# prepare data\n# you must create a list of the imputed datasets, like so:\n\nbrmdat <- list(\n  out$imputations$imp1,\n  \n  out$imputations$imp2,\n  \n  out$imputations$imp3,\n  \n  out$imputations$imp4,\n  \n  out$imputations$imp5,\n  \n  out$imputations$imp6,\n  \n  out$imputations$imp7,\n  \n  out$imputations$imp8,\n  \n  out$imputations$imp9,\n  \n  out$imputations$imp10\n)\n\n\n\nWe write the model as follows:\n\n\n# model equation\n# note the `bf` command\n\nbf_mod_eq <- bf(mod_eq)\n\n# we use the `brm_multiple` syntax and feed in the brmdat\n\nfit_imp1 <-\n  brm_multiple(\n    bf_mod_eq,\n    data = brmdat,\n    family = \"poisson\",\n    file = here::here(\"models\", \"bayes-imp-1\")\n  )\n\n# table\nsummary(fit_imp1)\n\n\n Family: poisson \n  Links: mu = log \nFormula: CharityDonate ~ Emp.JobSecure_S + Employed + Age_in_Decades_C + Male + years_s + (1 | Id) \n   Data: brmdat (Number of observations: 4140) \nSamples: 40 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 40000\n\nGroup-Level Effects: \n~Id (Number of levels: 414) \n              Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(Intercept)     5.40      2.89     1.08     9.93 7.38\n              Bulk_ESS Tail_ESS\nsd(Intercept)       41       47\n\nPopulation-Level Effects: \n                 Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept            7.33      1.83     4.51    11.56 8.47\nEmp.JobSecure_S      0.03      0.02    -0.01     0.06 5.11\nEmployed1            0.16      0.03     0.11     0.20 4.43\nAge_in_Decades_C    -3.14      2.04    -5.65     0.13 5.31\nMaleNot_Male        -0.55      0.87    -2.81     0.56 7.08\nyears_s              0.89      0.59    -0.06     1.62 5.36\n                 Bulk_ESS Tail_ESS\nIntercept              41       40\nEmp.JobSecure_S        42       86\nEmployed1              43       68\nAge_in_Decades_C       42       49\nMaleNot_Male           41       48\nyears_s                42       53\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nplot(fit_imp1)  # VERY POOR MIXING\n\n\n\n\nMixing is a problem, indeed I don’t think I have ever run a model that has mixed worse than this one.\nWe see the trouble in the coefficient plots:\n\n\n#plot posteriors\nplot_bayes_1 <- brms::mcmc_plot(fit_imp1,\n                                type = \"areas\",\n                                prob = .89)\n\nplot_bayes_1 +\n  plot_impute +\n  plot_annotation(title = \"Comparison of regressions using  (a) Bayesian Imputationand and (b) Lmer models\",\n                  tag_levels = 'a')\n\n\n\n\nWe can model missing-ness in BRMS in one step (for continuous missing variables). Let’s try that next:\n\n\n# Emp.JobSecure_S  + Employed + Age_in_Decades_C +  Male  +  years_s\n\n#Note that BRMS can only impute continuous data. That's not a problem. Your factors are converted to integars anyway.\ndf3 <- df2%>%\n  dplyr::mutate(Employed = as.numeric(as.character(Employed)),\n         Male = as.numeric((Male))-1) # male as zero or 1\n\nglimpse(df3)\n\n\nRows: 4,140\nColumns: 16\n$ Id               <fct> 15, 15, 15, 15, 15, 15, 15, 15, 1…\n$ CharityDonate    <dbl> 20, 0, 5, 10, 70, 0, 170, 160, 80…\n$ Emp.JobSecure    <dbl> 4, 6, 6, NA, 7, 5, NA, 7, NA, 7, …\n$ Male             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …\n$ Employed         <dbl> 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, …\n$ Relid            <dbl[,1]> <matrix[20 x 1]>\n$ Wave             <fct> 2010, 2011, 2012, 2013, 2014,…\n$ yearS            <dbl> 27, 347, 834, 1200, 1608, 2037, 2…\n$ KESSLER6sum      <int> 4, 4, 4, 4, 3, 4, 5, 4, 3, 5, 1, …\n$ Age              <dbl> 38.82820, 39.70431, 41.03765, 42.…\n$ Age.10yrs        <dbl> 3.882820, 3.970431, 4.103765, 4.2…\n$ Age_in_Decades_C <dbl[,1]> <matrix[20 x 1]>\n$ years_s          <dbl[,1]> <matrix[20 x 1]>\n$ years            <dbl> 27, 347, 834, 1200, 1608, 2037, 2…\n$ KESSLER6sum_S    <dbl[,1]> <matrix[20 x 1]>\n$ Emp.JobSecure_S  <dbl[,1]> <matrix[20 x 1]>\n\n\n\ndf3%>%\n  dplyr::count(CharityDonate ==0)\n\n\n# A tibble: 3 x 2\n  `CharityDonate == 0`     n\n  <lgl>                <int>\n1 FALSE                 3453\n2 TRUE                   515\n3 NA                     172\n\n\n## Write the model, note the `mi`s: each `mi` needs to appear as the outcome of a model. \n## note that for simplicity, these models claim that mi is random conditional on year and individual. We might obtain better predictions of missingness by including more information. \n\n# Note that brms can only take identity link functions when handling missing data. The \"lognormal\" is better than the normal because the variances are estimated using a log link. \n\nbform <- \n  bf(CharityDonate + 1 | mi() ~ mi(Emp.JobSecure_S) + mi(Employed) + mi(Age_in_Decades_C)  + mi(Male)  + (1 + years_s | Id), family = \"lognormal\") +\n  bf(Emp.JobSecure_S | mi() ~ mi(Employed) + mi(Age_in_Decades_C)  + mi(Male)  + (1 + years_s| Id)) +\n  bf(Employed | mi() ~ (1 + years_s| Id)) +\n  bf(Age_in_Decades_C | mi() ~  (1 + years_s| Id))+\n  bf(Male | mi() ~ (1 + years_s | Id)) +\n  set_rescor(FALSE)\n\n## fit the model \nfit_imp2 <- brm(bform, \n                data = df3, \n                file = here::here(\"models\", \"bayes-imp-2\"))\nsummary(fit_imp2)\n\n\n Family: MV(lognormal, gaussian, gaussian, gaussian, gaussian) \n  Links: mu = identity; sigma = identity\n         mu = identity; sigma = identity\n         mu = identity; sigma = identity\n         mu = identity; sigma = identity\n         mu = identity; sigma = identity \nFormula: CharityDonate + 1 | mi() ~ mi(Emp.JobSecure_S) + mi(Employed) + mi(Age_in_Decades_C) + mi(Male) + (1 + years_s | Id) \n         Emp.JobSecure_S | mi() ~ mi(Employed) + mi(Age_in_Decades_C) + mi(Male) + (1 + years_s | Id) \n         Employed | mi() ~ (1 + years_s | Id) \n         Age_in_Decades_C | mi() ~ (1 + years_s | Id) \n         Male | mi() ~ (1 + years_s | Id) \n   Data: df3 (Number of observations: 4140) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~Id (Number of levels: 414) \n                                                     Estimate\nsd(CharityDonate1_Intercept)                             1.25\nsd(CharityDonate1_years_s)                               0.16\nsd(EmpJobSecureS_Intercept)                              0.35\nsd(EmpJobSecureS_years_s)                                0.17\nsd(Employed_Intercept)                                   0.13\nsd(Employed_years_s)                                     0.04\nsd(AgeinDecadesC_Intercept)                              0.55\nsd(AgeinDecadesC_years_s)                                0.07\nsd(Male_Intercept)                                       0.36\nsd(Male_years_s)                                         0.00\ncor(CharityDonate1_Intercept,CharityDonate1_years_s)    -0.36\ncor(EmpJobSecureS_Intercept,EmpJobSecureS_years_s)       0.25\ncor(Employed_Intercept,Employed_years_s)                 0.15\ncor(AgeinDecadesC_Intercept,AgeinDecadesC_years_s)      -0.30\ncor(Male_Intercept,Male_years_s)                         0.26\n                                                     Est.Error\nsd(CharityDonate1_Intercept)                              0.70\nsd(CharityDonate1_years_s)                                0.19\nsd(EmpJobSecureS_Intercept)                               0.46\nsd(EmpJobSecureS_years_s)                                 0.18\nsd(Employed_Intercept)                                    0.17\nsd(Employed_years_s)                                      0.06\nsd(AgeinDecadesC_Intercept)                               0.32\nsd(AgeinDecadesC_years_s)                                 0.09\nsd(Male_Intercept)                                        0.10\nsd(Male_years_s)                                          0.00\ncor(CharityDonate1_Intercept,CharityDonate1_years_s)      0.56\ncor(EmpJobSecureS_Intercept,EmpJobSecureS_years_s)        0.55\ncor(Employed_Intercept,Employed_years_s)                  0.31\ncor(AgeinDecadesC_Intercept,AgeinDecadesC_years_s)        0.26\ncor(Male_Intercept,Male_years_s)                          0.31\n                                                     l-95% CI\nsd(CharityDonate1_Intercept)                             0.07\nsd(CharityDonate1_years_s)                               0.00\nsd(EmpJobSecureS_Intercept)                              0.00\nsd(EmpJobSecureS_years_s)                                0.01\nsd(Employed_Intercept)                                   0.00\nsd(Employed_years_s)                                     0.00\nsd(AgeinDecadesC_Intercept)                              0.04\nsd(AgeinDecadesC_years_s)                                0.00\nsd(Male_Intercept)                                       0.20\nsd(Male_years_s)                                         0.00\ncor(CharityDonate1_Intercept,CharityDonate1_years_s)    -0.97\ncor(EmpJobSecureS_Intercept,EmpJobSecureS_years_s)      -0.46\ncor(Employed_Intercept,Employed_years_s)                -0.35\ncor(AgeinDecadesC_Intercept,AgeinDecadesC_years_s)      -0.72\ncor(Male_Intercept,Male_years_s)                        -0.22\n                                                     u-95% CI\nsd(CharityDonate1_Intercept)                             1.89\nsd(CharityDonate1_years_s)                               0.47\nsd(EmpJobSecureS_Intercept)                              1.15\nsd(EmpJobSecureS_years_s)                                0.45\nsd(Employed_Intercept)                                   0.41\nsd(Employed_years_s)                                     0.13\nsd(AgeinDecadesC_Intercept)                              0.89\nsd(AgeinDecadesC_years_s)                                0.23\nsd(Male_Intercept)                                       0.45\nsd(Male_years_s)                                         0.00\ncor(CharityDonate1_Intercept,CharityDonate1_years_s)     0.33\ncor(EmpJobSecureS_Intercept,EmpJobSecureS_years_s)       0.97\ncor(Employed_Intercept,Employed_years_s)                 0.47\ncor(AgeinDecadesC_Intercept,AgeinDecadesC_years_s)       0.02\ncor(Male_Intercept,Male_years_s)                         0.65\n                                                     Rhat\nsd(CharityDonate1_Intercept)                         3.31\nsd(CharityDonate1_years_s)                           3.47\nsd(EmpJobSecureS_Intercept)                          3.78\nsd(EmpJobSecureS_years_s)                            3.10\nsd(Employed_Intercept)                               3.01\nsd(Employed_years_s)                                 3.48\nsd(AgeinDecadesC_Intercept)                          3.31\nsd(AgeinDecadesC_years_s)                            2.94\nsd(Male_Intercept)                                   3.57\nsd(Male_years_s)                                     4.27\ncor(CharityDonate1_Intercept,CharityDonate1_years_s) 4.06\ncor(EmpJobSecureS_Intercept,EmpJobSecureS_years_s)   3.44\ncor(Employed_Intercept,Employed_years_s)             3.12\ncor(AgeinDecadesC_Intercept,AgeinDecadesC_years_s)   3.27\ncor(Male_Intercept,Male_years_s)                     3.42\n                                                     Bulk_ESS\nsd(CharityDonate1_Intercept)                                4\nsd(CharityDonate1_years_s)                                  4\nsd(EmpJobSecureS_Intercept)                                 4\nsd(EmpJobSecureS_years_s)                                   5\nsd(Employed_Intercept)                                      5\nsd(Employed_years_s)                                        4\nsd(AgeinDecadesC_Intercept)                                 4\nsd(AgeinDecadesC_years_s)                                   5\nsd(Male_Intercept)                                          4\nsd(Male_years_s)                                            4\ncor(CharityDonate1_Intercept,CharityDonate1_years_s)        4\ncor(EmpJobSecureS_Intercept,EmpJobSecureS_years_s)          4\ncor(Employed_Intercept,Employed_years_s)                    5\ncor(AgeinDecadesC_Intercept,AgeinDecadesC_years_s)          4\ncor(Male_Intercept,Male_years_s)                            4\n                                                     Tail_ESS\nsd(CharityDonate1_Intercept)                               11\nsd(CharityDonate1_years_s)                                 16\nsd(EmpJobSecureS_Intercept)                                11\nsd(EmpJobSecureS_years_s)                                  18\nsd(Employed_Intercept)                                     20\nsd(Employed_years_s)                                       19\nsd(AgeinDecadesC_Intercept)                                15\nsd(AgeinDecadesC_years_s)                                  32\nsd(Male_Intercept)                                         12\nsd(Male_years_s)                                           11\ncor(CharityDonate1_Intercept,CharityDonate1_years_s)       14\ncor(EmpJobSecureS_Intercept,EmpJobSecureS_years_s)         13\ncor(Employed_Intercept,Employed_years_s)                   15\ncor(AgeinDecadesC_Intercept,AgeinDecadesC_years_s)         23\ncor(Male_Intercept,Male_years_s)                           15\n\nPopulation-Level Effects: \n                                  Estimate Est.Error\nCharityDonate1_Intercept              4.46      0.03\nEmpJobSecureS_Intercept               0.11      0.12\nEmployed_Intercept                    0.70      0.01\nAgeinDecadesC_Intercept              -0.02      0.05\nMale_Intercept                        0.63      0.01\nCharityDonate1_miEmp.JobSecure_S      0.01      0.02\nCharityDonate1_miEmployed             0.35      0.10\nCharityDonate1_miAge_in_Decades_C     0.15      0.06\nCharityDonate1_miMale                -0.15      0.13\nEmpJobSecureS_miEmployed              0.08      0.07\nEmpJobSecureS_miAge_in_Decades_C      0.09      0.05\nEmpJobSecureS_miMale                 -0.25      0.13\n                                  l-95% CI u-95% CI Rhat\nCharityDonate1_Intercept              4.43     4.50 3.22\nEmpJobSecureS_Intercept              -0.01     0.29 3.30\nEmployed_Intercept                    0.69     0.72 3.49\nAgeinDecadesC_Intercept              -0.08     0.04 3.30\nMale_Intercept                        0.62     0.65 3.29\nCharityDonate1_miEmp.JobSecure_S     -0.02     0.04 3.90\nCharityDonate1_miEmployed             0.21     0.48 3.34\nCharityDonate1_miAge_in_Decades_C     0.06     0.21 3.01\nCharityDonate1_miMale                -0.30     0.05 3.43\nEmpJobSecureS_miEmployed             -0.03     0.17 3.98\nEmpJobSecureS_miAge_in_Decades_C      0.04     0.17 3.54\nEmpJobSecureS_miMale                 -0.45    -0.10 3.34\n                                  Bulk_ESS Tail_ESS\nCharityDonate1_Intercept                 4       15\nEmpJobSecureS_Intercept                  4       19\nEmployed_Intercept                       4       16\nAgeinDecadesC_Intercept                  4       12\nMale_Intercept                           4       14\nCharityDonate1_miEmp.JobSecure_S         4       12\nCharityDonate1_miEmployed                4       11\nCharityDonate1_miAge_in_Decades_C        5       22\nCharityDonate1_miMale                    4       15\nEmpJobSecureS_miEmployed                 4       12\nEmpJobSecureS_miAge_in_Decades_C         4       15\nEmpJobSecureS_miMale                     4       13\n\nFamily Specific Parameters: \n                     Estimate Est.Error l-95% CI u-95% CI\nsigma_CharityDonate1     1.69      0.45     1.34     2.47\nsigma_EmpJobSecureS      1.43      0.20     1.09     1.63\nsigma_Employed           0.39      0.10     0.21     0.46\nsigma_AgeinDecadesC      0.74      0.60     0.01     1.39\nsigma_Male               0.00      0.00     0.00     0.00\n                     Rhat Bulk_ESS Tail_ESS\nsigma_CharityDonate1 3.45        4       16\nsigma_EmpJobSecureS  3.12        5       11\nsigma_Employed       3.64        4       11\nsigma_AgeinDecadesC  3.09        5       20\nsigma_Male           3.22        4       11\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nAgain, the model is a all over the place:\n\n\nplot(fit_imp2)\n\n\n\n\nMixing was a problem. Minimally we’d need to include more variables. However there might be deeper problems with the data, or our approach. Analysis is iterative. We need to return to the data and scrutinise it more carefully.\n\n\nplot_bayes_2 <- brms::mcmc_plot(fit_imp2,\n                                type = \"areas\",\n                                prob = .89)\n\nplot_bayes_2\n\n\n\n\n# again we run into trouble. \nplot(fit_imp2)\n\n\n\n\nAppendix 2. Probability\nWe have been working with probability throughout this course.\nSuppose there is a test that is 99% accurate at detecting COVID if you have it.\nVery rarely it throws up a false positive,say one in a thousand.\nYou just tested positve. What is the probability that you have COVID? Our intuition is that we probably have COVID. However, let’s assume COVID is rare. Currently in NZ, there are about 50 cases, so 1 in 100,000. The background rate matters.\nBayes rule says\n\\[ Pr(COVID|Positive) = \\frac{Pr(Positive|COVID)\\times Pr (COVID}{Pr(Positive)}\n\\]\nWe plug in the numbers:\n\n\nPr_Positive_COVID <- 0.99\nPr_Positive_Healthy <- 0.01\nPr_COVID <- 0.00001\n\n# Calculate the background probability of testing positive\n\nPr_Positive <- Pr_Positive_COVID * Pr_COVID + Pr_Positive_Healthy * ( 1 - Pr_COVID )\n\n# Now calculated your probability of testing positive\n\nPr_COVID_Positive <- Pr_Positive_COVID * Pr_COVID / (Pr_Positive )\nPr_COVID_Positive # 1 in 1000\n\n\n[1] 0.0009890307\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBhaskaran, Krishnan, and Liam Smeeth. 2014. “What Is the Difference Between Missing Completely at Random and Missing at Random?” International Journal of Epidemiology 43 (4): 1336–39. https://doi.org/10.1093/ije/dyu080.\n\n\nBlackwell, Matthew, James Honaker, and Gary King. 2017. “A Unified Approach to Measurement Error and Missing Data: Overview and Applications.” Sociological Methods and Research 46 (3): 303–41. http://journals.sagepub.com/doi/full/10.1177/0049124115585360.\n\n\nHonaker, James, Gary King, and Matthew Blackwell. 2011. “Amelia II: A Program for Missing Data.” Journal of Statistical Software 45 (7): 1–47. http://www.jstatsoft.org/v45/i07/.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. CRC press.\n\n\nFor a wonderful explanation, see: here↩︎\n",
    "preview": "posts/12_1/distill-preview.png",
    "last_modified": "2021-05-19T02:24:25+12:00",
    "input_file": "lecture_12.knit.md",
    "preview_width": 1200,
    "preview_height": 1500
  },
  {
    "path": "posts/10_1/",
    "title": "Mixed-effects/Multi-level models (continued), with excursion into metanalysis",
    "description": {},
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      }
    ],
    "date": "2021-05-11",
    "categories": [],
    "contents": "\n\nContents\nResources\nObjectives\nTerminological confusions\nMeta-analysis\nModel\nCode for meta-analytic model\nTest hypothesis of a greater than .2 effect size:\nForest plot\n\nGroup varying slopes\nCode for varying intercept/slope model\nJust the syntax please\n\nWithin and between group estimation\nComment on group mean centering: use with caution.\n\n\n\n\nShow code\n\nknitr::include_graphics(\"ml.png\")\n\n\n\n\n\n\nShow code\n\n### Libraries\nlibrary(\"tidyverse\")\nlibrary(\"ggplot2\")\nlibrary(\"patchwork\")\nlibrary(\"lubridate\")\nlibrary(\"kableExtra\")\nlibrary(\"gtsummary\")\nlibrary(\"lubridate\")\nlibrary(\"equatiomatic\")\nlibrary(\"ggdag\")\nlibrary(\"brms\")\nlibrary(\"rstan\")\nlibrary(\"rstanarm\")\nlibrary(\"bayesplot\")\nlibrary(\"easystats\")\nlibrary(\"kableExtra\")\nlibrary(\"broom\")\nlibrary(\"tidybayes\")\nlibrary(\"bmlm\")\nlibrary(\"metafor\")\nlibrary(\"scales\")\nlibrary(\"kableExtra\")\nlibrary(\"knitr\")\nif (!require(metafor)) {\n  install.packages(\"metafor\")\n}\n# rstan options\nrstan_options(auto_write = TRUE)\noptions(mc.cores = parallel::detectCores ())\ntheme_set(theme_classic())\n\n\n\nResources\nThe following is useful tutorial for explaining what multi-level modelling is doing under the hood (only read the first five pages). The tutorial would be especially useful for experimentalists: here: (Sorensen and Vasishth 2015) The published version is less clear, but still useful (Vasishth et al. 2018)\nMatti Vuorre provides and explanation for how to do meta-analysis using the BRMS package here.\nIn my view, the clearest account of multilevel modelling is Richard McElreath’s Statistical Rethinking(McElreath 2020).\nSolomon Kurz’s BRMS companion to Statistical Rethinking is really great, and has lots excellent code for making illuminating graphs: (Kurz 2020)\nThere is no single multi-level model. To understand how model syntax, heat over the GLMM Faq page here; For model specification see especially this\nTo understand how to write multi-level models in BRMS, in addition to the Kurz book, see Paul Bürkner’s tutorial here\nObjectives\nTo unify meta-analysis within the framework of multilevel modeling.\nTo extend multilevel modelling to included group-varying slopes (as well as intercepts).\nTo understand how to interpret results.\nTerminological confusions\nThere is much debate about terminology in multi-level modelling. In the circles I travel, the term “mixed-effects model” is preferred. There’s some discussion about the terminological issues on the GLMMFAQ page here. In part, this is because there are many different multi-level models. In part, the confusion owes to the evolution of nomenclature among different groups. And in part, the confusion owes to people being genuinely confused. Our task here is to walk you through the steps of relatively simple multi-level models; these will be powerful assets to your work. Howeer, we want to do more than to teach you how to write and interpret multilevel models; we want to foster basic intuitions that will help you to understand what these models are doing under the hood.\nRegarding nomenclature, we prefer the terms “group-varying intercept” and “group-varying slope” to the terms “random effect” and “random slope.” The term “random” tends to invite confusion – sampling theory requires “random” draws from various populations, etc. However, when we use the terms “group-varying” it will be important to remember that a “group” can include an individual who has been repeatedly measured over time.\nMeta-analysis\nMatti Vuorre provides an explanation for how to do metanalysis using the BRMS package here. See also, Matti’s brmstools package here. We will follow Matti’s approach.\nThe metafor package has data prepared for meta-analysis. We import the data:\n\n\nShow code\n\n# call data\n# data(\"dat.bangertdrowns2004\", package = \"metafor\")\n# \n# # obtain first 15 studies and rename columns\n# dat <- dat.bangertdrowns2004 %>%\n#   mutate(study = paste0(author, \" (\", year, \")\"), sei = sqrt(vi)) %>%\n#   select(study, yi, sei) \n# \n# # Truncate\n# dat <- dat[,-c(5:10)] %>% as_tibble()\n# \n# # Remove commas in study names\n# dat$study <-\n#   str_replace(dat$study, \",\", \"\")  \n# \n\ndat <- escalc(measure=\"ZCOR\", ri=ri, ni=ni, data=dat.molloy2014)\ndat <- dat[,-c(5:10)] %>% as_tibble()\ndat$yi <- as.numeric(dat$yi)\ndat$vi <- as.numeric(dat$vi)\ndat <- as_tibble(dat)\nnames(dat) <- c(\"study\", \"year\", \"ni\", \"ri\", \"yi\", \"vi\")\ndat$study <- paste0(dat$study, \" (\", dat$year, \")\")\ndat$sei <- as.numeric(sqrt(dat$vi))\ndat$study <- as.character(dat$study)\n# Major pain in reordering\ndat$study[5] <- \"Christensen et al. (1995)\"\ntmp <- dat[5,]\ndat[5,] <- dat[4,]\ndat[4,] <- tmp\n\n\n\nHere, yi is the observed outcome in effect size units, and sei is the observed sampling standard deviation (\\(\\sigma_i\\)). (You can read more about the metafor package here).\nModel\nIn metanalysis we assume:\n\\[y_i \\sim N(\\theta_i, \\sigma_i^2)\\] Where \\(\\theta_i\\) is the unknown true effect-size corresponding to \\(y_i\\), where \\(\\theta\\) has a standard deviation that is equal to the obeserved standard error \\(\\sigma_i\\).\nIn metanalysis, we assume that there is an underlying parameter which identifies the effect size of the hypothetical population of studies from which the sample of studies collected was drawn. Recall, a parameter is an abstract concept – it is the property of population that we never observe. As such,\n\\[\\theta_i \\sim N(\\mu, \\tau^2)\\]\nWhere \\(\\mu\\) is the population average effect size, and \\(\\tau^2\\), the population variance, or between-study heterogeneity.\nWe can write the meta-analytic model as a random intercept model:\n\\[y_i \\sim N(\\mu + \\theta_i, \\sigma_i^2)\\\\\n\\sigma_i \\sim N(0,\\tau^2)\\]\nCode for meta-analytic model\nThe code for a simple meta-analytic model in BRMS is as follows:\n\n\nm_meta <- brm(\n  yi | se(sei) ~ 1 + (1 | study),\n  data = dat,\n  control = list(adapt_delta = .99),\n  file = here::here(\"models\", \"metanalyis\")\n)\n\n\n\n\n\nShow code\n\noptions(width = 120)\n\n# Shows the prior\nsummary(m_meta, prior = TRUE)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: yi | se(sei) ~ 1 + (1 | study) \n   Data: dat (Number of observations: 16) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPriors: \nIntercept ~ student_t(3, 0.2, 2.5)\nsd ~ student_t(3, 0, 2.5)\n\nGroup-Level Effects: \n~study (Number of levels: 16) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.10      0.04     0.04     0.18 1.01     1045     1100\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.15      0.04     0.08     0.22 1.00     1491     2200\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.00      0.00     0.00     0.00 1.00     4000     4000\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nTest hypothesis of a greater than .2 effect size:\nProbably that the effect size is great than .2 is .08 (or 8%)\n\n\nShow code\n\noptions(width = 120)\nhypothesis(m_meta, \"Intercept > 0.2\")\n\n\nHypothesis Tests for class b:\n             Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star\n1 (Intercept)-(0.2) > 0    -0.05      0.04    -0.11     0.01       0.09      0.08     \n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\nForest plot\nThe forest plot graphs the posterior distribution of each estimated \\(\\theta_i\\).\nThe graph shows the meta-analytic effect size \\(\\mu\\) in the bottom row.\nHere is Matti Vuorre’s code for making a graph. Note that Matti indicates the observed effect size with the little ‘o.’ A metanalysis uses partial pooling to shrink estimates towards to the population estimate (\\(\\mu\\)), which is the weighted average of the group means.\n\n\nShow code\n\nlibrary(tidybayes)\nlibrary(ggdist)\n# Study-specific effects are deviations + average\nout_r <- spread_draws(m_meta, r_study[study,term], b_Intercept) %>% \n  mutate(b_Intercept = r_study + b_Intercept) \n# Average effect\nout_f <- spread_draws(m_meta, b_Intercept) %>% \n  mutate(study = \"Average\")\n\nout_f\n\n\n# A tibble: 4,000 x 5\n   .chain .iteration .draw b_Intercept study  \n    <int>      <int> <int>       <dbl> <chr>  \n 1      1          1     1      0.183  Average\n 2      1          2     2      0.182  Average\n 3      1          3     3      0.123  Average\n 4      1          4     4      0.110  Average\n 5      1          5     5      0.0619 Average\n 6      1          6     6      0.0612 Average\n 7      1          7     7      0.0742 Average\n 8      1          8     8      0.0730 Average\n 9      1          9     9      0.115  Average\n10      1         10    10      0.0639 Average\n# … with 3,990 more rows\n\nShow code\n\n# Combine average and study-specific effects' data frames\nout_all <- bind_rows(out_r, out_f) %>% \n  ungroup() %>%\n  # Ensure that Average effect is on the bottom of the forest plot\n  mutate(study = fct_relevel(study, \"Average\")) %>% \n  # tidybayes garbles names so fix here\n  mutate(study = str_replace_all(study, \"\\\\.\", \" \"))\n\n\n# Data frame of summary numbers\nout_all_sum <- group_by(out_all, study) %>% \n  mean_qi(b_Intercept)\n# Draw plot\nout_all %>%   \n  ggplot(aes(b_Intercept, study)) +\n  # Zero!\n  geom_vline(xintercept = 0, size = .25, lty = 2) +\n  stat_halfeye(.width = c(.8, .95), fill = \"dodgerblue\") +\n  # Add text labels\n  geom_text(\n    data = mutate_if(out_all_sum, is.numeric, round, 2),\n    aes(label = str_glue(\"{b_Intercept} [{.lower}, {.upper}]\"), x = 1.75),\n    hjust = \"inward\"\n  ) +\n  # Observed as empty points\n  geom_point(\n    data = dat %>% mutate(study = str_replace_all(study, \"\\\\.\", \" \")), \n    aes(x=yi), position = position_nudge(y = -.2), shape = 1 \n  )\n\n\n\n\nGroup varying slopes\nLast week, we considered how intercepts may vary between groups, and how modelling this variation enables a model to efficiently pool information within and between clusters. In line with this approach, we have just demonstrated how meta-analysis turns on the princible of modelling group-level intercepts. Next we consider how to model variability in slopes of regression coefficients across groups. This model group-varying slopes and intercepts together requires estimating both the slopes and intercepts as drawing from a multivariate distribution in which the two paramters (intercepts and slopes) may be correlated. In a varying intercept/varying slope multi-level model, then, we estimate the covariance of group-level intercepts and group-level slopes in the same model in which we estimate the other parameters (including, of course, the group-level intercept variances and group-level slope variances, else what would there be to co-vary).\n\\[\\begin{pmatrix}\n\\text{variances of the intercepts} &  \\text{co-variances of the intercepts and slopes}   \\\\\n\\text{co-variances of the intercepts and slopes}    &  \\text{variances of the slopes} &\n\\end{pmatrix}\\]\nUsing mathematical notation for the matrix:\n\\[\\begin{pmatrix}\n\\sigma_\\alpha^2 &  \\sigma_\\alpha\\sigma_\\beta \\rho  \\\\\n \\sigma_\\alpha\\sigma_\\beta \\rho  &  \\sigma_\\beta^2 &\n\\end{pmatrix}\\]\nThe varianceses for the intercepts and slopes are along the diagonal, and their co-variances are along the off-diagonal. The co-variances are the products of the standard deviations \\(\\times\\) their correlation\nHere we folllow a simulation from Richard McElreath’s Statistical Rethinking, which simulates a dataset in which the average wait times for a coffee in the morning at a cafe are correlated with the average wait times for a coffee in the afternoon at the same cafe.\nFirst the basic set up of the code:\n\n\na <- 3.5 # average morning wait time\nb <- (-1) # average difference afternoon wait time\nsigma_a <- 1 # std dev in intercepts\nsigma_b <- 0.5 # std dev in slopes\nrho <- (-0.7) #correlation between intercepts and slopes”\n\n# mean \n\nMu <- c( a , b )\n\n# Covariance of a and b\ncov_ab <- sigma_a * sigma_b * rho\n\n# Create a matrix with variances along the diagnols and the covariances on the off diagnols: \n\nSigma <- matrix( c(sigma_a^2,cov_ab,cov_ab,sigma_b^2) , ncol=2 )\n\n\n## Note that we can treat the correlations and the covariances separately, which is useful for assigning priors. We won't need to assign priors today, but it is useful to have the code.\nsigmas <- c(sigma_a,sigma_b) # standard deviations\nRho <- matrix( c(1,rho,rho,1) , nrow=2 ) # correlation matrix\n\n# nmatrix multiply to get covariance matrix -- this is the same Sigma matrix as above:\n\nSigma <- diag(sigmas) %*% Rho %*% diag(sigmas)\n\n\n\nNext we simulate the data\nSimulate cafes and their average properties:\n\n\nShow code\n\nn_cafes <- 20 \n\n# For generating multivariate normal distributions\nlibrary(MASS)\nset.seed(5) # used to replicate example\n\n# Matrix with 20 rows and 2 columns\n\nvary_effects <- mvrnorm( n_cafes , Mu , Sigma )\nhead(vary_effects)\n\n\n         [,1]       [,2]\n[1,] 4.223962 -1.6093565\n[2,] 2.010498 -0.7517704\n[3,] 4.565811 -1.9482646\n[4,] 3.343635 -1.1926539\n[5,] 1.700971 -0.5855618\n[6,] 4.134373 -1.1444539\n\nEach row is a cafe. The first column contains the intercepts and the second column contains the slopes. We can graph the correlation\n\n\nShow code\n\nlibrary(rethinking)\na_cafe <- vary_effects[,1] # intercept\nb_cafe <- vary_effects[,2] # slope\n\n\nplot( a_cafe , \n      b_cafe , \n      col=rangi2 ,\n      xlab= \"intercepts (a_cafe)\" , \n      ylab = \"slopes (b_cafe)\" \n      )\n\n# overlay population distribution\nlibrary(ellipse)\nfor ( l in c(0.1,0.3,0.5,0.8,0.99) )\nlines(\n  ellipse(Sigma,\n              centre = Mu,\n              level=l),\n      col=col.alpha(\"black\",0.2)\n      )\n\n\n\n\nNext we simulate sampling from these cafes\n\n\n\nset.seed(22)\nn_visits <- 10\n\nafternoon <- rep(0:1, n_visits * n_cafes/2)\n\ncafe_id <- rep( 1:n_cafes , each = n_visits )\n\nmu <- a_cafe[cafe_id] + b_cafe[cafe_id] * afternoon\n\nsigma <- 0.5 # std dev within cafes\n\nwait <- rnorm( n_visits * n_cafes , mu , sigma )\n\nd <- data.frame( cafe=cafe_id , afternoon = afternoon , wait = wait )\n\nhead(d)\n\n\n  cafe afternoon     wait\n1    1         0 3.967893\n2    1         1 3.857198\n3    1         0 4.727875\n4    1         1 2.761013\n5    1         0 4.119483\n6    1         1 3.543652\n\nWe can write out the math:\n\\[wait_i \\sim N(\\mu_i, \\sigma) \\\\\n\\mu_i = \\alpha_{\\text{cafe}_i} + \\beta_{\\text{cafe}_i}A_i\\\\\n\\begin{bmatrix}\n\\alpha_{\\text{cafe}} \\\\\n\\beta_{\\text{cafe}} \n\\end{bmatrix}\n\\sim \n\\text{MVNormal} \\begin{pmatrix}\n\\begin{bmatrix}\n\\alpha \\\\\n\\beta \n\\end{bmatrix}\n\\boldsymbol{S},\n\\end{pmatrix} \\\\\n\\boldsymbol{S} = \\begin{pmatrix}\n\\sigma_{\\alpha} & 0  \\\\\n0  &  \\sigma_{\\beta}\\end{pmatrix} \\boldsymbol{R} \\begin{pmatrix}\n\\sigma_{\\alpha} & 0  \\\\\n0  &  \\sigma_{\\beta}\n\\end{pmatrix}\\\\\n\\boldsymbol{R} = \n\\begin{pmatrix}\n1 & \\rho  \\\\\n\\rho &  1\n\\end{pmatrix}\\]\nEach cafe has an intercept \\(\\alpha_i\\) and a slope \\(\\beta_i\\) that samples from a two dimensional Gaussian distribution with means \\(\\alpha\\) and \\(\\beta\\) and a covariance matrix \\(\\boldsymbol{S}\\). The \\(\\boldsymbol{S}\\) matrix factors into the a matrix for the separate standard deviations of \\(\\alpha\\) and \\(\\beta\\), \\(\\sigma_{alpha}\\) and \\(\\sigma_{beta}\\) and the correlation matrix \\(\\boldsymbol{R}\\)\nRecall that we assume our paramters are sampling from distributions. In bayesian estimation we can be explicit about this:\n\\[\n\\alpha \\sim N(5,2) \\\\\n\\beta \\sim N(-1,5) \\\\\n\\sigma \\sim exp(1) \\\\\n\\sigma_a \\sim exp(1) \\\\\n\\sigma_b \\sim exp(1) \\\\\n\\boldsymbol{R} \\sim LKJcorr(1) \\\\\n\\]\nThe LKJcorr prior assumes:\n\\[\\boldsymbol{R}  = \n\\begin{pmatrix}\n1 & \\rho  \\\\\n\\rho  &  1\n\\end{pmatrix}\\]\nHere are some correlations the LKJ distributions\nLJK = 1\n\n\nShow code\n\nR <- rlkjcorr( 1e4 , K=2 , eta=1)\ndens( R[,1,2] , xlab= \"correlation\" )\n\n\n\n\nLJK = 2\n\n\nShow code\n\nR <- rlkjcorr( 1e4 , K=2 , eta=2)\ndens( R[,1,2] , xlab= \"correlation\" )\n\n\n\n\nLJK = 4\n\n\nShow code\n\nlibrary(rethinking)\nR <- rlkjcorr( 1e4 , K=2 , eta=4)\ndens( R[,1,2] , xlab= \"correlation\" )\n\n\n\n\nCode for varying intercept/slope model\nWe can estimate the model (at last):\n\n\nm_vslopes  <-\n  brm(\n    wait ~ 1 + afternoon + (1 + afternoon | cafe),\n    prior = c(\n      prior(normal(5, 2), class = Intercept),\n      prior(normal(-1, 10), class = b),\n      prior(exponential(1), class = sd),\n      prior(exponential(1), class = sigma),\n      prior(lkj(2), class = cor)\n    ),\n    file = here::here(\"models\", \"multi-level-var-slopes\"),\n    data = d,\n    family = gaussian\n  )\n\n\n\n\n\nShow code\n\noptions(width = 120)\n# Shows the prior\nsummary(m_vslopes, prior = TRUE)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: wait ~ 1 + afternoon + (1 + afternoon | cafe) \n   Data: d (Number of observations: 200) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPriors: \nb ~ normal(-1, 10)\nIntercept ~ normal(5, 2)\nL ~ lkj_corr_cholesky(2)\nsd ~ exponential(1)\nsigma ~ exponential(1)\n\nGroup-Level Effects: \n~cafe (Number of levels: 20) \n                         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)                1.00      0.17     0.72     1.37 1.00     1166     1826\nsd(afternoon)                0.36      0.12     0.13     0.60 1.00     1366     1072\ncor(Intercept,afternoon)    -0.48      0.23    -0.84     0.04 1.00     2972     2553\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     3.70      0.23     3.23     4.15 1.00      596     1013\nafternoon    -1.19      0.11    -1.41    -0.97 1.00     2031     2542\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.52      0.03     0.46     0.58 1.00     3389     2711\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nShow code\n\nsjPlot::tab_model(m_vslopes)\n\n\n\n \n\n\nwait\n\n\nPredictors\n\n\nEstimates\n\n\nCI (95%)\n\n\nIntercept\n\n\n3.70\n\n\n3.23 – 4.15\n\n\nafternoon\n\n\n-1.18\n\n\n-1.41 – -0.97\n\n\nRandom Effects\n\n\nσ2\n\n0.27\n\n\nτ00cafe\n\n1.02\n\n\nτ11cafe.afternoon\n\n0.14\n\n\nρ01\n\n \n\n\nρ01\n\n \n\n\nICC\n\n\n0.77\n\n\nN cafe\n\n20\n\n\nObservations\n\n\n200\n\n\nMarginal R2 / Conditional R2\n\n0.254 / 0.810\n\n\n\n\np1 <- brms::mcmc_plot(m_vslopes, \n               type = \"areas\",\n               prob = .89)\np1\n\n\n\n\nCompare to a model with no prior:\n\n\nm_vslopes_np  <-\n  brm(\n    wait ~ 1 + afternoon + (1 + afternoon | cafe),\n    file = here::here(\"models\", \"multi-level-var-slopes-no-prior\"),\n    data = d,\n    family = gaussian\n  )\n\n\n\n\n\nShow code\n\noptions(width = 120)\n# Shows the prior\nsummary(m_vslopes_np, prior = TRUE)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: wait ~ 1 + afternoon + (1 + afternoon | cafe) \n   Data: d (Number of observations: 200) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPriors: \nIntercept ~ student_t(3, 3, 2.5)\nL ~ lkj_corr_cholesky(1)\nsd ~ student_t(3, 0, 2.5)\nsigma ~ student_t(3, 0, 2.5)\n\nGroup-Level Effects: \n~cafe (Number of levels: 20) \n                         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)                1.05      0.20     0.75     1.52 1.00     1004     1757\nsd(afternoon)                0.38      0.13     0.14     0.65 1.00     1192     1507\ncor(Intercept,afternoon)    -0.57      0.23    -0.92    -0.04 1.00     2426     1801\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     3.68      0.24     3.20     4.15 1.01      572      669\nafternoon    -1.18      0.11    -1.40    -0.96 1.00     1657     2478\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.52      0.03     0.47     0.58 1.00     2434     2753\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\np2 <- brms::mcmc_plot(m_vslopes_np, \n               type = \"areas\",\n               prob = .89)\n\n# Comparison graph\np1 + p2 + plot_annotation(title = \"Priors (a) vs Default Priors (b)\", tag_levels = \"a\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJust the syntax please\nSee: glmmFAQ\nE.g. intercept varying among crossed grouping effects (e.g. site, year)\n\n\nlme4::lmer(y ~ intercept + beta1 + beta2  + (1|groupA) + (1|groupB))\n\n\n\nCorrelated intercepts and slopes varying between crossed grouping effects\n\n\nlme4::lmer(y ~ intercept + beta1 + beta2  + (beta1|groupA) + (beta2|groupB))\n\n\n\nRecall that we have the equatiomatic package:\n\n\nShow code\n\nlibrary(lme4)\nlibrary(equatiomatic)\nfm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)\nequatiomatic::extract_eq(fm1)\n\n\n\\[\n\\begin{aligned}\n  \\operatorname{Reaction}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1j[i]}(\\operatorname{Days}), \\sigma^2 \\right) \\\\    \n\\left(\n  \\begin{array}{c} \n    \\begin{aligned}\n      &\\alpha_{j} \\\\\n      &\\beta_{1j}\n    \\end{aligned}\n  \\end{array}\n\\right)\n  &\\sim N \\left(\n\\left(\n  \\begin{array}{c} \n    \\begin{aligned}\n      &\\mu_{\\alpha_{j}} \\\\\n      &\\mu_{\\beta_{1j}}\n    \\end{aligned}\n  \\end{array}\n\\right)\n, \n\\left(\n  \\begin{array}{cc}\n     \\sigma^2_{\\alpha_{j}} & \\rho_{\\alpha_{j}\\beta_{1j}} \\\\ \n     \\rho_{\\beta_{1j}\\alpha_{j}} & \\sigma^2_{\\beta_{1j}}\n  \\end{array}\n\\right)\n \\right)\n    \\text{, for Subject j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\nWithin and between group estimation\nConsider the following example from the parameters package here\nAnd see references on that page.\nWe first simulate data on the relationship between typing speed and typing accuracy.\nBtw, this is an interesting method for simulation, which differs frm the approach above: there is no corrlation of intercept and slope. We can discuss this approach in lab, but I wanted to flag that there are many ways to simulate data.\n\n\nShow code\n\nlibrary(ggplot2)\nlibrary(parameters)\nlibrary(dplyr)\nlibrary(see)\n\nset.seed(123)\nn <- 5\nb <- seq(1, 1.5, length.out = 5)\nx <- seq(2, 2 * n, 2)\n\ndi <- do.call(rbind, lapply(1:n, function(i) {\n  data.frame(\n    x = seq(1, n, by = .2),\n    y = 2 * x[i] + b[i] * seq(1, n, by = .2) + rnorm(21),\n    grp = as.factor(2 * i)\n  )\n}))\n\ndp <- di %>%\n  group_by(grp) %>%\n  mutate(x = rev(15 - (x + 1.5 * as.numeric(grp)))) %>%\n  ungroup()\n\nlabs <- c(\"very slow\", \"slow\", \"average\", \"fast\", \"very fast\")\nlevels(dp$grp) <- rev(labs)\n\n# Within and between group demeaning. \ndp <- cbind(dp, \n           parameters::demean(dp, \n                  c(\"x\", \"y\"),\n                  group = \"grp\")\n           )\n# I center the between group variable to recover an interpretable intercept\n\nd <- dp %>%\n  dplyr::mutate(x_c = scale(x, center = TRUE, scale = FALSE))%>%\n  dplyr::mutate(x_between_c = scale(x_between, center = TRUE, scale = FALSE))  \n\n\n\nGraph the response at the individual level, ignoring group-level structure: typing faster predicts fewer errors:\n\n\nShow code\n\nggplot2::ggplot(data = d,\n                aes(x = x,\n                    y = y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  xlab(\"speed\") +\n  ylab(\"errors\")\n\n\n\n\nHere’s an ordinary linear model\n\n\nShow code\n\nm00 <- lm(y ~ x_c, data = d)\nparameters::model_parameters(m00)\n\n\nParameter   | Coefficient |   SE |         95% CI | t(103) |      p\n-------------------------------------------------------------------\n(Intercept) |       15.82 | 0.44 | [14.95, 16.69] |  36.09 | < .001\nx_c         |       -1.92 | 0.18 | [-2.27, -1.56] | -10.69 | < .001\n\nHowever when we assess the relationship within a group – one model for each group – we see the opposite response\n\n\nShow code\n\nggplot2::ggplot(data = d,\n                aes(x = x,\n                    y = y,\n                    colour = grp)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") \n\n\n\n\nWe can combine the graphs:\n\n\nShow code\n\nggplot2::ggplot(data = d,\n                aes(x = x,\n                    y = y)) +\n  geom_smooth(method = \"lm\") +\n  geom_smooth(aes(x = x,\n                  y = y,\n                  colour = grp),\n              method = \"lm\")  +\n  geom_point(aes(x = x,\n                 y = y,\n                 colour = grp)) + \n  xlab(\"speed\")  + \n  ylab(\"accuracy\") + \n  scale_colour_viridis_d(option=\"magma\") + theme_classic()\n\n\n\n\nWe can use the “demeaned indicators” to produce a model that distinguishes within/beween\n\n\nhead(d)\n\n\n    x        y       grp x_between y_between x_within\n1 8.5 4.439524 very fast      10.5  7.084031     -2.0\n2 8.7 4.969823 very fast      10.5  7.084031     -1.8\n3 8.9 6.958708 very fast      10.5  7.084031     -1.6\n4 9.1 5.670508 very fast      10.5  7.084031     -1.4\n5 9.3 5.929288 very fast      10.5  7.084031     -1.2\n6 9.5 7.715065 very fast      10.5  7.084031     -1.0\n    y_within x_c x_between_c\n1 -2.6445067 1.0           3\n2 -2.1142086 1.2           3\n3 -0.1253227 1.4           3\n4 -1.4135227 1.6           3\n5 -1.1547433 1.8           3\n6  0.6310339 2.0           3\n\nm0 <- lme4::lmer(y ~ x_between_c + x_within + (1|grp), data = d)\n\nparameters::model_parameters(m0)\n\n\n# Fixed Effects\n\nParameter   | Coefficient |   SE |         95% CI | t(100) |      p\n-------------------------------------------------------------------\n(Intercept) |       15.82 | 0.09 | [15.64, 15.99] | 175.85 | < .001\nx_between_c |       -2.93 | 0.04 | [-3.02, -2.85] | -69.22 | < .001\nx_within    |        1.20 | 0.07 | [ 1.06,  1.35] |  16.22 | < .001\n\n# Random Effects\n\nParameter           | Coefficient\n---------------------------------\nSD (Intercept: grp) |        0.00\nSD (Residual)       |        0.96\n\n#equatiomatic::extract_eq(m1)\n\n\n\n\n\nShow code\n\nplot(\n  ggeffects::ggpredict(m0,\n                       terms = c(\"grp\"),\n                       type = \"random\"), \n  add.data = TRUE\n)\n\n\n\n\nWe can estimate whether the within-group speedslopes vary by groups:\n\n\nhead(d)\n\n\n    x        y       grp x_between y_between x_within\n1 8.5 4.439524 very fast      10.5  7.084031     -2.0\n2 8.7 4.969823 very fast      10.5  7.084031     -1.8\n3 8.9 6.958708 very fast      10.5  7.084031     -1.6\n4 9.1 5.670508 very fast      10.5  7.084031     -1.4\n5 9.3 5.929288 very fast      10.5  7.084031     -1.2\n6 9.5 7.715065 very fast      10.5  7.084031     -1.0\n    y_within x_c x_between_c\n1 -2.6445067 1.0           3\n2 -2.1142086 1.2           3\n3 -0.1253227 1.4           3\n4 -1.4135227 1.6           3\n5 -1.1547433 1.8           3\n6  0.6310339 2.0           3\n\nm1 <- brms::brm(y ~ x_between_c + x_within +  (1 + x_within| grp), \n                data = d,\n                file = here::here(\"models\",\"ml_within\"))\n\n\n\n\n\nShow code\n\noptions(width = 120)\n# Shows the prior\nparameters::model_parameters(m1, prior = TRUE, effects = \"all\")\n\n\n# Fixed effects\n\nParameter   | Median |         89% CI |   pd | % in ROPE |  Rhat |    ESS |                            Prior\n------------------------------------------------------------------------------------------------------------\n(Intercept) |  15.81 | [15.59, 16.03] | 100% |        0% | 1.003 | 651.00 | Student_t (df=3) (15.70 +- 8.80)\nx_between_c |  -2.94 | [-3.14, -2.83] | 100% |        0% | 1.048 |  79.00 |                          Uniform\nx_within    |   1.22 | [ 0.99,  1.46] | 100% |     0.40% | 1.009 | 593.00 |                          Uniform\n\n# Fixed effects sigma\n\nParameter | Median |       89% CI |   pd | % in ROPE |  Rhat |    ESS |                        Prior\n----------------------------------------------------------------------------------------------------\nsigma     |   0.92 | [0.82, 1.02] | 100% |        0% | 1.006 | 870.00 | Student_t (df=3) (0 +- 8.80)\n\n# Random effects SD/Cor: grp\n\nParameter            | Median |        89% CI |     pd | % in ROPE |  Rhat |    ESS | Prior\n-------------------------------------------------------------------------------------------\n(Intercept)          |   0.18 | [ 0.00, 0.68] |   100% |    88.25% | 1.092 |  35.00 |      \nx_within             |   0.21 | [ 0.00, 0.46] |   100% |    96.17% | 1.006 | 680.00 |      \nIntercept ~ x_within |  -0.21 | [-1.00, 0.72] | 59.38% |    60.95% | 1.004 | 621.00 |      \n\n\n\ncolor_scheme_set(\"red\")\np_m1 <- bayesplot::mcmc_intervals(m1, \n              regex_pars  = c(\"b_x_between\",\"b_x_within\"))\np_m1\n\n\n\n\nNote that we are adjusting for whether within-group speed differs by group, and if so weather these differences are correlated with the group-level intercepts. My head is exploding here…\nIn any case, graphing these parameters shows nothing is going on, which is to be expected because the simulation did not engineer anything to be going on:\n\n\nShow code\n\nplot(\n  ggeffects::ggpredict(m1, effects= c(\"b_x_between\",\"b_x_within\"),type = \"random\")[[1]], \n  add.data = TRUE\n)\n\n\n\n\n\n\nShow code\n\nplot(\n  ggeffects::ggpredict(m1, effects = c(\"b_x_between\",\"b_x_within\"),type = \"random\")[[2]], \n  add.data = TRUE\n)\n\n\n\n\n\n\ncolor_scheme_set(\"red\")\np_m1 <- bayesplot::mcmc_intervals(m1, \n              regex_pars  = c(\"r_\"))\np_m1\n\n\n\n\nWhat if we were to ignored between and within and between indicators and run an ordinary multi-level model? We would then write:\n\n\n\n# ordinary multi-level model wih group-varying intercept and slope\nm2 <- brms::brm(y ~ x_c +  (1 + x_c| grp), \n                data = d,\n                file = here::here(\"models\",\"ml_no_within\"))\n\n\n\nWhich produces:\n\n\nShow code\n\noptions(width = 120)\n# Shows the prior\nsummary(m2, prior = TRUE)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: y ~ x_c + (1 + x_c | grp) \n   Data: d (Number of observations: 105) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPriors: \nIntercept ~ student_t(3, 15.7, 8)\nL ~ lkj_corr_cholesky(1)\nsd ~ student_t(3, 0, 8)\nsigma ~ student_t(3, 0, 8)\n\nGroup-Level Effects: \n~grp (Number of levels: 5) \n                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)         10.53      3.51     5.87    19.21 1.00     1500     1796\nsd(x_c)                0.34      0.25     0.05     0.91 1.00      900      959\ncor(Intercept,x_c)     0.56      0.37    -0.37     0.99 1.00     2075     2251\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    15.91      4.05     7.95    24.08 1.00     1212     1704\nx_c           1.19      0.20     0.82     1.54 1.00     1714     1519\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.01      0.07     0.87     1.16 1.00     3706     2300\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nNote that the multi-level model pooled information efficiently, and we have reversed the speed\\(\\rightarrow\\)accuracy illusion that the ordinary regression model gave us above.\nPlotting the results tells the story:\n\n\ncolor_scheme_set(\"red\")\np_m2 <- bayesplot::mcmc_intervals(m2, \n              regex_pars  = c(\"r_\",\"b_\"))\np_m2\n\n\n\n\nAlthough the “average” response falls around 15 errors at the centered speed, there’s huge group level variability. In the very fast intercept there are many few errors at this level than there are at the very slow intercept, and we find a gradient in between.\nWe can generate expectation plots for the groups and this tells the story:\n\n\nShow code\n\nlibrary(brms)\nout_f <- conditional_effects(\n  m2,\n  \"x_c\",\n    point_args = list(alpha = 0.1)\n  )[[1]]\nout_r <- conditional_effects(\n  m2,\n  \"x_c\", \n  conditions = distinct(d, grp),\n  re_formula = NULL,\n   points = TRUE,\n  point_args = list(alpha = 0.1)\n  )[[1]]\nout_r %>% \n  ggplot(aes(x_c, estimate__)) +\n  geom_ribbon(\n    data = out_f,\n    aes(ymin = lower__, ymax = upper__),\n    alpha = .1\n  ) +\n  geom_line(data = out_f, size = 2) +\n  geom_line(aes(group = grp), alpha =.5) + \n  xlab(\"speed\") + \n  ylab(\"error\") +\n  ggtitle(\"Typing speed predicts fewer errors but faster typers make fewer errors\")\n\n\n\n\nAnother approach to graphing;\n\n\nShow code\n\n# uncertainty of the posterior distribution\npp <- posterior_predict(m2)\n\n# graph\nplot(\n  ggeffects::ggpredict(m2, , \n                       terms = c(\"x_c\",\"grp\"),\n                       type = \"random\"), \n  add.data = pp\n)\n\n\n\nShow code\n\n\n# this also\nsl <- ggeffects::ggpredict(\n  m2,\n  ,\n  terms = c(\"x_c\", \"grp\"),\n  type = \"random\",\n  add.data = pp\n)\n\nplot(sl, add.data = TRUE, ci = TRUE)\n\n\n\n\nComment on group mean centering: use with caution.\nI’m not sure I’m sold yet on within and between group “demeaning” because it would appear to lose the benefits of pooling and shrinkage that we get from multi-level models (the benefits of “regularisation”). I imagine there will be increasing discussion of this approach in the years ahead. For this reason I thought you should know about it.\nMeantime, some quotations about group-mean centering:\n\nUnfortunately, group mean centering changes the meaning of the entire regression model in a complicated way. If we use grand mean centering, we get different regression slopes for variables that are involved in an interaction, and different variance components, but we have an equivalent model, with identical deviance and residual errors. Another way to describe this situation is to state that we have specified a different parameterization for our model, meaning that we have essentially the same model, but transformed in a way that makes it easier to interpret. Using straightforward algebra, we can transform the grand mean centered estimates back to the values we would have found by analyzing the raw scores. Group mean centering, on the contrary, is not a simple reparameterization of a model, but a completely different model. We will find a different deviance, and transforming the estimated parameters back to the corresponding raw score estimates is not possible. The reason is that we have subtracted not one single value, but a collection of different values from the raw scores.\n\nExcerpt From: Joop J. Hox, Mirjam Moerbeek & Rens van de Schoot. “Multilevel Analysis.” Apple Books.\n\n“Group mean centering of an explanatory variable implies less effective modeling than using raw scores, simply because all information concerning differences between groups is removed from that variable. It would seem reasonable to restore this information by adding the aggregated group mean again as an additional group-level explanatory variable. But this adds extra information about the group structure, which is not present in the raw scores, and therefore we will obtain a model that fits better than the raw score model. If the effect of group mean centering is analyzed in detail, it appears that group mean centering is an implicit, complicated way to change the meaning of individual- and group-level effects, including the interpretation of cross-level interactions. My recommendation is that novice users of multilevel models should apply a great deal of caution in using group mean centering. If the theory behind the modeling strongly suggests ‘frog pond’ or similar effects (see Enders & Tofighi, 2007; Hofmann & Gavin, 1998), group centering is an attractive approach, but the users should be keenly aware of the issues they are facing in interpretation.”\n\nExcerpt From: Joop J. Hox, Mirjam Moerbeek & Rens van de Schoot. “Multilevel Analysis.” Apple Books.\n\n\n\n\n\n\n\n\n\nKurz, A. Solomon. 2020. Zenodo. https://doi.org/10.5281/zenodo.4080013.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. CRC press.\n\n\nSorensen, Tanner, and Shravan Vasishth. 2015. “Bayesian Linear Mixed Models Using Stan: A Tutorial for Psychologists, Linguists, and Cognitive Scientists.” arXiv Preprint arXiv:1506.06201.\n\n\nVasishth, Shravan, Bruno Nicenboim, Mary E Beckman, Fangfang Li, and Eun Jong Kong. 2018. “Bayesian Data Analysis in the Phonetic Sciences: A Tutorial Introduction.” Journal of Phonetics 71: 147–61.\n\n\n\n\n",
    "preview": "posts/10_1/ml.png",
    "last_modified": "2021-05-11T20:39:15+12:00",
    "input_file": {},
    "preview_width": 1200,
    "preview_height": 800
  },
  {
    "path": "posts/11_1/",
    "title": "Causal inference, confounding, and directed acylical graphs (DAGS) ",
    "description": {},
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      }
    ],
    "date": "2021-05-11",
    "categories": [],
    "contents": "\n\nContents\nRequired readings\nObjectives\nWhat is causal inference?\nOmitted variable bias\nDirected Acyclical Graphs\nOmitted variable DAG\n\nMediation and causation\nPipe confounding (full mediation)\nMasked relationships\nCollider Confounding\nCollider bias within experiments\nTaxonomy of confounding\nThe Fork (omitted variable bias)\nThe Pipe (fully mediated effects)\nThe Collider\nThe Descendant\n\nRules for avoiding confounding\nInference depends on assumptions that are not contained in the data.\nMore examples of counfounding/de-confounding\nUnmeasured causes\nWhat is the relationship between smoking and cardiac arrest?\nSelection bias in sampling\nSelection bias in longitudinal research\n\nWorkflow\nSummary\n\n\n\n\nRequired readings\nRequired readings are as follows:\nRohrer (2018) link\nBarrett (2021) link\nMcElreath (2020)link\n\n\nShow code\n\n# packages\n# install_rethinking\n# function for installing dependencies\nipak <- function(pkg){\nnew.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\nif (length(new.pkg)) \n    install.packages(new.pkg, dependencies = TRUE) \nsapply(pkg, require, character.only = TRUE)\n}\n# usage\npackages <- c(\"coda\", \"plyr\", \"mvtnorm\", \"scales\", \"dagitty\")\nipak(packages)\n\n\n   coda    plyr mvtnorm  scales dagitty \n   TRUE    TRUE    TRUE    TRUE    TRUE \n\nShow code\n\n# next install rethinking\nif (!require(rethinking)) {\n  devtools::install_github(\"rmcelreath/rethinking\")\n}\n#next install ggdag\nif (!require(ggdag)) {\n  devtools::install_github(\"malcolmbarrett/ggdag\")\n}\n\n\n# installed from previous lectures\nlibrary(\"tidyverse\")\nlibrary(\"ggdag\")\nlibrary(\"brms\")\nlibrary(\"rstan\")\nlibrary(\"rstanarm\")\nlibrary(\"tidybayes\")\nlibrary(\"bayesplot\")\nlibrary(\"easystats\")\n# rstan options\nrstan_options(auto_write=TRUE)\noptions(mc.cores=parallel::detectCores ())\ntheme_set(theme_classic())\n\n\n\n\n\n\nObjectives\nTo clarify the concepts of causal inference and causal confounding\nTo use these concepts, in combination with the ggdag package, to develop a workflow for causal inference that mitigates the risks of causal confounding. \nWhat is causal inference?\nUp to this point in the course, we have been using regression for prediction, asking:\n\nWhat is the expected change in y conditional on different levels of x?\n\nWhen there are two or more predictors\n\nWhat is the expected change in y conditional on different levels of x1 and x2, and what additional information do we learn from x1 given x2 (and x2, given x1).\n\nPrediction is possible when there are regularities in the world that make y more predictable when we have information about x1 (x2, x3 …).\nPrediction is useful for many practical questions:\n“Which candidate is more likely to win the election?”\n“Are people getting happier as they get older?”\n\"Does having meaning and purpose in life predict lower psychological distress.\nHowever, for the most part, scientists seek causal explanations. The topic of causation is tricky. We will think about causation by thinking about the effects of interventions. What would happen to y if we were to change x1 (or x2)? For example:\nMost theories in psychological science are causal explanations: they make claims about how people think and why they act.\nWhy did those who voted for Barack Obama in 2012 switch party vote for Donald Trump in 2016?\nPolitical psychology differs from polling because political psychology seeks to clarify the operations of the psychological, social, economic, and behavioral mechanisms that underpin voting behaviour, among other questions. To posit that inequality caused change is to imply that if inequality had been different voting behaviour would have been different. Sometimes we can use regression to test such predictions. However, often we can’t. Whether we can or cannot is rarely transparent. Although regression can be useful as a tool for evaluating causal theories, it is a dangerous tool. Think of today’s lecture as a health and saftey induction (so to speak). We will clarify how to use regression as a tool for causal inference while alerting you to common hazards. We will begin on familiar ground.\nOmitted variable bias\nOften when researchers include additional co-variates into their regression into their regression model they are worried about confounding from omitted variable bias. They use the word “control” to indicate that they are addressing this hazard. The case is familiar. X and Y are uncorrelated. However a lurking third variable is responsible for their apparent correlation.\n\n\nlibrary(ggdag)\ntheme_set(theme_dag())\n\n# create confounded triangle\nd1 <- confounder_triangle() %>%\n  ggdag_dconnected()\n\nd1\n\n\n\n\nWe can simulate date that have this causal relationship and ask what would happen were we to regress X on Y without accounting for Z.\n\n\nset.seed(123)\nN <- 100\nz <- rnorm(N)# sim z\nx <- rnorm(N , -z) # sim z -> x\ny <- rnorm(N , z) # sim z -> y\ndf <- data.frame(x, z, y)\n\n# note there is a predictive relationship between X to Y\nplot(x, y)\n\n\n\n\nRegressing X on Y:\n\n\nm0 <- lm(y ~ x, data = df)\nparameters::model_parameters(m0)\n\n\nParameter   | Coefficient |   SE |         95% CI | t(98) |      p\n------------------------------------------------------------------\n(Intercept) |        0.13 | 0.11 | [-0.09,  0.35] |  1.18 | 0.241 \nx           |       -0.40 | 0.08 | [-0.56, -0.23] | -4.85 | < .001\n\nX and Y are correlated. If we know X we can better predict Y. However our ability to predict arises from a process outside of X and Y. Put metaphorically, X “listens to” Z and Y “listens to” Z because Z influences both X and Y. If Z were to change, then so too would X and so too would Y. However X does not cause Y. If we were to intervene in the world and change X this would not change Y. Put yet another way, once we know Z, we do not gain any additional information about Y from X.\nTo understand the implications of information flow with in a regression model we will use directed acylical graphs or DAGS\nDirected Acyclical Graphs\nA directed acyclical graph (DAGS) is heuristic tools for investigating causal inference in a regression model. A DAG is a graph that has nodes and edges. The edges point in the direction of a causal influence. The flows are “acyclical” because a cause is not at the same time an effect. The ggdag package is useful for identifying potential confounding in your dataset and we will rely heavily on that package today.\nWarning: assessing causal inference using a DAG typically requires assumptions that are not part of your dataset. A poorly specified DAG will lead to poor inference. There is no working around this!\nAside\nIn the causal inference literature, we evaluate dependencies using the langauge of “conditional independence.”\nOnce we condition on Z, the link between X and Y is broken.\n\n\n# we can use the language of conditional independence\ng <- dagitty( \"dag{ x <- z -> y }\" )\nimpliedConditionalIndependencies( g )\n\n\nx _||_ y | z\n\nWe can use implied conditional independencies to test whether our DAG is right. For example, if X were to remain reliably predictive of Y, then we would know that the DAG we have drawn here is not correct.\nResume\nMany applied scientists equate omitted variable bias with confounding. For this reason, they seek to “control” for every variable that might be associated with both X and Y. If the relationship between X and Y holds after including such “controls,” many applied scientist will infer that there is a causal relationship between X and Y. We will see that this is not the case; quite the opposite, controlling for many variables is an invitation to confounding, leading to erroneous causal inference. Do not adopt a “causal salad” approach to regression.\n\n“But the approach which dominates in many parts of biology and the social sciences is instead CAUSAL SALAD.36 Causal salad means tossing various “control” variables into a statistical model, observing changes in estimates, and then telling a story about causation. Causal salad seems founded on the notion that only omitted variables can mislead us about causation. But included variables can just as easily confound us. When tossing a causal salad, a model that makes good predictions may still mislead about causation. If we use the model to plan an intervention, it will get everything wrong. Richard McElreath “Statistical Rethinking” Chapter 1, p46.\n\nOmitted variable DAG\nLet’s use ggdag to identify confounding arising from omitting Z in our regression of X on Y.\nFirst we write out the DAG as follows:\n\n\n# code for creating a DAG\nggdag_ov <- dagify(y ~ z,\n                       x ~ z,\n                       exposure = \"x\",\n                       outcome = \"y\") %>%\n  tidy_dagitty(layout = \"tree\")\n\n# plot the DAG\nggdag_ov %>%\n  ggdag()\n\n\n\n\nNext we ask ggdag which variables we need to include if we are to obtain an unbiased estimate of the outcome from the exposure:\n\n\n# use this code\n\nggdag::ggdag_adjustment_set( ggdag_ov )\n\n\n\n\nThe graph tells us to obtain an unbiased estimate of Y on X we must condition on Z.\nAnd indeed, when we included the omitted variable Z in our simulated dateset it breaks the association between X and Y:\n\n\nm1 <- lm(y ~ x + z, data = df)\n\nparameters::model_parameters(m1)\n\n\nParameter   | Coefficient |   SE |        95% CI | t(97) |      p\n-----------------------------------------------------------------\n(Intercept) |        0.14 | 0.10 | [-0.06, 0.33] |  1.40 | 0.163 \nx           |        0.02 | 0.10 | [-0.17, 0.22] |  0.24 | 0.810 \nz           |        0.89 | 0.15 | [ 0.60, 1.18] |  6.03 | < .001\n\nMediation and causation\nSuppose we were interested in the causal effect of X on Y. We have a direct effect of X on Y as well as an indirect effect of X on Y through M. We use ggdag to draw the DAG:\n\n\ndag_1 <- dagify(y ~ x + m,\n                m ~ x,\n                exposure = \"x\",\n                outcome = \"y\") %>%\n  tidy_dagitty(layout = \"tree\")\n\ndag_1 %>%\n  ggdag()\n\n\n\n\nWhat should we condition on if we are interested in the causal effect of changes in X on changes in Y?\nWe can pose the question to ggdag:\n\n\n# ask ggdag which variables to condition on:\n\nggdag::ggdag_adjustment_set(dag_1)\n\n\n\n\n‘Backdoor Paths Unconditionally Closed’ means that, assuming the DAG we have drawn is correct, we may obtain an unbiased estimate of X on Y without including additional variables.\nLater we shall understand why this is the case.1\nFor now, we can enrich our language for causal inference by considering the concept of d-connected and d-separated:\nTwo variables are d-connected if information flows between them (condional on the graph), and they are d-separated if they are conditionally independent of each other.\n\n\n# use this code to examine d-connectedness\nggdag::ggdag_dconnected(dag_1)\n\n\n\n\nIn this case, d-connection is a good thing because we can estimate the causal effect of X on Y. In other cases, d-connection will spoil the model. We have seen this for omitted variable bias. X and Y are d-separated conditional on Z, and that’s our motivation for including Z! These concepts are tricky, but they get easier with practice.\nTo add some grit to our exploration of mediation lets simulate data that are consistent with our mediation DAG\nFirst we ask, is X is related to Y?\n\n\nm2 <- lm(y ~ x_s, data = df2)\nparameters::model_parameters(m2)\n\n\nParameter   | Coefficient |   SE |        95% CI | t(98) |      p\n-----------------------------------------------------------------\n(Intercept) |        0.19 | 0.14 | [-0.08, 0.47] |  1.41 | 0.161 \nx_s         |        1.66 | 0.14 | [ 1.38, 1.93] | 12.00 | < .001\n\nYes.\nNext we ask, Is X related to Y conditional on M?\n\n\nm2 <- lm(y ~ x_s + m_s, data = df2)\nparameters::model_parameters(m2)\n\n\nParameter   | Coefficient |   SE |       95% CI | t(97) |      p\n----------------------------------------------------------------\n(Intercept) |        0.19 | 0.10 | [0.00, 0.38] |  2.04 | 0.044 \nx_s         |        0.77 | 0.13 | [0.51, 1.02] |  6.00 | < .001\nm_s         |        1.33 | 0.13 | [1.07, 1.58] | 10.34 | < .001\n\nYes, but notice this is a different question. The effect of X is attenuated because M contributes to the causal effect of Y.\nA mediation model would tell us the same. Recall from lecture 9 we can write a mediation model as follows:\n\n\npath_m <- brms::bf(m_s ~ x_s)\npath_y <- brms::bf(y ~ x_s + m_s)\n\nm1 <- brms::brm(\n  path_m + path_y + set_rescor(FALSE),\n  data = df2,\n  file = here::here(\"models\", \"mediation-lect11-1\")\n)\n\nparameters::model_parameters(m1)\n\n\n# Fixed effects ms\n\nParameter   |    Median |        89% CI |     pd |  Rhat |     ESS\n------------------------------------------------------------------\n(Intercept) | -6.96e-04 | [-0.12, 0.11] | 50.38% | 1.000 | 6914.00\nx_s         |      0.66 | [ 0.55, 0.79] |   100% | 0.999 | 5725.00\n\n# Fixed effects sigma ms\n\nParameter | Median |       89% CI |   pd |  Rhat |     ESS\n----------------------------------------------------------\nsigma     |   0.76 | [0.66, 0.84] | 100% | 0.999 | 5481.00\n\n# Fixed effects y\n\nParameter   | Median |       89% CI |     pd |  Rhat |     ESS\n--------------------------------------------------------------\n(Intercept) |   0.19 | [0.04, 0.35] | 97.50% | 1.000 | 5588.00\nx_s         |   0.77 | [0.57, 0.98] |   100% | 1.000 | 4211.00\nm_s         |   1.33 | [1.12, 1.53] |   100% | 1.000 | 4144.00\n\n# Fixed effects sigma y\n\nParameter | Median |       89% CI |   pd |  Rhat |     ESS\n----------------------------------------------------------\nsigma     |   0.96 | [0.85, 1.07] | 100% | 1.000 | 5088.00\n\nRecalling:\n\n\nbmlm::mlm_path_plot(xlab = \"Focal\\n(X)\",\n              mlab = \"Mediator\\n(M)\",\n              ylab = \"Outcome\\n(Y)\")\n\n\n\n\nFor a mediation model we may recover the indirect, direct and total effects as follow:\n\n\n# get posterior distributions\npost <- brms::posterior_samples(m1)\n\n# sum and multiply the posterior distributions to obain parameter estimates\npost2 <- post %>% \n  transmute(\n    a = b_ms_x_s ,\n    b = b_y_m_s,\n    cp = b_y_x_s,\n    me = a * b,\n    c = cp + me#,\n   # pme = me / c\n  )\n\n# plot the results\nmcmc_intervals(post2) \n\n\n\n\nSo we can ask how X affects Y in relation to X’s effect on M.\nHowever, to obtain an unbiased causal estimate of X on Y we only needed to include X We didn’t need to condition on M to estimate the causal effect of X.\nPipe confounding (full mediation)\nSuppose we are interested in the effect of x on y, in a scenario when m fully mediates the relationship of x on y.\n\n\nmediation_triangle(\n  x = NULL,\n  y = NULL,\n  m = NULL,\n  x_y_associated = FALSE\n) %>%\n  ggdag()\n\n\n\n\nWhat variables do we need to include to obtain an unbiased estimate of X on Y?\nLet’s fill out this example out by imagining an experiment.\nSuppose we want to know whether a ritual action condition (X) influences charity (Y). We have good reason to assume the effect of X on Y happens entirely through perceived social cohesion (M):\nX\\(\\to\\)M\\(\\to\\)Z or ritual \\(\\to\\) social cohesion \\(\\to\\) charity\nLets simulate some data\n\n\nset.seed(123)\n# Participants\nN <-100\n\n# initial charitable giving\nc0 <- rnorm(N ,10 ,2)\n\n# assign treatments and simulate charitable giving and increase in social cohesion\nritual <- rep( 0:1 , each = N/2 )\ncohesion <- ritual * rnorm(N,.5,.2)\n\n# increase in charity\nc1 <- c0 + ritual * cohesion \n\n# dataframe\nd <- data.frame( c0 = c0 , \n                 c1=c1 , \n                 ritual = ritual , \n                 cohesion = cohesion )\n\n# this code is handy from the rethinking package\nrethinking::precis(d)\n\n\n               mean        sd     5.5%      94.5%\nc0       10.1808118 1.8256318 7.509343 13.0941897\nc1       10.4346925 1.8494557 7.607934 13.3788824\nritual    0.5000000 0.5025189 0.000000  1.0000000\ncohesion  0.2538807 0.2868199 0.000000  0.7038016\n            histogram\nc0         ▁▁▃▃▇▇▃▂▂▁\nc1         ▁▁▂▃▇▇▅▃▂▁\nritual     ▇▁▁▁▁▁▁▁▁▇\ncohesion ▇▁▁▁▂▁▁▁▁▁▁▁\n\nDoes the ritual increase charity?\nIf we only include the ritual condition in the model, we find that ritual condition reliable predicts increases in charitable giving:\n\n\nparameters::model_parameters(\n  lm(c1 ~  c0 + ritual, data = d)\n  )\n\n\nParameter   | Coefficient |       SE |        95% CI |  t(97) |      p\n----------------------------------------------------------------------\n(Intercept) |        0.08 |     0.08 | [-0.07, 0.23] |   1.05 | 0.297 \nc0          |        0.99 | 7.26e-03 | [ 0.98, 1.01] | 136.74 | < .001\nritual      |        0.51 |     0.03 | [ 0.46, 0.56] |  19.33 | < .001\n\nDoes the ritual increase charity adjusting for levels of social cohesion?\n\n\nparameters::model_parameters(\n  lm(c1 ~  c0 + ritual + cohesion, data = d)\n  )\n\n\nParameter   | Coefficient |       SE |         95% CI |    t(96) |      p\n-------------------------------------------------------------------------\n(Intercept) |   -5.68e-15 | 4.21e-16 | [ 0.00,  0.00] |   -13.49 | < .001\nc0          |        1.00 | 4.06e-17 | [ 1.00,  1.00] | 2.46e+16 | < .001\nritual      |    1.78e-16 | 3.23e-16 | [ 0.00,  0.00] |     0.55 | 0.583 \ncohesion    |        1.00 | 5.64e-16 | [ 1.00,  1.00] | 1.77e+15 | < .001\n\nThe answer is that the (direct) effect of ritual entirely drops out when we include both ritual and social cohesion. Why is this? The answer is that once our model knows m it does not obtain any new information by knowing x.\nIf we were interested in assessing x\\(\\to\\)y but x were to effect y through m (i.e x\\(\\to\\)m\\(\\to\\)y) then conditioning on m would block the path from x\\(\\to\\)y. Including m leads to Pipe Confounding.\nIn experiments we should never condition on a post-treatment variable.\nMasked relationships\nImagine two variables were to affect an outcome. Both are correlated with each other. One affects the outcome positively and the other affects the outcome negatively. How shall we investigate the causal role of the focal predictor?\nConsider two correlated variables that jointly predict Political conservatism (C), religion (R). Imagine that one variable has a positive effect and the other has a negative effect on distress (K6).\nFirst consider this relationship, where conservatism causes religion\n\n\ndag_m1 <- dagify(K ~ C + R,\n                 R ~ C,\n                 exposure = \"C\",\n                 outcome = \"K\") %>%\n  tidy_dagitty(layout = \"tree\")\n\n# graph\ndag_m1%>%\n  ggdag()\n\n\n\n\nWe can simulate the data:\n\n\n# C -> K <- R\n# C -> R\nset.seed(123)\nn <- 100\nC <- rnorm( n )\nR <- rnorm( n , C )\nK <- rnorm( n , R - C )\n\nd_sim <- data.frame(K=K,R=R,C=C)\n\n\n\nFirst we only condition on conservatism\n\n\nms1 <- parameters::model_parameters(\n  lm(K  ~ C, data = d_sim)\n)\nplot(ms1)\n\n\n\nms1\n\n\nParameter   | Coefficient |   SE |        95% CI | t(98) |     p\n----------------------------------------------------------------\n(Intercept) |        0.03 | 0.14 | [-0.24, 0.30] |  0.22 | 0.829\nC           |       -0.19 | 0.15 | [-0.49, 0.11] | -1.24 | 0.219\n\nNext, only religion:\n\n\nms2<- parameters::model_parameters(\n  lm(K  ~ R, data = d_sim)\n)\nplot(ms2)\n\n\n\n\nWhen we add both C and R, we see them “pop” in opposite directions, as is typical of masking:\n\n\nms3<- parameters::model_parameters(\n  lm(K  ~ C + R, data = d_sim)\n)\nplot(ms3)\n\n\n\n\nMediation model\n\n\npath_m <- brms::bf(R ~ C)\npath_y <- brms::bf(K ~ C + R)\n\nm2 <- brms::brm(\n  path_m + path_y + set_rescor(FALSE),\n  data = d_sim,\n  file = here::here(\"models\",\"mediation-lect11-2\")\n)\n\nparameters::model_parameters(m2)\n\n\n# Fixed effects K\n\nParameter   | Median |         89% CI |     pd |  Rhat |     ESS\n----------------------------------------------------------------\n(Intercept) |   0.14 | [-0.03,  0.29] | 91.53% | 1.000 | 6798.00\nC           |  -1.16 | [-1.39, -0.93] |   100% | 1.001 | 4115.00\nR           |   1.02 | [ 0.87,  1.18] |   100% | 1.001 | 4091.00\n\n# Fixed effects sigma K\n\nParameter | Median |       89% CI |   pd |  Rhat |     ESS\n----------------------------------------------------------\nsigma     |   0.96 | [0.85, 1.07] | 100% | 1.000 | 5738.00\n\n# Fixed effects R\n\nParameter   | Median |        89% CI |     pd |  Rhat |     ESS\n---------------------------------------------------------------\n(Intercept) |  -0.10 | [-0.26, 0.04] | 85.12% | 0.999 | 6104.00\nC           |   0.95 | [ 0.77, 1.11] |   100% | 0.999 | 5882.00\n\n# Fixed effects sigma R\n\nParameter | Median |       89% CI |   pd |  Rhat |     ESS\n----------------------------------------------------------\nsigma     |   0.98 | [0.87, 1.10] | 100% | 0.999 | 5848.00\n\nRecalling:\n\n\nbmlm::mlm_path_plot(xlab = \"Focal\\n(X)\",\n              mlab = \"Mediator\\n(M)\",\n              ylab = \"Outcome\\n(Y)\")\n\n\n\n\nWe recover the indirect, direct and total effects as follows:\n\n\npost <- brms::posterior_samples(m2)\npost2 <- post %>% \n  transmute(\n    a = b_R_C ,\n    b = b_K_R,\n    cp = b_K_C,\n    me = a * b,\n    c = cp + me #,\n  #  pme = me / c\n  )\nmcmc_intervals(post2)\n\n\n\n\nNote that when you ask ggdag to assess how to obtain an unbiased estimate of C on K it will tell you you don’t need to condition on R.\n\n\ndag_m1%>%\n  ggdag_adjustment_set()\n\n\n\n\nYet recall when we just assessed the relationship of C on K we got this:\n\n\nplot(ms1)\n\n\n\n\nIs the DAG wrong?\nNo. The fact that C\\(\\to\\)R is positive and R\\(\\to\\)K is negative means that if we were to increase C, we wouldn’t reliably increase K. The total effect of C just isn’t reliable!\nCollider Confounding\nThe selection-distortion effect (Berkson’s paradox) (From Statistical Rethinking).\nImagine in science there is no relationship between the newsworthiness of science and its trustworthiness. Imagine further that selection committees make decisions on the basis of the both newsworthiness and the trustworthiness of scientific proposals.\nThis presents us with the following graph\n\n\nShow code\n\ndag_sd <- dagify(S ~ N,\n                 S ~ T,\n                 labels = c(\"S\" = \"Selection\",\n                            \"N\" = \"Newsworthy\",\n                            \"T\" = \"Trustworthy\")) %>%\n  tidy_dagitty(layout = \"nicely\")\n\n# Graph\ndag_sd %>%\n  ggdag(text = FALSE, use_labels = \"label\")\n\n\n\n\nWhen two arrows enter into an variable, it opens a path of information between the two variables.\nVery often this openning of information has disasterous implications. In the human sciences, included variable bias is a woefully underrated problem.\n\n\nShow code\n\nggdag_dseparated(\n  dag_sd,\n  from = \"T\",\n  to = \"N\",\n  controlling_for = \"S\",\n  text = FALSE,\n  use_labels = \"label\"\n)\n\n\n\n\nWe can use the ggdag package to find colliders among our variables:\n\n\n# code for finding colliders\n\nggdag::ggdag_collider(dag_sd,\n                      text = FALSE,\n                      use_labels = \"label\")\n\n\n\n\nThe following simulation (by Solomon Kurz) illustrates the selection-distortion effect, which Richard McElreath discusses in Statistical Rethinking:\nFirst simulated uncorrelated variables and a process of selection for sub-populations score high on both indicators.\n\n\nShow code\n\n# simulate selection distortion effect, following Solomon Kurz\n# https://bookdown.org/content/4857/the-haunted-dag-the-causal-terror.html\nset.seed(123)\nn <- 1000  # number of grant proposals\np <- 0.05  # proportion to select\n\nd <-\n  # uncorrelated newsworthiness and trustworthiness\n  tibble(\n    newsworthiness  = rnorm(n, mean = 0, sd = 1),\n    trustworthiness = rnorm(n, mean = 0, sd = 1)\n  ) %>%\n  # total_score\n  mutate(total_score = newsworthiness + trustworthiness) %>%\n  # select top 10% of combined scores\n  mutate(selected = ifelse(total_score >= quantile(total_score, 1 - p), TRUE, FALSE))\n\n\n\nNext filter out the high scoring examples, and assess their correlation.\nNote that the act of selection induces a correlation within our dataset.\n\n\nd %>% \n  filter(selected == TRUE) %>% \n  select(newsworthiness, trustworthiness) %>% \n  cor()\n\n\n                newsworthiness trustworthiness\nnewsworthiness       1.0000000      -0.7318408\ntrustworthiness     -0.7318408       1.0000000\n\nThis makes it seems as if there is a relationship between Trustworthiness and Newsworthiness in science, even when there isn’t any.\n\n\nShow code\n\n# we'll need this for the annotation\ntext <-\n  tibble(\n    newsworthiness  = c(2, 1),\n    trustworthiness = c(2.25, -2.5),\n    selected        = c(TRUE, FALSE),\n    label           = c(\"selected\", \"rejected\")\n  )\n\nd %>%\n  ggplot(aes(x = newsworthiness, y = trustworthiness, color = selected)) +\n  geom_point(aes(shape = selected), alpha = 3 / 4) +\n  geom_text(data = text,\n            aes(label = label)) +\n  geom_smooth(\n    data = . %>% filter(selected == TRUE),\n    method = \"lm\",\n    fullrange = T,\n    color = \"lightblue\",\n    se = F,\n    size = 1\n  ) +\n  # scale_color_manual(values = c(\"black\", \"lightblue\")) +\n  scale_shape_manual(values = c(1, 19)) +\n  scale_x_continuous(limits = c(-3, 3.9), expand = c(0, 0)) +\n  coord_cartesian(ylim = range(d$trustworthiness)) +\n  theme(legend.position = \"none\") +\n  xlab(\"Newsworthy\") +\n  ylab(\"Trustworthy\")\n\n\n\n\nOnce we know a proposal has been selected, it if is newsworthy we can predict that it is less trustworthy. Our simulation produces this prediction even though we simulated a world in which there is no relationship between trustworthiness and newsworthiness.\nSelection bias is commonplace. Imagine a world in which there is no relationship between merit and one’s tendency to complain about marks. Then imagine a selection process in which people get good marks either from merit or because they complain. What does complaining tell us about the merit of a student?\nCollider bias within experiments\nWe noted that conditioning on a post-treatment variable can induce bias by blocking the path between the experimental manipulation and the outcome. However, such conditioning can open a path even when there is no experimental effect.\n\n\nShow code\n\ndag_ex2 <- dagify(\n  C1 ~ C0 + U,\n  Ch ~ U + R,\n  labels = c(\n    \"R\" = \"Ritual\",\n    \"C1\" = \"Charity-post\",\n    \"C0\" = \"Charity-pre\",\n    \"Ch\" = \"Cohesion\",\n    \"U\" = \"Religiousness (Unmeasured)\"\n  ),\n  exposure = \"R\",\n  outcome = \"C1\",\n  latent = \"U\"\n) %>%\n  control_for(c(\"Ch\",\"C0\"))  \n\ndag_ex2 %>%\n  ggdag( text = FALSE,\n    use_labels = \"label\")\n\n\n\n\nHow do we avoid collider bias here?\nNote what happens if we condition on cohesion?\n\n\ndag_ex2 %>%\n  ggdag_collider(\n    text = FALSE,\n    use_labels = \"label\"\n  )  +\n  ggtitle(\"Cohesion is a collider that opens a path from ritual to charity\")\n\n\n\n\nDon’t condition on a post-treatment variable!\n\n\ndag_ex3 <- dagify(\n  C1 ~ C0,\n  C1 ~ U,\n  Ch ~ U + R,\n  labels = c(\n    \"R\" = \"Ritual\",\n    \"C1\" = \"Charity-post\",\n    \"C0\" = \"Charity-pre\",\n    \"Ch\" = \"Cohesion\",\n    \"U\" = \"Religiousness (Unmeasured)\"\n  ),\n  exposure = \"R\",\n  outcome = \"C1\",\n  latent = \"U\"\n)\nggdag_adjustment_set(dag_ex3)\n\n\n\n\nTaxonomy of confounding\nThere is good news. Ultimately are only four basic types of confounding:\nThe Fork (omitted variable bias)\n\n\nconfounder_triangle(x = \"Coffee\",\n                    y = \"Lung Cancer\",\n                    z = \"Smoking\") %>%\n  ggdag_dconnected(text = FALSE,\n                   use_labels = \"label\")\n\n\n\n\nThe Pipe (fully mediated effects)\n\n\nmediation_triangle(\n  x = NULL,\n  y = NULL,\n  m = NULL,\n  x_y_associated = FALSE\n) %>%\n  tidy_dagitty(layout = \"nicely\") %>%\n  ggdag()\n\n\n\n\nThe Collider\n\n\ncollider_triangle() %>%\n  ggdag_dseparated(controlling_for = \"m\")\n\n\n\n\nThe Descendant\nIf we “control for” a descendant of a collider, we will introduce collider bias.\n\n\ndag_sd <- dagify(\n  Z ~ X,\n  Z ~ Y,\n  D ~ Z,\n  labels = c(\n    \"Z\" = \"Collider\",\n    \"D\" = \"Descendant\",\n    \"X\" = \"X\",\n    \"Y\" = \"Y\"\n  ),\n  exposure = \"X\",\n  outcome = \"Y\"\n) %>%\n  control_for(\"D\") \n\ndag_sd %>%\n  ggdag_dseparated(\n    from = \"X\",\n    to = \"Y\",\n    controlling_for = \"D\",\n    text = FALSE,\n    use_labels = \"label\"\n  )  +\n  ggtitle(\"X --> Y, controlling for D\",\n          subtitle = \"D induces collider bias\")\n\n\n\n\nRules for avoiding confounding\nFrom Statistical Rethinking, p.286\n\nList all of the paths connecting X (the potential cause of interest) and Y (the outcome).\n\n\nClassify each path by whether it is open or closed. A path is open unless it contains a collider.\n\n\nClassify each path by whether it is a backdoor path. A backdoor path has an arrow entering X.\n\n\nIf there are any open backdoor paths, decide which variable(s) to condition on to close it (if possible).\n\nPractically speaking this can be very difficult.We often have many paths to consider:\nBriefly, here is an example from a cross cultural experiment I was part of this year:\n\n\n# Susan's model\n# call ggdag model\n# write relationships:\n\nlibrary(ggdag)\ndg_1 <- ggdag::dagify(\n  b ~  im + ordr + rel + sr  + st,\n  rel ~  age + ses + edu + male + cny,\n  ses ~ cny + edu + age,\n  edu ~ cny + male + age,\n  im ~ mem + rel + cny,\n  mem ~ age + edu + ordr,\n  exposure = \"sr\",\n  outcome = \"b\",\n  labels = c(\n    \"b\" = \"statement credibility\",\n    \"sr\" = \"source\",\n    \"st\" = \"statement\",\n    \"im\" = \"importance\",\n    \"mem\" = \"memory\",\n    \"s\" = \"source\",\n    \"rel\" = \"religious\",\n    \"cny\" = \"country\",\n    \"mem\" = \"memory\",\n    \"male\" = \"male\",\n    \"ordr\" = \"presentation order\",\n    \"ses\" = \"perceived SES\",\n    \"edu\" = \"education\",\n    \"age\" = \"age\"\n  )\n) %>%\n  control_for(\"rel\")\n\n\n\nNote the colliders induced from the “controls” that we had included in the study:\n\n\np3 <- ggdag::ggdag_dseparated(\n  dg_1,\n  from = \"sr\",\n  to = \"b\",\n  controlling_for = c(\"ses\", \"age\", \"cny\", \"im\", \"edu\", \"mem\", \"male\", \"rel\"),\n  text = FALSE,\n  use_labels  = \"label\"\n) +\n  theme_dag_blank() +\n  labs(title = \"Collider Confounding occurs when we `control for` a bunch of variables\")\np3\n\n\n\n\nHow do we fix the problem? Think hard about the causal network and let ggdag do the work.\n\n\n# find adjustment set\np2 <- ggdag::ggdag_adjustment_set(dg_1,\n                                  text = FALSE,\n                                  use_labels  = \"label\") +\n  theme_dag_blank() +\n  labs(title = \"Adjustment set\",\n       subtite = \"Model for Source credibility from belief \")\np2\n\n\n\n\nInference depends on assumptions that are not contained in the data.\n\nregression itself does not provide the evidence you need to justify a causal model. Instead, you need some science.\" – Richard McElreath: “Statistical Rethinking, Chapter 6”\n\n\n“…the data alone can never tell you which causal model is correct”- Richard McElreath: “Statistical Rethinking” Chapter 5\n\n\n“The parameter estimates will always depend upon what you believe about the causal model, because typically several (or very many) causal models are consistent with any one set of parameter estimates.” “Statistical Rethinking” Chapter 5\n\nSuppose we assume that the source condition affects religion, say through priming. We then have the following dag:\n\n\n## adding religion to effect on edu\ndg_3 <- ggdag::dagify(\n  b ~  im + ordr + rel  + st + sr,\n  rel ~  age + ses + edu + male + cny + sr,\n  ses ~ cny + edu + age,\n  edu ~ cny + male + age,\n  im ~ mem + rel + cny,\n  mem ~ age + edu + ordr,\n  exposure = \"rel\",\n  outcome = \"b\",\n  labels = c(\n    \"b\" = \"statement credibility\",\n    \"sr\" = \"source\",\n    \"st\" = \"statement\",\n    \"im\" = \"importance\",\n    \"mem\" = \"memory\",\n    \"s\" = \"source\",\n    \"rel\" = \"religious\",\n    \"cny\" = \"country\",\n    \"mem\" = \"memory\",\n    \"male\" = \"male\",\n    \"ordr\" = \"presentation order\",\n    \"ses\" = \"perceived SES\",\n    \"edu\" = \"education\",\n    \"age\" = \"age\"\n   )\n)%>%\n  control_for(\"rel\")\n\nggdag(dg_3, text = FALSE, use_labels  = \"label\")\n\n\n\n\nWe turn to our trusted oracle, and and ask: “What do we condition on to obtain an unbiased causal estimate?”\nThe oracle replies:\n\n\nggdag::ggdag_adjustment_set(\n  dg_3,\n  exposure = \"sr\",\n  outcome = \"b\",\n  text = FALSE,\n  use_labels  = \"label\"\n) +\n  theme_dag_blank() +\n  labs(title = \"Adjustment set\",\n       subtite = \"Model for Source credibility from belief \")\n\n\n\n\nYour data cannot answer your question.\nMore examples of counfounding/de-confounding\nHere’s another example from recent NZAVS research\n\n\ntidy_ggdag <- dagify(\n  WB ~ belief + age_within + age_between + partner + nzdep + urban + male + pols + empl,\n  WB ~~ partner,\n  belief ~ age_within + age_between + male + ethn,\n  partner ~ nzdep + age_within + age_between + belief, \n  nzdep ~ empl + age_within + age_between,\n  pols ~ age_within + age_between + empl + ethn,\n  empl ~  edu + ethn + age_within + age_between,\n  exposure =  \"belief\",\n  outcome =   \"WB\")%>%\n  tidy_dagitty()\n\n# graph\ntidy_ggdag %>%\n  ggdag()\n\n\n\n\nWe can examine which variables to select, conditional on the causal assumptions of this dag\n\n\n# graph adjustment sets\nggdag::ggdag_adjustment_set(tidy_ggdag, node_size = 14) + \n  theme(legend.position = \"bottom\") + theme_dag_blank()\n\n\n\n\nThis method reveals two adjustments sets: {age, employment, male, political conservativism, and time}, and {age, ethnicty, male, and time.} We report the second set because employment is likely to contain more measurement error: some are not employed because they cannot find employment, others because they are not seeking employment (e.g. retirement).\nUnmeasured causes\nReturn to the previous example of R and C on K6 distress, but imagine an underlying common cause of both C and R (say childhood upbringing) called “U”:\n\n\ndag_m3 <- dagify(\n  K ~ C + R,\n  C ~ U,\n  R ~ U,\n  exposure = \"C\",\n  outcome = \"K\",\n  latent = \"U\"\n) %>%\n  tidy_dagitty(layout = \"nicely\")\n\ndag_m3 %>%\n  ggdag()\n\n\n\n\nHow do we assess the relationship of C on K?\nWe can close the backdoor from U through R by conditioning on R\n\n\nggdag::ggdag_adjustment_set(dag_m3)\n\n\n\n\nAside, we can simulate this relationship using the following code:\n\n\n# C -> K <- R\n# C <- U -> R\nn <- 100\nU <- rnorm( n )\nR <- rnorm( n , U )\nC <- rnorm( n , U )\nK <- rnorm( n , R - C )\nd_sim3 <- data.frame(K = K, R = R, U = U, C = C )\n\n\n\nWhat is the relationship between smoking and cardiac arrest?\nThis example is from the ggdag package, by Malcolm Barrett here\n\n\nsmoking_ca_dag <- dagify(\n  cardiacarrest ~ cholesterol,\n  cholesterol ~ smoking + weight,\n  smoking ~ unhealthy,\n  weight ~ unhealthy,\n  labels = c(\n    \"cardiacarrest\" = \"Cardiac\\n Arrest\",\n    \"smoking\" = \"Smoking\",\n    \"cholesterol\" = \"Cholesterol\",\n    \"unhealthy\" = \"Unhealthy\\n Lifestyle\",\n    \"weight\" = \"Weight\"\n  ),\n  latent = \"unhealthy\",\n  exposure = \"smoking\",\n  outcome = \"cardiacarrest\"\n)\n\nggdag(smoking_ca_dag,\n      text = FALSE,\n      use_labels = \"label\")\n\n\n\n\nWhat do we condition on to close any open backdoor paths, while avoiding colliders? We imagine that unhealthy lifestyle is unmeasured.\n\n\nggdag_adjustment_set(\n  smoking_ca_dag,\n  text = FALSE,\n  use_labels = \"label\",\n  shadow = TRUE\n)\n\n\n\n\nWhat if we control for cholesterol?\n\n\nggdag_dseparated(\n  smoking_ca_dag,\n  controlling_for = c(\"weight\", \"cholesterol\"),\n  text = FALSE,\n  use_labels = \"label\",\n  collider_lines = FALSE\n)\n\n\n\n\n\nControlling for intermediate variables may also induce bias, because it decomposes the total effect of x on y into its parts. (ggdag documentation)\n\nSelection bias in sampling\nThis example is from https://ggdag.malco.io/articles/bias-structures.html\n\nLet’s say we’re doing a case-control study and want to assess the effect of smoking on glioma, a type of brain cancer. We have a group of glioma patients at a hospital and want to compare them to a group of controls, so we pick people in the hospital with a broken bone, since that seems to have nothing to do with brain cancer. However, perhaps there is some unknown confounding between smoking and being in the hospital with a broken bone, like being prone to reckless behavior. In the normal population, there is no causal effect of smoking on glioma, but in our case, we’re selecting on people who have been hospitalized, which opens up a back-door path:\n\n\n\ncoords <- tibble::tribble(\n  ~name,           ~x,  ~y,\n  \"glioma\",         1,   2,\n  \"hospitalized\",   2,   3,\n  \"broken_bone\",    3,   2,\n  \"reckless\",       4,   1,\n  \"smoking\",        5,   2\n)\n\ndagify(hospitalized ~ broken_bone + glioma,\n       broken_bone ~ reckless,\n       smoking ~ reckless,\n       labels = c(hospitalized = \"Hospitalization\",\n                  broken_bone = \"Broken Bone\",\n                  glioma = \"Glioma\",\n                  reckless = \"Reckless \\nBehavior\",\n                  smoking = \"Smoking\"),\n       coords = coords) %>% \n  ggdag_dconnected(\"glioma\", \"smoking\", controlling_for = \"hospitalized\", \n                   text = FALSE, use_labels = \"label\", collider_lines = FALSE)\n\n\n\n\n\nEven though smoking doesn’t actually cause glioma, it will appear as if there is an association. Actually, in this case, it may make smoking appear to be protective against glioma, since controls are more likely to be smokers.\n\nSelection bias in longitudinal research\nSuppose we want to estimate the effect of ethnicity on ecological orientation in a longitudinal dataset where there is selection bias from homeownership (it is easier to reach homeowners by the mail.)\nSuppose the following DAG:\n\n\ndag_sel <- dagify(\n  retained ~ homeowner,\n  homeowner ~ income + ethnicity,\n  ecologicalvalues ~  ethnicity + income,\n  labels = c(\n    retained = \"retained\",\n    homeowner = \"homeowner\",\n    ethnicity = \"ethnicity\",\n    income = \"income\",\n    ecologicalvalues = \"Ecological \\n Orientation\"\n  ),\n  exposure = \"ethnicity\",\n  outcome = \"ecologicalvalues\"\n) %>%\n  control_for(\"retained\")\n\n\ndag_sel %>%\n  ggdag_adjust(\n    \"retained\",\n    layout = \"mds\",\n    text = FALSE,\n    use_labels = \"label\",\n    collider_lines = FALSE\n  )\n\n\n\n\nNotice that “retained” falls downstream from a collider, “home ownership”\n\n\nggdag_collider(dag_sel)\n\n\n\n\nBecause we are stratifying on “retained,” we introduce collider bias in our estimate of ethnicity on ecological values.\n\n\nggdag_dseparated(\n  dag_sel,\n  controlling_for = \"retained\",\n  text = FALSE,\n  use_labels = \"label\",\n  collider_lines = TRUE\n)\n\n\n\n\nHowever we have an adjustment set\n\n\nggdag_adjustment_set(dag_sel)\n\n\n\n\nWorkflow\nImport your data\nCheck that data types are correct\nGraph your data\nConsider your question\nIf causal, draw your DAG/S\nExplain your DAG’s\nWrite your model\nRun your model\nGraph and interpret your results\nReturn to your question, and assess what you have learned.\n(Typically there are multiple iterations between these steps in your workflow. Annotate your scripts; keep track of your decisions; allow GitHub to track changes; embrace uncertainty.)\nSummary\nWe control for variables to avoid omitted variable bias\nOmitted variable bias is real, but also commonplace is included variable bias\nIncluded variable biases arise from “pipes,” “colliders,” and conditioning on descendant of colliders.\nThe ggdag package can help you to obtain causal inference, but it relies on assumptions that are not part of your data.\nClarify your assumption.\n\n\n\nBarrett, Malcolm. 2021. Ggdag: Analyze and Create Elegant Directed Acyclic Graphs. https://CRAN.R-project.org/package=ggdag.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. CRC press.\n\n\nRohrer, Julia M. 2018. “Thinking Clearly about Correlations and Causation: Graphical Causal Models for Observational Data.” Advances in Methods and Practices in Psychological Science 1 (1): 27–42.\n\n\nWe shall see there is no “backdoor path” from X to Y that would bias our estimate, hence the estimate X->Y is an unbiased causal estimate – again, conditional on our DAG.↩︎\n",
    "preview": "posts/11_1/op.png",
    "last_modified": "2021-05-18T18:55:04+12:00",
    "input_file": "lecture_11.knit.md",
    "preview_width": 1920,
    "preview_height": 1920
  },
  {
    "path": "posts/9_1/",
    "title": "Ordinal responses, monotonic predictors, mediation, and group-level intercepts",
    "description": {},
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      }
    ],
    "date": "2021-05-04",
    "categories": [],
    "contents": "\n\nContents\nObjectives\nOrdinal responses\nModel equation for an ordinal response model\nInterpreting results of an ordinal model using graphical methods\n\nOrdinal (or monotonic) predictors\nModel equation for a monotonic predictor model:\n\nDistributional model\nRandom intercept model (clustering)\nModel equation for a random intercept model\n\nRandom intercept: Fatigue\nMultiple response models\nModel equation\n\nMediation\nAssumptions\nSet up\nModel form\nHypothesis\nBonus: Latent Profile Analysis\nLatent Profile Analysis\n\n\n\nShow code\n\n### Libraries\nlibrary(\"tidyverse\")\nlibrary(\"ggplot2\")\nlibrary(\"patchwork\")\nlibrary(\"lubridate\")\nlibrary(\"kableExtra\")\nlibrary(\"gtsummary\")\nlibrary(\"lubridate\")\nlibrary(\"equatiomatic\")\nlibrary(\"ggdag\")\nlibrary(\"brms\")\nlibrary(\"rstan\")\nlibrary(\"rstanarm\")\nlibrary(\"bayesplot\")\nlibrary(\"easystats\")\nlibrary(\"kableExtra\")\nlibrary(\"broom\")\nlibrary(\"tidybayes\")\nlibrary(\"bmlm\")\nif (!require(tidyLPA)) {\n  install.packages(\"tidyLPA\")\n}\n# rstan options\nrstan_options(auto_write = TRUE)\noptions(mc.cores = parallel::detectCores ())\ntheme_set(theme_classic())\n\n\n\nObjectives\nTo develop the following skills:\nmodelling ordinal (cumulative logit) responses\nmodelling ordinal (monotonic) predictors\ndistributional models in which we estimate predictors for the variance as well as for the mean response.\ngroup-level intercept models (aka “random” intercept models).\nmultiple response models estimating multivariate outcomes (i.e. two or more)\nmediation models\ninterpret and report the results for these models using graphical methods.\nOrdinal responses\nAn ordinal model is a cumulative logistic model. Instead of binary outcomes, we assume there are n > 2 outcomes .\n\n\nConsider the HLTH.Fatigue indicator from the NZAVS jitter dataset. The item reads:\n\n“During the past 30 days have you felt fatigue…”\n\nand the responses are:\n\n“None Of The Time,”\n\n\n“A Little Of The Time,”\n\n\n“Some Of The Time,”\n\n\n“Most Of The Time,”\n\n\n“All Of The Time.”\n\nA priori, we might think that Fatigue is better approached as an ordered categorical indicator rather than as a continuous indicator:\n\n\nShow code\n\nhist(nzl$HLTH.Fatigue)\n\n\n\n\nModel equation for an ordinal response model\nWe can write the model equation for an ordinal (or cumulative logistic) model of Fatigue s follows\n\\[\\begin{align}\ny_{i}^c \\sim \\text{Ordered}(p_i) \\\\\n\\text{CumLogit}(\\boldsymbol{p_i}) = \\alpha^c +\\beta X_i \\\\\n\\alpha^c \\sim Normal(0,10)\\\\\n\\boldsymbol{\\beta}\\sim \\text{Normal}(0,1) \n\\end{align}\\]\nFor an ordinal response model, where there are \\(R\\) responses for our outcome indicator, there are \\(C = R-1, c = 1\\dots C\\) thresholds or “cutpoints.”\nAs with binary logistic regression, residuals for cumulative logistic models are not identified, so are fixed to 1. \\(\\alpha^c\\) denotes the \\(c^{th}\\) intercept estimated in the model. Where the lowest response level is modeled as zero, hence four intercepts are estimated. \\(\\mathbf{\\beta}\\) is the esitmate for the\\(X\\) parameter measured on \\(i...N\\) individuals. In this case the time categories of the Covid_Timeline indicator.\n\n\nShow code\n\nm1 <- brm(\n  bf(HLTH.Fatigue_int  ~\n       Covid_Timeline_cr),\n  family = cumulative(link = \"logit\"),\n  data = nz,\n  file = here::here(\"models\", \"ordinal_fatigue\"),\n  silent = FALSE\n)\n\npar_m1 <- parameters::model_parameters(m1)\npar_m1\n\n\n# Fixed effects\n\nParameter                     | Median |         89% CI |     pd | % in ROPE |  Rhat |     ESS\n----------------------------------------------------------------------------------------------\nIntercept[1]                  |  -1.87 | [-1.94, -1.80] |   100% |        0% | 1.000 | 3136.00\nIntercept[2]                  |  -0.07 | [-0.12, -0.02] | 99.00% |    99.98% | 1.000 | 4351.00\nIntercept[3]                  |   1.33 | [ 1.27,  1.39] |   100% |        0% | 1.000 | 4529.00\nIntercept[4]                  |   3.02 | [ 2.91,  3.12] |   100% |        0% | 0.999 | 4437.00\nCovid_Timeline_crJanFeb       |   0.08 | [-0.06,  0.22] | 81.92% |    86.88% | 0.999 | 5554.00\nCovid_Timeline_crEarlyMarch   |   0.04 | [-0.10,  0.19] | 67.50% |    93.50% | 1.000 | 5763.00\nCovid_Timeline_crLockdown     |  -0.26 | [-0.43, -0.08] | 99.12% |    22.82% | 0.999 | 4896.00\nCovid_Timeline_crPostLockdown |  -0.10 | [-0.22,  0.01] | 92.50% |    84.38% | 1.000 | 4559.00\n\nShow code\n\nplot(par_m1)\n\n\n\n\nHre we can see that the log-odds of Fatigue dropped during Lockdown. But how exactly did Fatigue drop?\nAs with logistic regression, the coefficients here are not obvious. To interpret results, we should graph the predicted outcomes at specific values.\nInterpreting results of an ordinal model using graphical methods\nTo understand what is happening, we plot all the individual intercepts by setting categorical = TRUE. Following McElreath’s Statistical Rethinking, we will predict outcomes using the .89 probability credible interval:\n\n\nShow code\n\nplot(\n  conditional_effects(\n    m1,\n    categorical = TRUE,\n    prob = 0.89,\n    re_formula = NA,\n  ),   # WE cannot graph points when the points arg = TRUE\n  points = TRUE,\n  point_args = list(\n    alpha = 0.1,\n    width = .1,\n    size = .2\n  )\n) \n\n\n\n\nHere we see the separation occurring during Lockdown as compared with the baseline PreCOVID\nThis is another method for graphing, where the individual facets denote our expected response thresholds:\n\n\nShow code\n\nplot(ggeffects::ggpredict(\n  m1, \n  effects = \"Covid_Timeline_cr\")\n  )\n\n\n$Covid_Timeline_cr\n\n\nFinally, for the purposes of exploration, we can obtain an average response using the BRMS conditional_effects function, with the setting categorical = FALSE\n\n\nShow code\n\nplot(\n  conditional_effects(\n    m1,\n    categorical = FALSE,\n    prob = 0.89,\n    re_formula = NA,\n  ),\n  points = TRUE,\n  point_args = list(\n    alpha = 0.1,\n    width = .1,\n    size = .2\n  )\n) \n\n\n\n\nOrdinal (or monotonic) predictors\nReference, here (https://psyarxiv.com/9qkhj/) also the BRMS documentation here\n\nA predictor, which we want to model as monotonic (i.e., having a monotonically increasing or decreasing relationship with the response), must either be integer valued or an ordered factor. As opposed to a continuous predictor, predictor categories (or integers) are not assumed to be equidistant with respect to their effect on the response variable. Instead, the distance between adjacent predictor categories (or integers) is estimated from the data and may vary across categories.\n\nModel equation for a monotonic predictor model:\nFor an ordinal predictor model, where there are \\(R\\) indicator responses, there are \\(C = R-1, c = 1\\dots C\\) thresholds to estimate for the the ordered reponses predictors\n\\(b^c\\) locates the direction and size of effect, as with an ordinary regression solution. We consider \\(b^c\\) as the expected average difference between two adjacent categories of the ordinal predictor.\n\\(\\zeta^c\\) locates the normalized distances between consecutive predictor categories, producing the shape of the monotonic effect\n\\[g(y_i) = \\alpha + b^c \\zeta^c \\]\nSuppose we wanted to assess whether fatigue predicts psychological distress. We’ll use a smaller sub-sample of the NZAVS jitter dataset to speed up computing time:\n\n\nShow code\n\n# Create small sample to improve computing time\nsnzl <- nzl %>%\n  dplyr::filter(Wave == 2019) # Only one wave\nset.seed(123)\nnm <-\n  sample(snzl$Id, size = 300) # randomly select a smaller sample of individuals.\nsub_nzl <- snzl %>%\n  filter(Id %in% nm)\n\n\n\nFirst we estimate a model without a monotonic effect:\n\n\n# ordinary predictor\nmo_0 <- brm(\n  bf(KESSLER6sum  ~ HLTH.Fatigue,\n     family = \"poisson\"),\n  data = sub_nzl,\n  file = here::here(\"models\", \"monotonic_0\"),\n  silent = FALSE\n)\n\n# table\npar_mo_0 <-parameters::model_parameters(mo_0)\npar_mo_0\n\n\n# Fixed effects\n\nParameter    | Median |       89% CI |   pd | % in ROPE |  Rhat |     ESS\n-------------------------------------------------------------------------\n(Intercept)  |   0.76 | [0.67, 0.86] | 100% |        0% | 1.001 | 1640.00\nHLTH.Fatigue |   0.45 | [0.42, 0.49] | 100% |        0% | 1.000 | 1895.00\n\n\n# coefficient plot\nplot(par_mo_0) + labs(title = \"Distress on Fatigue, no monotonic effects\")\n\n\n\n\nThe expected increase in distress from a one unit increase in Fatigue is .45 units of Kessler 6 distress on the log scale.\nTo translate this expectation to the data scale recall that we must exponentiate our result.\nA one unit change in fatigue at the intercept leads to an expected change in distress of:\n\n\nShow code\n\nexp(.75 + .45)\n\n\n[1] 3.320117\n\nWe plot the entire range of the response scale:\n\n\nShow code\n\np_mo_0 <- plot(\n  conditional_effects(mo_0),\n  points = TRUE,\n  point_args = list(alpha = 0.1,\n                    width = .2), \n  ask = FALSE\n)[[1]]\n\n\n\n\nWe next model the relationship of Fatigue on Distress by thinking of Fatigue as as a monotonic predictor, using the mo command, as follows:\n\n\nmo_1 <- brm(\n  bf(KESSLER6sum  ~ mo(HLTH.Fatigue),\n     family = \"poisson\"),\n  data = sub_nzl,\n  file = here::here(\"models\", \"monotonic_1\")\n)\n\n# table\npar_mo_1 <-parameters::model_parameters(mo_1)\npar_mo_1\n\n\n# Fixed effects\n\nParameter      | Median |       89% CI |   pd | % in ROPE |  Rhat |     ESS\n---------------------------------------------------------------------------\n(Intercept)    |   0.84 | [0.67, 1.01] | 100% |        0% | 1.004 | 1179.00\nmoHLTH.Fatigue |   0.44 | [0.38, 0.49] | 100% |        0% | 1.004 | 1253.00\n\n# Fixed effects (monotonic effects)\n\nParameter        | Median |       89% CI |   pd | % in ROPE |  Rhat |     ESS\n-----------------------------------------------------------------------------\nHLTH.Fatigue1[1] |   0.19 | [0.09, 0.28] | 100% |     7.90% | 1.003 | 1248.00\nHLTH.Fatigue1[2] |   0.29 | [0.21, 0.36] | 100% |        0% | 1.002 | 1691.00\nHLTH.Fatigue1[3] |   0.24 | [0.17, 0.31] | 100% |     0.03% | 1.000 | 2338.00\nHLTH.Fatigue1[4] |   0.28 | [0.20, 0.35] | 100% |        0% | 1.001 | 2441.00\n\n\n# coefficient plot\nplot(par_mo_1) + labs(title = \"Distress on Fatigue, monotonic effects\") \n\n\n\n\nNote that we have 4 x betas for Fatigue. What do these mean?\nGraphing the results:\n\n\nShow code\n\np_mo_1 <- plot(\n  conditional_effects(mo_1),\n  points = TRUE,\n  point_args = list(alpha = 0.1,\n                    width = .2)\n)[[1]] \n\n\n\n\nThe monotonic predictor, here, doesn’t look to make all that much a difference.\nWe can formally compare the two models:\n\n\nShow code\n\ncompare_mo_0 <- add_criterion(mo_0, \"loo\")\ncompare_mo_1 <- add_criterion(mo_1, \"loo\")\n\ncompare_mo <-\n  loo_compare(compare_mo_0, compare_mo_1, criterion = \"loo\")\ncompare_mo\n\n\n             elpd_diff se_diff\ncompare_mo_0  0.0       0.0   \ncompare_mo_1 -4.1       1.7   \n\nNo real difference.\nAnd can visually inspect the posterior predictions, and they not look too different:\nWithout monotonic predictors\n\n\nShow code\n\nbrms::pp_check(mo_0)\n\n\n\n\nWith monotonic predictors\n\n\nShow code\n\nbrms::pp_check(mo_1)\n\n\n\n\nAgain, no real difference. However, our model isn’t fitting well. What would you do to improve the model fit?\nThere are no default strategies. Modelling requires a combination of reasoning and art.\nDistributional model\nA distributional model predicts the variance as well as the mean of a response.\nPaul Bruckner, the author of the BRMS package, offers the following simulated data for a distributional model (see the explanation {here](https://cran.r-project.org/web/packages/brms/vignettes/brms_distreg.html))\n\n\ngroup <- rep(c(\"treat\", \"placebo\"), each = 30)\nsymptom_post <-\n  c(rnorm(30, mean = 1, sd = 2), rnorm(30, mean = 0, sd = 1))\ndat1 <- data.frame(group, symptom_post)\nhead(dat1)\n\n\n  group symptom_post\n1 treat    -5.621357\n2 treat     2.076932\n3 treat     2.784972\n4 treat     1.978924\n5 treat    -1.392703\n6 treat     1.925476\n\nFitting the model we have:\n\n\nfit1 <- brm(bf(symptom_post ~ group,\n               sigma ~ group),\n            data = dat1,\n            file = here::here(\"models\", \"distributional\"),\n            family = gaussian())\n\npar_fit1 <-parameters::model_parameters(fit1)\npar_fit1\n\n\n# Fixed effects\n\nParameter        | Median |         89% CI |     pd | % in ROPE |  Rhat |     ESS\n---------------------------------------------------------------------------------\n(Intercept)      |  -0.21 | [-0.38, -0.03] | 96.97% |    35.80% | 1.000 | 4801.00\nsigma_Intercept  |  -0.51 | [-0.72, -0.31] |   100% |     0.73% | 1.000 | 2927.00\ngrouptreat       |   1.50 | [ 0.88,  2.12] | 99.98% |     0.07% | 1.000 | 2219.00\nsigma_grouptreat |   1.21 | [ 0.91,  1.49] |   100% |        0% | 1.000 | 2844.00\n\n# Fixed effects sigma\n\nParameter        | Median |         89% CI |   pd | % in ROPE |  Rhat |     ESS\n-------------------------------------------------------------------------------\nsigma_Intercept  |  -0.51 | [-0.72, -0.31] | 100% |     0.73% | 1.000 | 2927.00\nsigma_grouptreat |   1.21 | [ 0.91,  1.49] | 100% |        0% | 1.000 | 2844.00\n\n\n# coefficient plot\nplot(par_fit1) \n\n\n\n\nHere we have the prediction plot\n\n\nShow code\n\nplot(conditional_effects(fit1), points = TRUE)\n\n\n\n\nWe can see the variance in the treatment group:\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen might this model apply?\n\nSuppose we have two groups of patients: One group receives a treatment (e.g., an antidepressive drug) and another group receives placebo. Since the treatment may not work equally well for all patients, the symptom variance of the treatment group may be larger than the symptom variance of the placebo group after some weeks of treatment. (Paul Bruckner, BRMS vignette)\n\nRandom intercept model (clustering)\nTypically our model has clustering. Often this clustering arises from dependencies owning to unmeasured grouping factors, students within schools, or repeated measures within students.\nHowever, recall a fundamental assumption of regression:\n\nThe simple regression model assumes that the errors from the prediction line are independent, an assumption that is violated in time series, spatial, and multilevel settings (gelman_regression_2020?)\n\nLet’s look at environmental concern as predicted by religious group membership:\n\n\n# 506 weekss betwen 530 June 2009 and 15 March 2019\nnzl_11 <- nzl %>%\n  dplyr::filter(Wave == 2019)\n\nri_relgroups <- brm(\n  bf(Env.ClimateChgConcern    ~\n       (1 | Religious_Group)),\n  data = nzl_11,\n  file = here::here(\"models\", \"ri_relgroups\"),\n  silent = FALSE\n)\n\nsummary(ri_relgroups)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Env.ClimateChgConcern ~ (1 | Religious_Group) \n   Data: nzl_11 (Number of observations: 5618) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~Religious_Group (Number of levels: 71) \n              Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(Intercept)     0.70      0.17     0.40     1.04 1.00\n              Bulk_ESS Tail_ESS\nsd(Intercept)      845     1064\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept     5.07      0.13     4.82     5.34 1.00\n          Bulk_ESS Tail_ESS\nIntercept      881     1404\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsigma     1.71      0.02     1.68     1.74 1.00     6911\n      Tail_ESS\nsigma     2903\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nModel equation for a random intercept model\n\\[ g(y_{ig}) \\sim N(\\mu_{ig}, \\sigma)\\\\\n\\mu_i = \\boldsymbol{\\alpha} + \\beta x_{ig}\\\\\n \\boldsymbol{\\alpha} = \\alpha_o + \\alpha_g\\\\\n \\alpha_o \\sim N(3.5,10)\\\\\n \\alpha_g \\sim N(0,\\sigma_g)\\\\\n \\sigma_g \\sim Exp(1)\\\\\n  \\sigma \\sim Exp(1)\n\\]\nWe can calculate the intraclass correlation coefficient for religious groups, which is the ration of group variance devited by the total variance or in this case:\n\\[\\frac{\\sigma^2_{religious groups}}{\\sigma^2_{religious groups} + \\sigma^2_{indiviuals}}\\]\n\n\nperformance::icc(ri_relgroups)\n\n\n# Intraclass Correlation Coefficient\n\n     Adjusted ICC: 0.143\n  Conditional ICC: 0.143\n\nThe authors of the performance package write (performance package documentation)\n\nWhile the adjusted ICC only relates to the random effects, the conditional ICC also takes the fixed effects variances into account (see Nakagawa et al. 2017). Typically, the adjusted ICC is of interest when the analysis of random effects is of interest.\n\nWe can plot the group-level variances:\n\n\nShow code\n\npar_ri_relgroups <-parameters::model_parameters(ri_relgroups,\n                                             effects = \"random\")\nplot(par_ri_relgroups,   sort = TRUE) \n\n\n\n\nReferences: See: https://m-clark.github.io/mixed-models-with-R/\nRandom intercept: Fatigue\nWith longitudinal data, we have repeated measures within individuals. This leads to clustering. We can adjust for this clustering by including group-level intercept for individuals.\nLet’s return to the Fatigue ~ Covid_Timeline model.\n\\[\\begin{align}\ny_{ij}^c \\sim \\text{Ordered}(\\mu_{ij}^c) \\\\\n\\text{CumLogit}(\\mu_{ij}^c) = \\boldsymbol{\\alpha}^c +\\beta X_i \\\\\n\\boldsymbol{\\alpha}^c  = \\alpha_{0}^c +\\alpha_j\\\\\n\\alpha_{0}^c \\sim N(0,10)\\\\\n\\alpha_j \\sim N(0,\\sigma_j)\\\\\n\\sigma_j \\sim exp(1)\\\\\n\\boldsymbol{\\beta}\\sim \\text{Normal}(0,1) \\\\\n\\end{align}\\]\n\n\n  m1_l <- brm(\n    bf(HLTH.Fatigue_int  ~\n      Covid_Timeline + (1|Id),\n    family = cumulative(link = \"logit\")),\n    data = nzl,\n    file = here::here(\"models\", \"ordinal_fatigue_longitudinal\"),\n    silent = FALSE\n  )\nsummary(m1_l)\n\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: HLTH.Fatigue_int ~ Covid_Timeline + (1 | Id) \n   Data: nzl (Number of observations: 11736) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~Id (Number of levels: 5934) \n              Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(Intercept)     2.48      0.05     2.38     2.58 1.01\n              Bulk_ESS Tail_ESS\nsd(Intercept)      870     2060\n\nPopulation-Level Effects: \n                           Estimate Est.Error l-95% CI\nIntercept[1]                  -3.06      0.06    -3.18\nIntercept[2]                  -0.02      0.05    -0.11\nIntercept[3]                   2.65      0.06     2.53\nIntercept[4]                   5.32      0.09     5.14\nCovid_TimelinePreCOVID         0.23      0.04     0.15\nCovid_TimelineJanFeb           0.27      0.11     0.05\nCovid_TimelineEarlyMarch       0.19      0.12    -0.04\nCovid_TimelineLockdown        -0.38      0.15    -0.68\nCovid_TimelinePostLockdown    -0.06      0.10    -0.25\n                           u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]                  -2.95 1.00     2158     2852\nIntercept[2]                   0.07 1.00     2688     3297\nIntercept[3]                   2.76 1.00     2192     3020\nIntercept[4]                   5.49 1.00     2001     2816\nCovid_TimelinePreCOVID         0.32 1.00     7122     3181\nCovid_TimelineJanFeb           0.49 1.00     4779     3284\nCovid_TimelineEarlyMarch       0.43 1.00     4527     3187\nCovid_TimelineLockdown        -0.08 1.00     4456     3136\nCovid_TimelinePostLockdown     0.13 1.00     4723     3491\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\ndisc     1.00      0.00     1.00     1.00 1.00     4000\n     Tail_ESS\ndisc     4000\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nWe graph the results\n\n\nShow code\n\nplot(\n  conditional_effects(\n    m1_l,\n   # spaghetti = TRUE,\n  #  nsamples = 100,\n    categorical = T,\n    prob = 0.89,\n    re_formula = NA,\n  ),\n  points = TRUE,\n  point_args = list(alpha = 0.1,\n                    width = .02)\n) #  note this command controls which facet\n\n\n\n\nMultiple response models\nModel equation\n\\[ g(y^n_{ig}) \\sim N(\\mu^n_{ig}, \\sigma^n)\\\\\n\\mu^n_i = \\boldsymbol{\\alpha^n} + \\beta^n x_{ig}\\\\\n \\boldsymbol{\\alpha} = \\alpha_o + \\alpha_g\\\\\n \\alpha^n_o \\sim N(3.5,10)\\\\\n \\alpha^n_g \\sim N(0,\\sigma_g^n)\\\\\n \\sigma_g^n \\sim exp(1)\\\\\n \\sigma^{n_1} \\sim exp(1)\\\\\n \\sigma^{n_2}\\sim exp(1) \\\\\n\\begin{bmatrix}\n\\sigma^{n_1} \\\\\n\\sigma^{n_2} \n\\end{bmatrix}\n\\sim \n\\boldsymbol{RESCOR} \\begin{pmatrix}\n1 &  \\sigma^{n_1}\\sigma^{n_2} \\rho    \\\\\n\\sigma^{n_1}\\sigma^{n_2}\\rho   &  1\n\\end{pmatrix}\\\\\n\\boldsymbol{RESCOR}\\sim \\text{LKJcorr}(2)\n\\]\n\n\nShow code\n\n# Create smaller data frame\nsnzl <- nzl %>%\n  dplyr::filter(Wave == 2019) # Only one wave\n\nset.seed(123)\nnm <- sample(snzl$Id, size = 300) # randomly select a smaller sample of individuals. \n\n# create the data frame\nsub_nzl<- snzl%>%\n filter(Id %in% nm)\n\n\n\n\n\nf_mv <- brm(\n  mvbind(Warm.Immigrants, Warm.Muslims) ~  log(Hours.News + 1),\n  data = sub_nzl,\n  file = here::here(\"models\", \"multivariate_warmth\"), \n)\nsummary(f_mv)\n\n\n Family: MV(gaussian, gaussian) \n  Links: mu = identity; sigma = identity\n         mu = identity; sigma = identity \nFormula: Warm.Immigrants ~ log(Hours.News + 1) \n         Warm.Muslims ~ log(Hours.News + 1) \n   Data: sub_nzl (Number of observations: 293) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n                               Estimate Est.Error l-95% CI\nWarmImmigrants_Intercept           4.54      0.16     4.23\nWarmMuslims_Intercept              4.30      0.18     3.95\nWarmImmigrants_logHours.NewsP1     0.08      0.10    -0.11\nWarmMuslims_logHours.NewsP1        0.03      0.12    -0.20\n                               u-95% CI Rhat Bulk_ESS\nWarmImmigrants_Intercept           4.84 1.00     3094\nWarmMuslims_Intercept              4.66 1.00     3101\nWarmImmigrants_logHours.NewsP1     0.28 1.00     3046\nWarmMuslims_logHours.NewsP1        0.26 1.00     3046\n                               Tail_ESS\nWarmImmigrants_Intercept           2693\nWarmMuslims_Intercept              2861\nWarmImmigrants_logHours.NewsP1     2395\nWarmMuslims_logHours.NewsP1        2622\n\nFamily Specific Parameters: \n                     Estimate Est.Error l-95% CI u-95% CI\nsigma_WarmImmigrants     1.24      0.05     1.14     1.34\nsigma_WarmMuslims        1.46      0.06     1.35     1.58\n                     Rhat Bulk_ESS Tail_ESS\nsigma_WarmImmigrants 1.00     2980     2955\nsigma_WarmMuslims    1.00     3086     2924\n\nResidual Correlations: \n                                   Estimate Est.Error\nrescor(WarmImmigrants,WarmMuslims)     0.77      0.02\n                                   l-95% CI u-95% CI Rhat\nrescor(WarmImmigrants,WarmMuslims)     0.72     0.81 1.00\n                                   Bulk_ESS Tail_ESS\nrescor(WarmImmigrants,WarmMuslims)     3547     2954\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nCoefficient plot\n\n\nbrms::mcmc_plot(f_mv, \n               type = \"areas\",\n               prob = .89)\n\n\n\n\nMediation\nManipulate X, measure M and Y\nRegress M on X; Y on X and M\n\n\nShow code\n\nbmlm::mlm_path_plot(xlab = \"Condition\\n(X)\",\n              mlab = \"Mediator\\n(M)\",\n              ylab = \"Distress\\n(Y)\")\n\n\n\n\nAssumptions\nY does not affect M\nNo 3rd variable on M to Y relationship\nM is measured without error\nY and M residuals are not correlated (vuorre2020multilevel?)\nSet up\n\n\npath_m <- bf(\n  mF ~ x + (1 | c | id)\n  )\npath_y <- bf(\n  y ~ x + mF_w + mF_b +\n               (1 | c | id)\n  )\nm1 <- brm(\n  path_m + path_y + set_rescor(FALSE),\n  data = datF,\n  file = here(\"models/mediation-k6-covid-fatigue\")\n)\n\n\n\nModel form\n\n\nx <-nzl$Covid_Timeline\nmF <-nzl$HLTH.Fatigue_int\ny<- nzl$KESSLER6sum\nid <-nzl$Id\ndatF <-data.frame(x,mF, y,id)\n\n\n\n\n\npath_m <- bf(\n  mF ~ x + (1 | c |  id)\n  )\npath_y <- bf(\n  y ~ x + mF +  (1 | c |  id)\n  )\nf1 <- brm(\n  path_m + path_y + set_rescor(FALSE),\n  data = datF,\n  file = here::here(\"models/mediation-k6-covid-fatigue\")\n)\n\nsummary(f1)\n\n\n Family: MV(gaussian, gaussian) \n  Links: mu = identity; sigma = identity\n         mu = identity; sigma = identity \nFormula: mF ~ x + (1 | id) \n         y ~ x + mF + (1 | c | id) \n   Data: datF (Number of observations: 11735) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nGroup-Level Effects: \n~id (Number of levels: 5933) \n                 Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(mF_Intercept)     0.81      0.01     0.79     0.83 1.00\nsd(y_Intercept)      2.52      0.03     2.46     2.59 1.01\n                 Bulk_ESS Tail_ESS\nsd(mF_Intercept)     1271     2049\nsd(y_Intercept)      1000     1890\n\nPopulation-Level Effects: \n                 Estimate Est.Error l-95% CI u-95% CI Rhat\nmF_Intercept         2.58      0.01     2.55     2.60 1.01\ny_Intercept          0.69      0.09     0.52     0.87 1.00\nmF_xPreCOVID         0.08      0.01     0.05     0.11 1.00\nmF_xJanFeb           0.09      0.04     0.02     0.17 1.00\nmF_xEarlyMarch       0.06      0.04    -0.02     0.14 1.00\nmF_xLockdown        -0.12      0.05    -0.22    -0.02 1.00\nmF_xPostLockdown    -0.02      0.03    -0.08     0.04 1.00\ny_xPreCOVID         -0.04      0.05    -0.13     0.05 1.00\ny_xJanFeb           -0.19      0.12    -0.43     0.05 1.00\ny_xEarlyMarch        0.23      0.12    -0.01     0.48 1.00\ny_xLockdown          0.55      0.16     0.24     0.88 1.00\ny_xPostLockdown      0.15      0.10    -0.04     0.34 1.00\ny_mF                 1.71      0.03     1.65     1.77 1.00\n                 Bulk_ESS Tail_ESS\nmF_Intercept         1654     2355\ny_Intercept          1638     2484\nmF_xPreCOVID         5789     3093\nmF_xJanFeb           3596     3181\nmF_xEarlyMarch       3688     2978\nmF_xLockdown         3466     2915\nmF_xPostLockdown     3998     3049\ny_xPreCOVID          4813     3216\ny_xJanFeb            3616     3138\ny_xEarlyMarch        3418     3080\ny_xLockdown          3601     3083\ny_xPostLockdown      3569     3198\ny_mF                 1662     2226\n\nFamily Specific Parameters: \n         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsigma_mF     0.67      0.01     0.66     0.68 1.00     1521\nsigma_y      2.10      0.02     2.06     2.14 1.00     1612\n         Tail_ESS\nsigma_mF     2310\nsigma_y      2807\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\npost1F <- brms::posterior_samples(f1)\npost_marF <- post1F %>% \n  transmute(\n    a = b_mF_xLockdown,\n    b = b_y_mF,\n    cp = b_y_xLockdown,\n    me = a * b,\n    c = cp + me#,\n   # pme = me / c\n  )\n# posterior_summary(post_marF)\n\n\n\n\n\nShow code\n\nmcmc_intervals(post_marF)\n\n\n\n\nHypothesis\n\n\nh1 <- c(\n  a = \"mF_xLockdown  = 0\",\n  b = \"y_mF = 0\",\n  cp = \"y_xLockdown = 0\",\n  me = \"mF_xLockdown * y_xLockdown = 0\",\n  c = \"mF_xLockdown * y_mF + y_xLockdown = 0\"\n)\n\nplot(\n  hypothesis(f1, h1)\n)\n\n\n\n\nBonus: Latent Profile Analysis\nLatent Profile Analysis\nDistinct profiles or clusters… tbc…\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyLPA)\n\n\nout<-nzl %>%\n  dplyr::select(Hours.Internet, \n          Hours.Exercise,\n          Hours.Work)%>%\n  dplyr::mutate_all(., scale)\n\nout%>%\n  single_imputation() %>%\n  tidyLPA::estimate_profiles(3) %>%\n    plot_profiles(add_line = TRUE)\n\n\n\n\n\n\n\n",
    "preview": "posts/9_1/lecture_9_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-05-04T15:21:55+12:00",
    "input_file": {},
    "preview_width": 2304,
    "preview_height": 1920
  },
  {
    "path": "posts/8_1/",
    "title": "Generalised linear models",
    "description": "Estimating binary responses, counts, rates, overdispersion, and zero-inflation",
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      }
    ],
    "date": "2021-04-27",
    "categories": [],
    "contents": "\n\nContents\nObjectives\nIntroduction\nLogistic regression\nLink function for logistic regression\n\nLogistic regression\nLink function for logistic regression\nExtimating the probability of home ownership in the population\nIntepretation\n\nLogistic regression with a single co-variate.\nWorkflow: center and scale continuous predictors\nModel syntax\nInterpretation\nWorkflow: graph your results.\nLogistic regression with a categorical covariate\nNotes\n\nPoisson regression (counts)\nLink function for poisson regression\nModel checks\n\nNegative binomial models (over-dispersed Poissons)\nLink function for a negative binomial model\n\nZero-inflated poisson/ neg binomial regression\nLink function for zero-inflated poisson\nIntroducing brms for estimating complex regression models\nZero_inflated_poisson model syntax\nZero_inflated_negbinomial model syntax\nA model for your zeros\nInterpretation\nPosterior predictive checks\nZero-inflated poisson PP check\nZero-inflated negative binomial with no predictors for the zero-inflation PP check\nZero-inflated negative binomial with zero-inflation predictors PP check\n\nReporting\nSummary\nAppendix 1\nAppendix 2\nAppendix 3\nAcknowledgments and References\nBürkner and Vuorre (2019)\n\n\n\n\n\n\n\nObjectives\nTo understand the concept of a “generalised linear model,” and why the standard (gaussian) linear model is a special case.\nTo undertand how to write four classes of generalised linear models:\nLogistic regression models, which apply to binary responses;\nPoisson regression models, which apply to rates;\nNegative binomial models (over-dispersed poisson regression models)\nZero-inflated poisson/negative binomial models, in which rates contain an over abundance of zeros.\nTo understand how to interpret and report the results of a generalised linear model.\nIntroduction\nRecall that a regression model combines data from a sample, on the one hand, with the tools of probability theory, on the other hand, to infer features of an unobserved population. We call these unobserved features “parameters.” The task in regression is to estimate uncertainty in these parameters, and where possible, to narrow the bandwidth of such uncertainty. In a nutshell, regression is educated guesswork.\nOur focus has been on teaching workflows for estimation that are grounding in three imperatives:\nto clarify our question: what do we want to infer?\nto clarify our assumptions: what do we believe about the world and our data before estimation gets going\nto clarify our decisions: inevitably applied regression modelers must make choices: what have we decided and why?\nSo far, our models have assumed that response data in our models are sampling from a “normal” or “gaussian” distribution. This assumption is useful because we live i an ordered universe from which many of our observations are sampling from a normal distribution. However, although the gaussian distribution is sensible choice for estimating many parameters it is not a sensible choice for estimating all parameters. The linear regression model that we have been using is really a special case of the generalised linear regression model. Today we introduce the generalised linear model. ## A regression model implies a ‘link’ function\nSo far, we have written the gaussian linear model as:\n\\[ y_i  = \\alpha + \\beta x_i + e\\]\nWhere y is the response for the i\\({^th}\\) data point, \\(\\alpha\\) is the intercept, or the expected response for the population when all other regression coefficients are set to zero, \\(\\beta\\) is the adjustment in this expectation for the i\\(^{th}\\) predictor \\(x\\) associated with \\(y_i\\), where both y and x are random variables.\nOften applied regression models were use compact matrix notation, where a bolded symbol is short hand for a matrix:\n\\[\\boldsymbol{\\eta} =  \\boldsymbol{\\alpha} + \\boldsymbol{X}\\boldsymbol{\\beta}\\\\\\]\nFor example here, \\[\\boldsymbol{X}\\boldsymbol{\\beta}\\\\\\] is shorthand for \\[\\beta_1X_i + \\beta_2X_i + \\beta_2X \\dots\\]\nWe can write the gaussian linear model in way that makes our assumptions and decisions explicit about what we think/hope it is doing when combining data with probability theory to estimate unknown (and inherently uncertain) parameters.1\nRecall that there are two parameters that we need to estimate for gaussian linear model: the mean, and the variance.\n\\[\ny_i \\sim Normal ( \\mu_i, \\sigma)\\\\\n\\mu_i = \\alpha + \\beta x_i \\\\\n\\sigma \\sim Exponentional (1) \\\\\n\\]\nWe assume that our response variable is a random variable that is sampling from a normal distribution with that has a mean \\(\\mu_i\\) and a variance \\(\\sigma^2\\). For reasons that will become clear in the final lecture, we will write the variance parameter as the square root of the variance parameter, \\(\\sigma\\) which is a standard deviation (see Appendix 3 .appendix3)\nThe exponential distribution has good properties for estimating the standard deviation of the mean:\n\n\nexponential_distribution <- (rexp(1000, 1))\nhist(exponential_distribution, breaks = 100)\n\n\n\n\nsee here\nEvery linear model implies a ‘link’ function:\n\\(g(\\cdot)\\) = link function as well as an an inverse link function:\n\\(h(\\cdot) = g^-1(\\cdot)\\) = inverse link function\nWhere \\((\\cdot)\\) is the linear predictor: \\(\\boldsymbol{\\eta}\\)\nIn the gaussian linear model we assume\n\\[g(\\cdot) = h(\\cdot)\\] That is, the link function is an identity function. This is a special case. In the remainder of the lecture we will explore different mapping from the expected outcome of a model and its linear predictors.\nLogistic regression\nWe begin with outcomes that are distributed as binary data. Consider home ownership in the nz jitter dataset:\n\n\nhist(nz$HomeOwner)\n\n\n\n\nFrom the graph, we can see response distribution is fully bimodal (excluding the NAs).\nLink function for logistic regression\nThe binomial link function does two things:\nfirst, it maps the range \\((0, 1)\\) to \\(-(\\infty, -\\infty)\\).\nsecond, it maps these values back to the unit range (see: Gelman, Hill, and Vehtari (2020) )\nThe logistic function satisfies the first task:\n\\[logit(\\cdot) = log_e\\frac{p}{(1-p)}\\]\nThe inverse logit functionsatisfies the second task:\n\\[logit^-1(\\cdot) = log\\frac{e^\\cdot}{(1-e^\\cdot)}\\]\nWe can write this:\n\\[\n\\Pr(y_i = 1) = p_i \\\\\nlogit(p_i) = \\alpha + \\beta x_i \\\\\n\\Pr(y_i = 1) = logit^{-1}(\\alpha + \\beta x_i)\n\\] In R these functions are written:\n\n\nlogit <- qlogis\ninvlogit <- plogis\n\n\n\nLogistic regression\nWe begin with outcomes that are distributed as binary data. Consider home ownership in the nz jitter dataset:\n\n\nhist(nz$HomeOwner)\n\n\n\n\nFrom the graph, we can see response distribution is fully bimodal (excluding the NAs).\nLink function for logistic regression\nThe binomial link function does two things:\nfirst, it maps the range \\((0, 1)\\) to \\(-(\\infty, \\infty)\\).\nsecond, it maps these values back to the unit range (see: Gelman, Hill, and Vehtari (2020) )\nThe logistic function satisfies the first task:\n\\[logit(\\cdot) = log_e\\frac{p}{(1-p)}\\]\nThe inverse logit functionsatisfies the second task:\n\\[logit^-1(\\cdot) = log\\frac{e^\\cdot}{(1-e^\\cdot)}\\]\nWe can write this:\n\\[\n\\Pr(y_i = 1) = p_i \\\\\nlogit(p_i) = \\alpha + \\beta x_i \\\\\n\\Pr(y_i = 1) = logit^{-1}(\\alpha + \\beta x_i)\n\\] In R these functions are written:\n\n\nlogit <- qlogis \ninvlogit <- plogis\n\n\n\nFor logistic regression, the functions are employed as follow:\n\\[\n\\Pr(y_i = 1) = p_i \\\\\nlogit(p_i) = \\alpha + \\beta x_i \\\\\n\\Pr(y_i = 1) = logit^{-1}(\\alpha + \\beta x_i)\n\\]\nAside: later on we will express paramters for the linear predictors, so something like:\n\\[Ownership_i \\sim binomial (n, Pr_i)\\\\\nOwnersip_i = \\alpha + \\beta X_i \\\\\n\\alpha \\sim N(0,\\sigma_{alpha})\\\\\n\\sigma_{alpha} \\sim(0,10) \\\\\n\\beta \\sim lognormal(0,1) \\\\\n\\]\nWhere the values we assign correspond to a range of expectations bout how the world might be. Let’s not get distracted with these details for now, however, I include them to give you a sense of how notation can help us to clarify our assumptions and decisions – which recall are essential navigations points for applied scientists.\nExtimating the probability of home ownership in the population\nWe can write a generalised linear model that predict home ownership as follows:\n\n\nhome <- glm(HomeOwner ~ 1, data = nz, \n            family = \"binomial\")\n\n\n\nWhich gives us the following result\n\n\nparameters::model_parameters(home)\n\n\nParameter   | Log-Odds |   SE |       95% CI |     z |      p\n-------------------------------------------------------------\n(Intercept) |     1.46 | 0.05 | [1.36, 1.55] | 30.38 | < .001\n\nOr plugging this into the equation:\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(home,  use_coefs = TRUE)\n\n\n\\[\n\\log\\left[ \\frac { \\widehat{P( \\operatorname{HomeOwner} = \\operatorname{1} )} }{ 1 - \\widehat{P( \\operatorname{HomeOwner} = \\operatorname{1} )} } \\right] = 1.46\n\\]\n\nIntepretation\nHow do we interpret this result?\nWe can use the plogis function to obtain the probability\n\n\nplogis(coef(home)[[1]])\n\n\n[1] 0.811068\n\nThe probability of an NZAVS participant owning their own home is 0.811068\nNotably, the logistic regression has estimated the sample mean to seven decimal places.\n\n\nmean(nz$HomeOwner, na.rm=TRUE)\n\n\n[1] 0.811068\n\nLogistic regression with a single co-variate.\nWorkflow: center and scale continuous predictors\nWe do this as follows.\n\n\n# work around for compatibility issue between ggeffects and dplyr. \nnz['Household.INC_s'] <- as.data.frame( scale(nz$Household.INC) )\n\n\n\nTo ge a reference point for a standard deviation of household income, let’s find the standard deviation for the sample:\n\n\n# how much is a standard deviation -- which will represent a 1 unit change for the regression coefficient? \nsd( nz$Household.INC, na.rm = TRUE ) # 95,090\n\n\n[1] 95090.79\n\nLet’s ask about the mean household for income in 2018?\n\n\nmean( nz$Household.INC, na.rm = TRUE )\n\n\n[1] 112877.1\n\nModel syntax\nWe write a logistic regression model with a single covariate as follows:\n\n\nhome2 <- glm(HomeOwner ~ Household.INC_s, data = nz, \n            family = \"binomial\")\n\n\n\nResults:\n\n\nrs2<-parameters::model_parameters(home2)\nrs2\n\n\nParameter       | Log-Odds |   SE |       95% CI |     z |      p\n-----------------------------------------------------------------\n(Intercept)     |     1.58 | 0.05 | [1.48, 1.69] | 29.37 | < .001\nHousehold.INC_s |     0.72 | 0.08 | [0.57, 0.89] |  8.86 | < .001\n\nplot(rs2)\n\n\n\n\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(home2,  use_coefs = TRUE)\n\n\n\\[\n\\log\\left[ \\frac { \\widehat{P( \\operatorname{HomeOwner} = \\operatorname{1} )} }{ 1 - \\widehat{P( \\operatorname{HomeOwner} = \\operatorname{1} )} } \\right] = 1.58 + 0.72(\\operatorname{Household.INC\\_s})\n\\]\n\nInterpretation\nHow do we interpret this model?\nLet’s use the report package\n\n\nreport::report(home2)\n\n\nWe fitted a logistic model (estimated using ML) to predict HomeOwner with Household.INC_s (formula: HomeOwner ~ Household.INC_s). The model's explanatory power is weak (Tjur's R2 = 0.04). The model's intercept, corresponding to Household.INC_s = 0, is at 1.58 (95% CI [1.48, 1.69], p < .001). Within this model:\n\n  - The effect of Household.INC_s is significantly positive (beta = 0.72, 95% CI [0.57, 0.89], p < .001; Std. beta = 0.73, 95% CI [0.57, 0.89])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n\nThere’s lots of mention of p-values and power claims in the automated report, but what do these words practically mean?\nWorkflow: graph your results.\nWe are cultivating a habit of graphing our results. Let’s put this habit to virtuous use.\nHere’s a shortcut for obtaining a quick, investigative plot:\n\n\nplot(nz$Household.INC_s, nz$HomeOwner) \ncurve(invlogit(coef(home2)[1] + coef(home2)[2]*x), add=TRUE)\n\n\n\n\nThe slightly longer syntax for a ggeffects graph is:\n\n\nplot(ggeffects::ggpredict(home2, terms = \"Household.INC_s\"), add.data = TRUE, alpha =.1)\n\n\n\n\nAnd here we find a curious feature of our data. Income is diffuse. We have someone that makes over 25 standard deviations more than the average income.\n\n\nhist(nz$Household.INC, breaks = 1000)\n\n\n\n\nAlthough we graph home ownership, we forgot to graph Household income.\nBefore launching into a model, your workflow should include graphing your predictors as well as your responses\nThe range of incomes is: 0, 2.5^{6}.\nNote that we also have 8 who report making less than 10000,\nSensitivity of the data to outliers?\nLet’s re-run the model while eliminating the extremely rich, and restrict focus to 98% of the data. This restriction would appear to be justified. It would not be surprising if very rich people were to own their own homes.\n\n\n# Select 98 % of the range\nnz2 <-  nz%>%\n  dplyr::filter(Household.INC_s < 4)\n##\nnrow(nz2)/nrow(nz)\n\n\n[1] 0.979438\n\n\n\nhome2.1 <- glm(HomeOwner ~ Household.INC_s, data = nz2, \n            family = \"binomial\")\nparameters::model_parameters(home2.1)\n\n\nParameter       | Log-Odds |   SE |       95% CI |     z |      p\n-----------------------------------------------------------------\n(Intercept)     |     1.60 | 0.05 | [1.50, 1.71] | 29.21 | < .001\nHousehold.INC_s |     0.78 | 0.08 | [0.62, 0.95] |  9.27 | < .001\n\nNote that we need a sensible range. The lowest value is not 4 SD from the mean\n\n\nhist(nz2$Household.INC_s)\n\n\n\n\n\n\nrange(nz2$Household.INC_s, na.rm = T)\n\n\n[1] -1.187046  3.755599\n\nDoes this matter? Not necessarily. Linear regression does not require that the predictors sample from a normal distribution. This should be obvious, as we have used categorical predictors (e.g. Male/Not_Male). However it is worth explicitly stating. I have heard people who should know better express confusion on this point. Of course, that there are no parametric assumptions for your predictor variables does not let you off the hook. In this case, the extreme values might be distorting our inference.\nLet’s write a model with the diminished dataset.\n\n\n#range(nz$Household.INC_s, na.rm = T)\n\nmp2 <- plot(ggeffects::ggpredict(home2,\n                                 terms = \"Household.INC_s[all]\")) + scale_y_continuous(limits = c(0, 1)) +\n  scale_x_continuous(limits = c(-1.2, 4))\nmp2.1 <- plot(ggeffects::ggpredict(home2.1,\n                                   terms = \"Household.INC_s[all]\")) + scale_y_continuous(limits = c(0, 1)) +\n  scale_x_continuous(limits = c(-1.2, 4))\n\nlibrary(patchwork)\nmp2 + mp2.1 +\n  plot_annotation(title = \"Comparison of logistic regression models with tranformations\",\n                  tag_levels = 'a') \n\n\n\n\nNotice the trick that I used here:\nscale_x_continuous(limits = c(-1.2, 4))\nThis code allowed me to constrain both graphs to the same x-axis scale. If I left this out the graphs would have looked like this:\n\n\n#range(nz$Household.INC_s, na.rm = T)\nmp2 <- plot(ggeffects::ggpredict(home2,\n                                 terms = \"Household.INC_s[all]\")) + scale_y_continuous(limits = c(0, 1))\nmp2.1 <- plot(ggeffects::ggpredict(home2.1,\n                                   terms = \"Household.INC_s[all]\")) + scale_y_continuous(limits = c(0, 1))\n\nlibrary(patchwork)\nmp2 + mp2.1 + plot_annotation(title = \"Comparison of logistic regression models with tranformations\",\n                              tag_levels = 'a') +\n  plot_layout(guides = 'collect')\n\n\n\n\nThe models are for all intents and purposes identical.\nYou can perform further checks using the following code, however, it should be apparent from the preceding graph that the models two models do not vary.\n\n\ncheck1 <- performance::check_model(home2)\ncheck1\n\n\n\n\n\ncheck2 <- performance::check_model(home2.1)\ncheck2\n\n\n\nBefore leaving this example, what would an ordinary linear regression sampling from a normal distribution have returned?\n\n\nhome2LM <- lm(HomeOwner ~ Household.INC_s, data = nz)\nhome2LM_r <- parameters::model_parameters(home2LM)\nhome2LM_r\n\n\nParameter       | Coefficient |       SE |       95% CI | t(2796) |      p\n--------------------------------------------------------------------------\n(Intercept)     |        0.81 | 7.27e-03 | [0.80, 0.83] |  111.88 | < .001\nHousehold.INC_s |        0.06 | 7.23e-03 | [0.04, 0.07] |    8.04 | < .001\n\nplot(home2LM_r)\n\n\n\n\nLet’s graph the results and compare the\n\n\nhome2LM_p <- plot(ggeffects::ggpredict(home2LM,\n                                       terms = \"Household.INC_s[all]\"),\n                  add.data = TRUE) +\n  scale_y_continuous(limits = c(0, 1.5))  +\n  scale_x_continuous(limits = c(-1.2, 4)) + theme_classic()\nhome2LM_p\n\n\n\n\nhome2_p <- plot(ggeffects::ggpredict(home2,\n                                     terms = \"Household.INC_s[all]\"),\n                add.data = TRUE) +\n  scale_y_continuous(limits = c(0, 1.5))  +\n  scale_x_continuous(limits = c(-1.2, 4)) + theme_classic()\n\nhome2LM_p + home2_p + plot_annotation(subtitle = \"Comparison of ordinary least squares regression \\n (a) with logistic regression (b) reveals n\\ impossible predictions for OLS\") +\n  plot_layout(guides = \"collect\")\n\n\n\n\nLogistic regression with a categorical covariate\nLet’s use the GenCohort variable.\n\n\nmg1 <- glm(HomeOwner ~ GenCohort, data = nz, family = \"binomial\")\nparameters::model_parameters(mg1)\n\n\nParameter                               | Log-Odds |   SE |         95% CI |      z |      p\n--------------------------------------------------------------------------------------------\n(Intercept)                             |     2.13 | 0.10 | [ 1.94,  2.34] |  20.68 | < .001\nGenCohortGen_Silent *  born< 1946       |     0.26 | 0.28 | [-0.26,  0.85] |   0.94 | 0.347 \nGenCohortGenX *  born >=1961 & b.< 1980 |    -0.62 | 0.13 | [-0.87, -0.38] |  -4.90 | < .001\nGenCohortGenY *  born >=1980 & b.< 1996 |    -1.87 | 0.14 | [-2.15, -1.59] | -13.00 | < .001\nGenCohortGenZ *  born >= 1996           |    -4.91 | 1.04 | [-7.80, -3.30] |  -4.74 | < .001\n\nWhat does this mean? Let’s graph the results\n\n\np_mg1 <-plot(ggeffects::ggpredict(mg1, terms = \"GenCohort[all]\"))\np_mg1\n\n\n\n\nLets stratify by income\nHousehold.INC_s\n\n\nmg2 <- glm(HomeOwner ~ GenCohort + Household.INC_s, data = nz, family = \"binomial\")\nparameters::model_parameters(mg2)\n\n\nParameter                               | Log-Odds |   SE |         95% CI |      z |      p\n--------------------------------------------------------------------------------------------\n(Intercept)                             |     2.60 | 0.12 | [ 2.37,  2.84] |  21.79 | < .001\nGenCohortGen_Silent *  born< 1946       |     0.70 | 0.30 | [ 0.15,  1.33] |   2.35 | 0.019 \nGenCohortGenX *  born >=1961 & b.< 1980 |    -0.99 | 0.14 | [-1.26, -0.73] |  -7.31 | < .001\nGenCohortGenY *  born >=1980 & b.< 1996 |    -2.40 | 0.16 | [-2.71, -2.09] | -14.94 | < .001\nGenCohortGenZ *  born >= 1996           |    -4.99 | 1.06 | [-7.91, -3.32] |  -4.72 | < .001\nHousehold.INC_s                         |     1.19 | 0.10 | [ 0.99,  1.39] |  11.62 | < .001\n\nWe really don’t see income making a difference to home ownership for boomers. A little sepearation happens among those in Gen X.\n\n\np_mg2 <-plot(ggeffects::ggpredict(mg2, terms = c(\"GenCohort[all]\", \"Household.INC_s[c(-1,0,3)]\")))\np_mg2\n\n\n\n\nNotes\nAdditive indicators on the logit scale are non-linear on the data scale. We see this in the previous graph. There’s a curve. This is typical of generalised linear models.\ndo not interpret the signs of the coefficients. For example, plogis(-3) is 0.0474259, which is a positive probability.\nhere are is no error term (\\(\\sigma^2\\)) in logistic regression. We only estimate the mean. The variances cannot be estimated:\n\n\nsjPlot::tab_model(home2)\n\n\n\n \n\n\nHomeOwner\n\n\nPredictors\n\n\nOdds Ratios\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n4.87\n\n\n4.39 – 5.43\n\n\n<0.001\n\n\nHousehold.INC_s\n\n\n2.06\n\n\n1.76 – 2.43\n\n\n<0.001\n\n\nObservations\n\n\n2798\n\n\nR2 Tjur\n\n\n0.036\n\n\nwe can add points to our graph like this:\n\n\nplot(ggeffects::ggpredict(home2, \n                     terms = \"Household.INC_s[all]\"), add.data = TRUE) + scale_x_continuous(limits= c(-1.2,4))\n\n\n\n\nOr to limit our points to the meaningful range:\n\n\nplot(ggeffects::ggpredict(home2, \n                     terms = \"Household.INC_s[all]\"), add.data = TRUE) + scale_x_continuous(limits= c(-1.2,4))\n\n\n\n\ncenter (and where it eases interpretation, also scale) your predictor variables.\nUncertainty arises because we only have 17 people in this jittered nz dataset born after 1996:\n\n\ntable(nz$GenCohort)\n\n\n\nGen Boombers: born >= 1946 & b.< 1961 \n                                 1024 \n               Gen_Silent: born< 1946 \n                                  208 \n         GenX: born >=1961 & b.< 1980 \n                                 1253 \n         GenY: born >=1980 & b.< 1996 \n                                  416 \n                   GenZ: born >= 1996 \n                                   17 \n\n\n\nggplot(nz, (aes(GenCohort, Household.INC))) + geom_jitter(alpha = .5)\n\n\n\n\nWhich model should we prefer?\nThe model mg2 grealy improves on the BIC performance, indicating that we should prefer this model.\n\n\nper_home <-performance::compare_performance(home2,mg1,mg2)\nper_home\n\n\n# Comparison of Model Performance Indices\n\nName  | Model |      AIC |      BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log |   PCP | Score_spherical\n----------------------------------------------------------------------------------------------------------------\nhome2 |   glm | 2590.320 | 2602.193 |     0.036 | 0.381 | 0.962 |    0.462 |      -Inf | 0.708 |                \nmg1   |   glm | 2516.922 | 2546.675 |     0.099 | 0.372 | 0.941 |    0.442 |      -Inf | 0.724 |       3.915e-04\nmg2   |   glm | 2272.307 | 2307.927 |     0.168 | 0.354 | 0.900 |    0.404 |      -Inf | 0.748 |       5.159e-04\n\nHere’s a graph:\n\n\nplot(per_home)\n\n\n\n\nNote that we do not include the model that used fewer cases because, from the vantage point of information theory, this would be comparing apples with organges.\nWe can use the performance package to check the accuracy of the our models\nCompare:\n\n\nperformance_accuracy(mg1)\n\n\n# Accuracy of Model Predictions\n\nAccuracy: 65.78%\n      SE: 4.45%-points\n  Method: Area under Curve\n\nWith:\n\n\nperformance_accuracy(mg2)\n\n\n# Accuracy of Model Predictions\n\nAccuracy: 76.94%\n      SE: 2.54%-points\n  Method: Area under Curve\n\nAnd this reveals little difference, indicating that with this many data, the outliers don’t affect inference.\nPoisson regression (counts)\nWe use a poisson model for rates and counts\nLink function for poisson regression\n\\[\ny_i \\sim Poisson(\\lambda_i)\\\\  \nlog(\\lambda_i) = \\alpha +\\beta x_i\\\\\nE(\\lambda|y_i) = exp(\\alpha +\\beta x_i)\n\\]\nLet’s simulate some data (example from Gelman, Hill, and Vehtari (2020), for more on simulated poisson variables go here\n\n\nset.seed(999)\nn <- 50\nx <- runif(n, -2, 2)\na <- 1\nb <- 2\nout <- a + b  * x\nset.seed(999)\ny <- rpois(n,  exp(out)) # mean of poisson is equal to its variance\nfake <- data.frame(x=x, y=y)\nhist(fake$y)\n\n\n\n\nModel\n\n\npois1 <- glm(y ~ x, data = fake, family = \"poisson\")\nmodel_parameters(pois1)\n\n\nParameter   | Log-Mean |   SE |       95% CI |     z |      p\n-------------------------------------------------------------\n(Intercept) |     1.01 | 0.11 | [0.79, 1.21] |  9.40 | < .001\nx           |     1.99 | 0.08 | [1.84, 2.14] | 26.24 | < .001\n\nNote that in a poisson model, it is the log of the expected values (not the log of the raw data) that the model estimates:\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(pois1,  use_coefs = TRUE)\n\n\n\\[\n\\log ({ \\widehat{E( \\operatorname{y} )} })  = 1.01 + 1.99(\\operatorname{x})\n\\]\n\nWe can put this on the data scale\n\n\np_pois1 <- plot(ggeffects::ggpredict(pois1, terms = \"x\"), add.data = TRUE)\np_pois1\n\n\n\n\nLet’s compare this to a model in which we assume a normal distribution\n\n\npois2 <- glm(y ~ x, data = fake) # remove \"family = `poisson`)\nmodel_parameters(pois2)\n\n\nParameter   | Coefficient |   SE |         95% CI | t(48) |      p\n------------------------------------------------------------------\n(Intercept) |       15.19 | 2.35 | [10.58, 19.81] |  6.45 | < .001\nx           |       14.73 | 2.04 | [10.73, 18.73] |  7.22 | < .001\n\nQuick plot:\n\n\np_pois2 <- plot(ggeffects::ggpredict(pois2, terms = \"x\"), add.data = TRUE)\np_pois2\n\n\n\n\nModel checks\n\n\nperformance::check_model(pois1)\n\n\n\n\nWe can see the linearity assumption is violated:\n\n\nperformance::check_model(pois2)\n\n\n\n\n\n\nlibrary(splines)\n\npois3 <- glm(y ~ bs(x), data = fake) # remove \"family = `poisson`)\nmodel_parameters(pois3)\n\n\nParameter      | Coefficient |   SE |           95% CI |  t(46) |      p\n------------------------------------------------------------------------\n(Intercept)    |       -6.57 | 2.13 | [-10.74,  -2.39] |  -3.08 | 0.003 \nx [1st degree] |       43.71 | 7.41 | [ 29.19,  58.23] |   5.90 | < .001\nx [2nd degree] |      -67.11 | 5.30 | [-77.50, -56.72] | -12.66 | < .001\nx [3rd degree] |      118.01 | 4.46 | [109.26, 126.76] |  26.44 | < .001\n\n\n\np_pois3<- plot(ggeffects::ggpredict(pois3, terms = \"x\"), add.data = TRUE)\np_pois3\n\n\n\n\n\n\nlibrary(patchwork)\np_pois1 + p_pois2 + p_pois3 + plot_annotation(title = \"comparison of three assumed distributions\", tag_levels = 'a',\n                                              subtitle = \"The Poisson model (a) fits \\nThe gaussian model (b) underfitsthe \\nThe spline model (c) overfits\") +\n  plot_layout(guides = \"collect\")\n\n\n\n\nThe poisson fits best: this is no surprise: we simulated poisson outcomes.\n\n\nper_pois <-performance::compare_performance(pois1,pois2,pois3)\nper_pois\n\n\n# Comparison of Model Performance Indices\n\nName  | Model |     AIC |     BIC |   RMSE |  Sigma |    R2 | Nagelkerke's R2 | Score_log | Score_spherical\n-----------------------------------------------------------------------------------------------------------\npois1 |   glm | 188.481 | 192.305 |  3.361 |  0.985 |       |           1.000 |    -1.845 |           0.097\npois2 |   glm | 426.698 | 432.434 | 16.249 | 16.584 | 0.521 |                 |           |                \npois3 |   glm | 300.273 | 309.833 |  4.410 |  4.597 | 0.965 |                 |           |                \n\nplot(per_pois)\n\n\n\n\nNegative binomial models (over-dispersed Poissons)\nLink function for a negative binomial model\n\\[\ny_i \\sim NegBinomial(\\lambda_i,\\phi)\\\\\nlog(\\lambda_i) = \\alpha +\\beta x_i\\\\\n\\phi \\sim gamma(.01,.01)\n\\]\nOver dispersion in the rate parameter.\n\n\ngamma_distribution<-rgamma(1000,.01,.01)\nhist(gamma_distribution, breaks = 100)\n\n\n\n\nThe expected value of a poisson and the variance of poisson variable are the same: lamda. However often (typically) this assumption is violated, and the random variables in one’s data set are over-dispersed.\nTo see this, lets simulate data with overdispersion\n\n\nlibrary(MASS)\nn <- 100\nx <- runif(n, -2, 2)\na <- 1\nb <- 2\nout <- a + b  * x\n\nset.seed(999)\n\ny <- rnegbin(n,  mu =exp(out), theta = 2) # mean overdistribution parameter\nfake2 <- data.frame(x=x, y=y)\nhist(fake2$y, breaks = 50)\n\n\n\n\nWe fit a poisson model:\n\n\n\nnb1<- glm(y ~ x, family = poisson, fake2)\nsummary(nb1)\n\n\n\nCall:\nglm(formula = y ~ x, family = poisson, data = fake2)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-9.7583  -1.3352  -0.4345   0.8231  11.6413  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.91028    0.07736   11.77   <2e-16 ***\nx            2.07293    0.04596   45.10   <2e-16 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 6242.37  on 99  degrees of freedom\nResidual deviance:  961.42  on 98  degrees of freedom\nAIC: 1249.2\n\nNumber of Fisher Scoring iterations: 5\n\nperformance::check_overdispersion(nb1)\n\n\n# Overdispersion test\n\n       dispersion ratio =   9.769\n  Pearson's Chi-Squared = 957.369\n                p-value = < 0.001\n\nTry a negative binomial model\n\n\nnb2<- glm.nb(y ~ x,  data = fake2)\n\n\n\n\n\ncompare_models(nb1,nb2)\n\n\nParameter    |               nb1 |               nb2\n----------------------------------------------------\n(Intercept)  | 0.91 (0.76, 1.06) | 1.00 (0.76, 1.25)\nx            | 2.07 (1.98, 2.16) | 2.00 (1.80, 2.20)\n----------------------------------------------------\nObservations |               100 |               100\n\n\n\nplot(ggeffects::ggpredict(nb1,terms=\"x\"), add.data = TRUE)\n\n\n\n\n\n\nplot(ggeffects::ggpredict(nb2,terms=\"x\"), add.data = TRUE)\n\n\n\n\nIt is clear both from the test statistics and the graphs, that the negative binomial model provides a better fit.\nHow would a normal linear model do here?\n\n\nlmnb<- lm(y ~ x,  fake2)\nplot(ggeffects::ggpredict(lmnb,terms=\"x\"), add.data = TRUE)\n\n\n\n\nThe answer is: not very well.\nZero-inflated poisson/ neg binomial regression\nLink function for zero-inflated poisson\n\\[\ny_i \\sim ZIPoisson(p_i, \\lambda_i)\\\\\nlogit(p_i) = \\alpha_p + \\beta_p x_i \\\\\nlog(\\lambda) = \\alpha_\\lambda + \\beta\\lambda x_i\n\\]\nIn the nz dataset, volunteering (hours of charity) look to be zero-inflated, and also over-dispersed.\n\n\nhist(nz$HoursCharity, breaks = 100)\n\n\n\n\nWe can quickly check the proportion of people who report zero volunteering:\n\n\nsum(nz$HoursCharity ==0, na.rm=TRUE)/nrow(nz)\n\n\n[1] 0.6826594\n\nWe can get a sense of over-dispersion by looking at the ration of the sample variation to the sample mean?\n\n\nsd(nz$HoursCharity, na.rm=TRUE)/mean(nz$HoursCharity, na.rm=TRUE)^2\n\n\n[1] 1.680429\n\nThere’s about 1.68 more dispersion that a poisson model would expect\nLet’s use the performance package to formally check both zero-inflation and overdispersed\n\n\nz1 <-glm(HoursCharity ~ 1, family = \"poisson\", data = nz)\n\ncheck_zeroinflation(z1)\n\n\n# Check for zero-inflation\n\n   Observed zeros: 1992\n  Predicted zeros: 536\n            Ratio: 0.27\n\nNext check for over-dispersion:\n\n\ncheck_overdispersion(z1)\n\n\n# Overdispersion test\n\n       dispersion ratio =    13.196\n  Pearson's Chi-Squared = 37595.179\n                p-value =   < 0.001\n\nAnd indeed, we find both.\nIntroducing brms for estimating complex regression models\nI use the brms package to estimate zero-inflated and/or negative binomial models\nZero_inflated_poisson model syntax\n\n\nlibrary(brms)\n\n# Requires integer output \nnz$HoursCharity <- as.integer(nz$HoursCharity)\n\n# \nnz['Household.INC_s'] = as.data.frame(scale(nz$Household.INC))\n\n# Scale religion variabile\nnz['Relid_s'] = as.data.frame(scale(nz$Relid))\n\nb0<- brms::brm(HoursCharity ~ Relid_s + Household.INC_s, \n                family = \"zero_inflated_poisson\",\n                file = here::here(\"models\", \"zeroinflated_poisson_volunteer\"), \n               data = nz)\n\n\n\n\n\nsummary(b0)\n\n\n Family: zero_inflated_poisson \n  Links: mu = log; zi = identity \nFormula: HoursCharity ~ Relid_s + Household.INC_s \n   Data: nz (Number of observations: 2796) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept           1.70      0.02     1.67     1.73 1.00\nRelid_s             0.00      0.01    -0.02     0.03 1.00\nHousehold.INC_s    -0.09      0.02    -0.12    -0.05 1.00\n                Bulk_ESS Tail_ESS\nIntercept           3785     3068\nRelid_s             4501     3362\nHousehold.INC_s     3704     3054\n\nFamily Specific Parameters: \n   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nzi     0.70      0.01     0.68     0.72 1.00     3849\n   Tail_ESS\nzi     2989\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nMy preferred way of graphing the predicted effects of religious identification on volunteering is to generate prediction lines from the posterior samples. This captures uncertainty in an intuitive way. I’ll explain the mechanics when we get to Bayesian estimation, which, by the way, we are already doing here.\n\n\nplot(\n  conditional_effects(\n    b0,\n    spaghetti = TRUE,\n    nsamples = 100,\n    select_points = 0.1\n  ),\n  points = TRUE,\n  point_args = list(alpha = 0.1,\n                    width = .02)\n) #  note this command controls which facet \n\n\n\n\nZero_inflated_negbinomial model syntax\n\n\nb1 <- brms::brm(HoursCharity ~ Relid_s + Household.INC_s, \n                family = \"zero_inflated_negbinomial\",\n                file = here::here(\"models\", \"zeroinflated_neg_bin_volunteer\"),\n                data = nz)\n\n\n\n\n\nsummary(b1)\n\n\n Family: zero_inflated_negbinomial \n  Links: mu = log; shape = identity; zi = identity \nFormula: HoursCharity ~ Relid_s + Household.INC_s \n   Data: nz (Number of observations: 2796) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept           0.89      0.17     0.52     1.17 1.00\nRelid_s             0.21      0.06     0.11     0.33 1.00\nHousehold.INC_s    -0.07      0.05    -0.16     0.03 1.00\n                Bulk_ESS Tail_ESS\nIntercept            949      885\nRelid_s             1456     1698\nHousehold.INC_s     2061     2040\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nshape     0.28      0.07     0.16     0.42 1.00      938\nzi        0.35      0.11     0.07     0.50 1.00      939\n      Tail_ESS\nshape      914\nzi         697\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nCompare fits of the two models using leave one out cross-validation.\nNote that on this index, negative numbers are worse (sorry to confuse…)\n\n\nb0 <- add_criterion(b0, \"loo\")\nb1 <- add_criterion(b1, \"loo\")\n\nw <-loo_compare(b0, b1, criterion = \"loo\")\nw\n\n\n   elpd_diff se_diff\nb1     0.0       0.0\nb0 -1514.8     207.5\n\nRecall we hadbeen using and AIC/BIC convention to estimate improvements in goodness of fit. We can generate an analous index as follows:\n\n\ncbind(waic_diff = w[, 1] * -2,\n      se        = w[, 2] * 2)\n\n\n   waic_diff       se\nb1     0.000   0.0000\nb0  3029.657 414.9648\n\nAnd we can see that the negative binomial model fits much better.\nA model for your zeros\nThe estimates in the graphs above are only for the positive (non-zero components of the model). Let’s look at the results again:\n\n\nsummary(b1)\n\n\n Family: zero_inflated_negbinomial \n  Links: mu = log; shape = identity; zi = identity \nFormula: HoursCharity ~ Relid_s + Household.INC_s \n   Data: nz (Number of observations: 2796) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n                Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept           0.89      0.17     0.52     1.17 1.00\nRelid_s             0.21      0.06     0.11     0.33 1.00\nHousehold.INC_s    -0.07      0.05    -0.16     0.03 1.00\n                Bulk_ESS Tail_ESS\nIntercept            949      885\nRelid_s             1456     1698\nHousehold.INC_s     2061     2040\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nshape     0.28      0.07     0.16     0.42 1.00      938\nzi        0.35      0.11     0.07     0.50 1.00      939\n      Tail_ESS\nshape      914\nzi         697\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nThe probability of non-volunteering in the preferred model for people who are at the mean Religious Identification and mean Household income in this population is plogis(.35) or 0.5866176. More often than not, we should predict zeros in this population. What predicts the zero component of the model? We can use this syntax:\n\n\nb2 <- brms::brm(\n  bf(HoursCharity ~ Relid_s + Household.INC_s, # note: use `bf` when you have more than one model, as we do here\n     zi ~ Relid_s + Household.INC_s),\n  family = \"zero_inflated_negbinomial\",\n  file = here::here(\"models\", \"zeroinflated_nb_2_volunteer\"),\n  data = nz)\n\n\n\nLet’s look at the results:\n\n\nsjPlot::tab_model(b2)\n\n\n\n \n\n\nHoursCharity\n\n\nPredictors\n\n\nIncidence Rate Ratios\n\n\nCI (95%)\n\n\nCount Model\n\n\nIntercept\n\n\n3.40\n\n\n2.85 – 3.95\n\n\nRelid_s\n\n\n1.02\n\n\n0.94 – 1.11\n\n\nHousehold.INC_s\n\n\n0.93\n\n\n0.84 – 1.03\n\n\nZero-Inflated Model\n\n\nIntercept\n\n\n1.06\n\n\n0.72 – 1.38\n\n\nRelid_s\n\n\n0.52\n\n\n0.42 – 0.61\n\n\nHousehold.INC_s\n\n\n1.02\n\n\n0.87 – 1.17\n\n\nObservations\n\n\n2796\n\n\nR2 Bayes\n\n\n0.015\n\n\nInterpretation\nWe can graph the results using ggeffects::\nReligious identification:\n\n\nplot(ggeffects::ggpredict(b2, terms = c(\"Relid_s\")), \n    add.data = TRUE,  # doesn't work\n     dot.alpha = .2,  \n     facet = TRUE)  + ylim(0, 5)\n\n\n\n\nHousehold income:\n\n\nplot(ggeffects::ggpredict(b2, terms = c(\"Household.INC_s\")), \n    add.data = TRUE,  # doesn't work\n     dot.alpha = .2,  \n     facet = TRUE)  + ylim(0, 5) +  xlim(0, 5)\n\n\n\n\nOr using my preferred method\nPredicted effects of religious identification:\n\n\nplot(\n  conditional_effects(\n    b2,\n    spaghetti = TRUE,\n    nsamples = 100,\n    select_points = 0.1\n  ),\n  points = TRUE,\n point_args = list(alpha = 0.05,\n                    width = .02),\n ask = FALSE\n)  + # note this command controls which facet \n  ylim(0,5)\n\n\n\nNULL\n\nNote:\n\nModels of class brmsfit always condition on the zero-inflation component, if the model has such a component. Hence, there is no type = “zero_inflated” nor type = “zi_random” for brmsfit-models, because predictions are based on draws of the posterior distribution, which already account for the zero-inflation part of the model.\n\nSee package description\nComparing models we find that adding the prdictors improves the model\n\n\nb2 <- add_criterion(b2, \"loo\")\n\nw <-loo_compare(b0, b1, b2,  criterion = \"loo\")\nw\n\n\n   elpd_diff se_diff\nb2     0.0       0.0\nb1   -50.0      10.1\nb0 -1564.8     206.1\n\nAgain we can use an -2 * loglik analogue\n\n\n\ncbind(waic_diff = w[, 1] * -2,\n      se        = w[, 2] * 2)\n\n\n   waic_diff        se\nb2    0.0000   0.00000\nb1  100.0416  20.14189\nb0 3129.6983 412.13260\n\nPosterior predictive checks\nThese help to show the implications of our modelling decisions\nZero-inflated poisson PP check\n\n\nbrms::pp_check(b0) + xlim(0, 5)\n\n\n\n\nZero-inflated negative binomial with no predictors for the zero-inflation PP check\n\n\nbrms::pp_check(b1) + xlim(0, 5)\n\n\n\n\nZero-inflated negative binomial with zero-inflation predictors PP check\n\n\nbrms::pp_check(b2) + xlim(0, 5)\n\n\n\n\n\n\nsummary(b2)\n\n\n Family: zero_inflated_negbinomial \n  Links: mu = log; shape = identity; zi = logit \nFormula: HoursCharity ~ Relid_s + Household.INC_s \n         zi ~ Relid_s + Household.INC_s\n   Data: nz (Number of observations: 2796) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n                   Estimate Est.Error l-95% CI u-95% CI\nIntercept              1.22      0.08     1.05     1.37\nzi_Intercept           0.05      0.16    -0.33     0.32\nRelid_s                0.02      0.04    -0.06     0.10\nHousehold.INC_s       -0.07      0.05    -0.17     0.03\nzi_Relid_s            -0.66      0.09    -0.88    -0.50\nzi_Household.INC_s     0.02      0.07    -0.14     0.16\n                   Rhat Bulk_ESS Tail_ESS\nIntercept          1.00     1657     2031\nzi_Intercept       1.00     1466     1395\nRelid_s            1.00     3142     2943\nHousehold.INC_s    1.00     3404     2974\nzi_Relid_s         1.00     2096     1704\nzi_Household.INC_s 1.00     2964     2613\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nshape     0.45      0.06     0.33     0.58 1.00     1510\n      Tail_ESS\nshape     1500\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nReporting\nYou can start with the report package to generate reports. However, be careful about reporting using boilerplate because it is up to you, as an applied scientist, to interpret your results\nFor example the report package describes the \\(R^2\\) statistic. For reasons we can discuss in lab, this statistic is problematic, especially for observational studies.\nA better option for expressing practical interest of a result is to describe the expected values of out an outcome across a range of predictors. We have been doing this all along with our graphical models. However, you might want to report the numbers for these expected values as well. For this purpose, the ggeffects package can be handy. You merely leave out the plot component of your syntax:\n\n\nggeffects::ggpredict(b2, terms = \"Relid_s\")\n\n\n# Predicted counts of HoursCharity\n# x = Relid_s\n\n    x | Predicted |       95% CI\n--------------------------------\n-0.64 |      1.29 | [1.14, 1.46]\n-0.25 |      1.51 | [1.36, 1.68]\n 0.15 |      1.74 | [1.58, 1.92]\n 0.54 |      1.97 | [1.78, 2.18]\n 0.94 |      2.19 | [1.96, 2.44]\n 1.33 |      2.40 | [2.13, 2.72]\n 1.73 |      2.60 | [2.26, 2.99]\n 2.12 |      2.78 | [2.36, 3.27]\n\nAdjusted for:\n* Household.INC_s = 0.01\n\nHere, we have generated the predicted magnitudes of volunteering across the full range of the response variables (Religious Identification, as measured in standard deviation units). The expected volunteering rate of a secular person when other predictors are set to zero is: 1.23 hours [CI 95% 1.14, 1.46] and for a fully religiously identified person when all other predictors are set to zero it is 2.78 hours (CI 95% [2.35, 3.28])\nWe might want to focus on different elements of the model. The expected volunteering among the secular population (when other predictors are set to zero) who volunteersis exp(1.23): 3.421 and for a religious person (when other predictors are set to zero) who volunteers is: exp(1.23 + .02 *  2.12):3.569. expected zero-rate among the secular population is plogis(0.05) 0.512; for a fully identified religious person it is plogis(0.05 + -0.65 *  2.12): 0.209. This suggests that religious people are less zero-inflated. However among those who volunteer, religion isn’t predicting much of a difference in the number of hours one volunteers (in the baseline population).\nIs this interesting? Rather than averaging across both the zero-inflated and volunteering populations, it might be more informative to separately describe behaviour among each of these distinct populations. Remember, as applied scientists, we are not merely trying to be explicit about our assumptions and decisions. We’re trying to improve our beliefs relating to some concrete question. Our reporting must reflect our scientific interests. It must clarify what we’ve learned about the world, as well as how we remain uncertain.\nSummary\nToday:\nWe have clarified that all linear regression models are “generalised linear model” because all linear regression models imply a link function. Prior to this week, we’d been working with the gaussian linear model, in which the link function is the identify function. However, the Gaussian linear model is a special case.\nThis has taken us a step further into understanding how confusing the term ‘linear’ can be. We’ve already shown that quadratic predictors and splines enable us to estimate non-linerity in the relationships between predictor and response parameters. However, now we can see that the entire edifice of regresion is built upon the link function. This is a non-linear mapping from expected responses to additive and multiplicative predictors.\n\nWe have demonstrated how to write four classes of generalised linear models:\nLogistic regression models, which apply to binary responses;\nPoisson regression models, which apply to rates;\nNegative binomial models (over-dispersed poisson regression models)\nZero-inflated poisson/negative binomial models, in which rates contain an over abundance of zeros.\n\nWe have clarified how to interpret and report the results of a generalised linear model using graphical strategies.\nAppendix 1\nIf you want to graph each predictor separately emply the [[1]] or [[2] syntax as follows:]\nPredicted effects of religious identification\n\n\nb2_p1 <- plot(\n  conditional_effects(\n    b2,\n    spaghetti = TRUE,\n    nsamples = 100,\n    select_points = 0.1\n  ),\n  points = TRUE,\n  ask = TRUE,\n  point_args = list(alpha = 0.1,\n                    width = .02)\n)[[1]]  + # note this command controls which facet\n  ylim(0, 5) + labs(title = \"Better title\",\n                                 subtitle = \"better subtitle\") +\n  xlab(\"Religious Identification (SD units)\") +\n  ylab(\"Hours volunteering in the previous week\")\n\n\n\nPredicted effects of income:\n\n\nlibrary(\"patchwork\")\nb2_p1 + b2_p2\n\n\n\n\nAppendix 2\nWe have covered lots of ground today. The generalised linear models described here are the most commponplace. However there are many more. For those who are curious on how to estimated zero inflated binary data, I recommend Solomon Kurz’s work here.\nAppendix 3\nAside: In Bayesian estimation we often estimate the standard deviation of the mean \\(\\sigma\\) , however outside these circles people we describe the same parameter as the variance of the mean, or \\(\\sigma^2\\).\nIt doesn’t really matter the parameters don’t care how we express them. We can say, “Johannes is 2 meters tall,” or we can say “Johannes is the square root of 4 meters tall” and his height will remain indifferent to our convention. So too, the world is indifferent to whether we write $\\sigma$ o r $\\sigma^2$\nAcknowledgments and References\nGelman, Hill, and Vehtari (2020)\nKurz (2020)\nBürkner and Vuorre (2019)\n\n\n\nBürkner, Paul-Christian, and Matti Vuorre. 2019. “Ordinal Regression Models in Psychology: A Tutorial.” Advances in Methods and Practices in Psychological Science 2 (1): 77–101.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.\n\n\nKurz, A. Solomon. 2020. Zenodo. https://doi.org/10.5281/zenodo.4080013.\n\n\nIt is worth cultivating this explicit habit because we will need it when clarifying our belielfs about the world prior to modelling the world (as we do in Bayesian modelling).↩︎\n",
    "preview": "posts/8_1/op.png",
    "last_modified": "2021-04-27T20:32:20+12:00",
    "input_file": {},
    "preview_width": 1000,
    "preview_height": 1000
  },
  {
    "path": "posts/7_1/",
    "title": "Multiple regression (ANOVA, ANOVCA, MANOVA)",
    "description": {},
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      }
    ],
    "date": "2021-04-20",
    "categories": [],
    "contents": "\n\nContents\nLearning objectives\nWhat is a regression model?\nHow do we interpret the results of a regression model?\nHow to get an interpretable intercept?\nMultiple regression\nMultiple regression with more than than two covariates\nMultiple regression with interactions\nHow do we select a model?\nCan we estimate multiple outcomes at the same time?\nANOVA\nANOVA and T-tests\n\nOne-way ANOVA\nTwo-way ANOVA\nMANOVA\nAppendix A: LaTeX tables\n\n\n\n\nLearning objectives\nBefore the break, we introduced basic concepts in statistical regression, focusing on regression using a single covariate.\nToday, we will introduce regression using multiple co-variates. You will acquire the following skills:\nUnderstand how to write a regression model with multiple co-variates in R.\nUnderstand how to interpret a regression model with multiple co-variates in R.\nUnderstand methods for comparing simple and complex models.\nUnderstand how to create a table for your results.\nUnderstand how to graph your results.\nUnderstand how to write equivalent models in an ANOVA framework, in case someone forces you to do this.\nWhat is a regression model?\nIn the first instance, linear regression is a method for predicting features of the world, or as we put it in lecture 5:\n\n[R]egression … is method for inferring the expected average features of a population, and the variance of a population, conditional on other features of the population as measured in a sample.\n\nIn week 9, we’ll discussion how to use regression for explaining features of the world. However, for the next two weeks, we’ll restrict our interests to prediction.\nTo referesh your memory about how the magic of prediction by regression works, let’s look at an example. Consider data collected in the 1920s on the relationship between the speed at which a car is travelling and the distance that it takes for that car to stop. The data are found in the cars dataset, which is automatically loaded when you start R.\nHere is our model:\n\n\nmodel_simple <- lm(dist ~ speed, data = cars)\n\n\n\nLet’s look at the output. You can create a table like this:\n\n\nparameters::parameters(model_simple)\n\n\nParameter   | Coefficient |   SE |          95% CI | t(48) |      p\n-------------------------------------------------------------------\n(Intercept) |      -17.58 | 6.76 | [-31.17, -3.99] | -2.60 | 0.012 \nspeed       |        3.93 | 0.42 | [  3.10,  4.77] |  9.46 | < .001\n\nRecall that we can create an html table in this way:\n\n\nparameters::parameters(model_simple)%>%\n    parameters::print_html(caption = \"Breaking distance as predicted by speed\")\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#ivepthrvkf .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ivepthrvkf .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ivepthrvkf .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ivepthrvkf .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ivepthrvkf .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ivepthrvkf .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ivepthrvkf .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ivepthrvkf .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ivepthrvkf .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ivepthrvkf .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ivepthrvkf .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ivepthrvkf .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ivepthrvkf .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ivepthrvkf .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#ivepthrvkf .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#ivepthrvkf .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ivepthrvkf .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#ivepthrvkf .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ivepthrvkf .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#ivepthrvkf .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ivepthrvkf .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ivepthrvkf .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ivepthrvkf .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ivepthrvkf .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ivepthrvkf .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ivepthrvkf .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ivepthrvkf .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ivepthrvkf .gt_left {\n  text-align: left;\n}\n\n#ivepthrvkf .gt_center {\n  text-align: center;\n}\n\n#ivepthrvkf .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ivepthrvkf .gt_font_normal {\n  font-weight: normal;\n}\n\n#ivepthrvkf .gt_font_bold {\n  font-weight: bold;\n}\n\n#ivepthrvkf .gt_font_italic {\n  font-style: italic;\n}\n\n#ivepthrvkf .gt_super {\n  font-size: 65%;\n}\n\n#ivepthrvkf .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nBreaking distance as predicted by speed\n    \n    Parameter\n      Coefficient\n      SE\n      95% CI\n      t(48)\n      p\n    (Intercept)\n      -17.58\n      6.76\n      (-31.17, -3.99)\n      -2.60\n      0.012 \n    speed\n      3.93\n      0.42\n      (3.10, 4.77)\n      9.46\n      < .001\n    \n\nHow do we interpret the results of a regression model?\nRecall that the report package makes your life easy:\n\n\nreport::report(model_simple)\n\n\nWe fitted a linear model (estimated using OLS) to predict dist with speed (formula: dist ~ speed). The model explains a statistically significant and substantial proportion of variance (R2 = 0.65, F(1, 48) = 89.57, p < .001, adj. R2 = 0.64). The model's intercept, corresponding to speed = 0, is at -17.58 (95% CI [-31.17, -3.99], t(48) = -2.60, p < .05). Within this model:\n\n  - The effect of speed is statistically significant and positive (beta = 3.93, 95% CI [3.10, 4.77], t(48) = 9.46, p < .001; Std. beta = 0.81, 95% CI [0.64, 0.98])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset.\n\nHowever, before you go rushing to report your “signficant” p-value, how shall we intepret this output?\nRecall that can write the output of a model as an equation.\nThe equatiomatic package in R makes this work easy for you.\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(model_simple,  use_coefs = TRUE)\n\n\n\\[\n\\operatorname{\\widehat{dist}} = -17.58 + 3.93(\\operatorname{speed})\n\\]\n\n\\[\n\\operatorname{\\widehat{dist}} = -17.58 + 3.93(\\operatorname{speed})\n\\]\nThe generic form of the a linear model is:\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(model_simple,  use_coefs = FALSE)\n\n\n\\[\n\\operatorname{dist} = \\alpha + \\beta_{1}(\\operatorname{speed}) + \\epsilon\n\\]\n\nThe model says that the expected stopping distance for a car is -17.58 feet when the care is traveling zero mph; To this we an additional 3.93 feet for each additional unit of speed (here in miles per hour).\nWhat strikes you about this model?\nIf you are like me you probably feel confusion when you see the number “-17.58” predicting speed 😲. Did car manufacturers of the 1920s invent a method for traversing space and time as we know it 🤔? Or is regression a hopeless tool for understanding the world and should you demand your money back for this course 😿?\nLet’s look at the data more carefully:\n\n\ncars%>%\n  dplyr::arrange(speed)%>%\n  tibble()\n\n\n# A tibble: 50 x 2\n   speed  dist\n   <dbl> <dbl>\n 1     4     2\n 2     4    10\n 3     7     4\n 4     7    22\n 5     8    16\n 6     9    10\n 7    10    18\n 8    10    26\n 9    10    34\n10    11    17\n# … with 40 more rows\n\nWe can see that the lowest speed measured in this dataset is 4 miles per hour, at which distance the car stopped in 2 feet. Another car travelling at 4 mph took 10 feet to stop. So there’s variability.\nLet’s plug these two numbers into the regression equation that we just estimated. We do not need to copy and paste coefficients from the output of the model. Rather we can recover the intercept as follows:\n\n\ncoef(model_simple)[[1]]\n\n\n[1] -17.57909\n\nAnd for each mph thereafter we just multiply by this value\n\n\ncoef(model_simple)[[2]]\n\n\n[1] 3.932409\n\nSo we can write the expected (or predicted) speed for a car travelling at the maximum speed in the dataset (25) as follows:\n\n\ncoef(model_simple)[[1]] + coef(model_simple)[[2]] * max(cars$speed, na.rm = TRUE)\n\n\n[1] 80.73112\n\nand for the minimum speed (4) as follows:\n\n\ncoef(model_simple)[[1]] + coef(model_simple)[[2]] * min(cars$speed, na.rm = FALSE)\n\n\n[1] -1.84946\n\nIs this any better? We’re still getting a negative speed.\nTo avoid confusion, let’s turn to the most useful tool in your R toolkit, your graph.\nWe can plot the model as follows:\n\n\nlibrary(ggplot2)\nggplot2::ggplot(data = cars, \n                aes( x = speed,  y = dist )) +\n  geom_smooth(method = \"lm\") + \n  geom_point() + theme_classic()\n\n\n\n\nHere, our linear model is minimising the average distance between between observed speed and observed distance in the sample. The model hits at most a few points in the dataset. Otherwise it estimates a response that is either too high or two low.\nNote that by allowing our predictor variable to start at 0 we render the intercept term -17.5790949 in our model un-interpretable.\nThere is no coherent concept we can attach to an expected stopping distance from an expected speed of 0 mp, and the value 0mph never occurs in the dataset.\nHow to get an interpretable intercept?\nCenter (or center and scale) all your continuous predictors. In such a model, the intercept is interpretable as the expected response when all continuous predictors are set to their sample average, which in this case is 15.4 mph.\nRecall that we can center our variables using the following code\n\n\n# center and create new dataframe\nschmars <- cars\n\n# not that I am presently having trouble with dplyr output. The following code will allow me to graph results (which I found by searching stackoverflow.com)\n\nschmars['speed_c'] = as.data.frame(scale(schmars$speed, scale = FALSE) )# work around for a bug - center and convert to decade units\nschmars$speed_c\n\n\n [1] -11.4 -11.4  -8.4  -8.4  -7.4  -6.4  -5.4  -5.4  -5.4  -4.4  -4.4\n[12]  -3.4  -3.4  -3.4  -3.4  -2.4  -2.4  -2.4  -2.4  -1.4  -1.4  -1.4\n[23]  -1.4  -0.4  -0.4  -0.4   0.6   0.6   1.6   1.6   1.6   2.6   2.6\n[34]   2.6   2.6   3.6   3.6   3.6   4.6   4.6   4.6   4.6   4.6   6.6\n[45]   7.6   8.6   8.6   8.6   8.6   9.6\n\n# model\nmodel_simple2 <- lm(dist ~ speed_c, data = schmars)\n\n# graph\nparameters::parameters(model_simple2)%>%\n  print_html()\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#fwefldpmbt .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#fwefldpmbt .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fwefldpmbt .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#fwefldpmbt .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#fwefldpmbt .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fwefldpmbt .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fwefldpmbt .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#fwefldpmbt .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#fwefldpmbt .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#fwefldpmbt .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#fwefldpmbt .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#fwefldpmbt .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#fwefldpmbt .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#fwefldpmbt .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#fwefldpmbt .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#fwefldpmbt .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#fwefldpmbt .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#fwefldpmbt .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fwefldpmbt .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#fwefldpmbt .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fwefldpmbt .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#fwefldpmbt .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#fwefldpmbt .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fwefldpmbt .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fwefldpmbt .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#fwefldpmbt .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fwefldpmbt .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#fwefldpmbt .gt_left {\n  text-align: left;\n}\n\n#fwefldpmbt .gt_center {\n  text-align: center;\n}\n\n#fwefldpmbt .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#fwefldpmbt .gt_font_normal {\n  font-weight: normal;\n}\n\n#fwefldpmbt .gt_font_bold {\n  font-weight: bold;\n}\n\n#fwefldpmbt .gt_font_italic {\n  font-style: italic;\n}\n\n#fwefldpmbt .gt_super {\n  font-size: 65%;\n}\n\n#fwefldpmbt .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nModel Summary\n    \n    Parameter\n      Coefficient\n      SE\n      95% CI\n      t(48)\n      p\n    (Intercept)\n      42.98\n      2.18\n      (38.61, 47.35)\n      19.76\n      < .001\n    speed_c\n      3.93\n      0.42\n      (3.10, 4.77)\n      9.46\n      < .001\n    \n\nNotice that the estimated coefficient in for speed is this second model is the same as the estimated coefficient for speed in the first model:\n\n\n# evaluate whether the two coefficients are the same at least to five decimal places\nround(coef(model_simple)[[2]],5) == round(coef(model_simple2)[[2]],5)\n\n\n[1] TRUE\n\nAnd the graph is identical:\n\n\nggplot2::ggplot(data = cars, \n                aes( x = speed,  y = dist )) +\n  geom_smooth(method = \"lm\") + \n  geom_point()\n\n\n\n\nHowever, the intercept is now meaningful. It is the expected (or predicted) outcome when speed is set to its sample average (25mph)\n\n\nround(coef(model_simple2)[[1]],5)\n\n\n[1] 42.98\n\nWestill interpret the coefficient for speed as the expected increase or decrease in stopping distance for a one-unit change in speed (which was measured in miles per hour in the population from which this sample was collected. For a car travelling 3 mph faster than the sample average we would expect an average stopping distance of:\n\n\ncoef(model_simple2)[[1]] + coef(model_simple2)[[2]] * 3\n\n\n[1] 54.77723\n\nAnd for a car travelling 10.33 mph slower than the sampling average we would expect an average stopping distance of:\n\n\ncoef(model_simple2)[[1]] + coef(model_simple2)[[2]] * 10.33\n\n\n[1] 83.60178\n\nRecall that you can create a nice prediction plot using the ggeffects package:\n\n\n# graph espected means\nplot(ggeffects::ggpredict(model_simple2, terms = \"speed_c [all]\"), \n     add.data = TRUE, \n     dot.alpha = .8, \n    # jitter = .01, \n     ci.style = \"errorbar\") + \n  ylab(\"Distance in feet\") + \n  xlab(\"Speed in MPH (centered at 25 mph\") + \n  labs(title = \"Predicted average stopping distance by speed for cars in the 1920s\",\n       subtitle = \"Speed centered at 25 MPH\") + theme_classic()\n\n\n\n\nor another method:\n\n\n# graph espected means\nplot(ggeffects::ggpredict(model_simple2, terms = \"speed_c [all]\"), \n     add.data = TRUE, \n     dot.alpha = .8, \n     jitter = .01) + \n  ylab(\"Distance in feet\") + \n  xlab(\"Speed in MPH (centered at 25 mph\") + \n  labs(title = \"Predicted average stopping distance by speed for cars in the 1920s\",\n       subtitle = \"Speed centered at 25 MPH\") + theme_classic()\n\n\n\n\nThe essential take home messages about regression are as follows:\ninspect your data\ncenter your continuous predictors (standardise? maybe…)\ngraph your model\ngenerate a prediction plot\nMultiple regression\nWe have already encountered multiple regression. Perhaps the most familiar case is prediction. Suppose we want to predict someones expected income based on their gender identification. Suppose we theory is true there might be an added income advantage from height. We can include an additional term in our model and evaluate whether or theory is true. Let’s assess this question using the jittered NZAVS dataset.\n\n\n\n\n\n\nHere is a regression model with two predictors. We have centered height to the population average. The outcome is expected household income for the NZ population simultaneously stratified by height and by male identification. (Question: can you think of why household income is not an ideal indicator in a setting where we are looking at gender differences…? We’ll come back to this question in a few weeks.)\n\n\n# model\nmodel_theory <- lm(income ~ height_cm_c + not_male, data = df)\nsjPlot::tab_model(model_theory)\n\n\n\n \n\n\nincome\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n142397.64\n\n\n131258.64 – 153536.64\n\n\n<0.001\n\n\nheight_cm_c\n\n\n1382.24\n\n\n611.54 – 2152.94\n\n\n<0.001\n\n\nnot_male [Not_Male]\n\n\n-9927.30\n\n\n-25243.88 – 5389.29\n\n\n0.204\n\n\nObservations\n\n\n1731\n\n\nR2 / R2 adjusted\n\n\n0.020 / 0.019\n\n\nHow do we interpret this model? First we can write the equation:\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(model_theory,  use_coefs = FALSE)\n\n\n\\[\n\\operatorname{income} = \\alpha + \\beta_{1}(\\operatorname{height\\_cm\\_c}) + \\beta_{2}(\\operatorname{not\\_male}_{\\operatorname{Not\\_Male}}) + \\epsilon\n\\]\n\nAnd plugging in the values\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(model_theory,  use_coefs = TRUE)\n\n\n\\[\n\\operatorname{\\widehat{income}} = 142397.64 + 1382.24(\\operatorname{height\\_cm\\_c}) - 9927.3(\\operatorname{not\\_male}_{\\operatorname{Not\\_Male}})\n\\]\n\nFirst we need the average sample height (across all gender identifications):\n\n\nmean(nz_0$HLTH.Height, na.rm=TRUE)\n\n\n[1] 1.694277\n\nThe model tells us the following. The expected household income for the population of men who are at the sample average height is: 1.4239764^{5}.The expected increase in income for each additional centimeter of height whether or not one is male or not-male identified is 1382.2392856. The expected reduction in income for people who do not identify as male is -9927.2961633.\nAre men expected to make -9927.2961633 more than woman?\nNo because on average non-male is shorter and we are stratifying across male and non-male gender identifications. If we focus only on the gender difference we can include male-id and remove height and this gives us:\n\n\nmodel_theory2 <- lm(income ~ not_male, data = df)\nsjPlot::tab_model(model_theory2)\n\n\n\n \n\n\nincome\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n153753.08\n\n\n144623.34 – 162882.82\n\n\n<0.001\n\n\nnot_male [Not_Male]\n\n\n-28349.98\n\n\n-39814.07 – -16885.89\n\n\n<0.001\n\n\nObservations\n\n\n1736\n\n\nR2 / R2 adjusted\n\n\n0.013 / 0.013\n\n\nWe write the model equation here:\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(model_theory2,  use_coefs = FALSE)\n\n\n\\[\n\\operatorname{income} = \\alpha + \\beta_{1}(\\operatorname{not\\_male}_{\\operatorname{Not\\_Male}}) + \\epsilon\n\\]\n\nAnd plugging in the values\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(model_theory,  use_coefs = TRUE)\n\n\n\\[\n\\operatorname{\\widehat{income}} = 142397.64 + 1382.24(\\operatorname{height\\_cm\\_c}) - 9927.3(\\operatorname{not\\_male}_{\\operatorname{Not\\_Male}})\n\\]\n\nThus the expected not-male income is 153753.08 - 28349.98 = or about $NZD 125,400.\nWe can recover this expectation in the original model by adding the difference between the sample averages in male heights over not-male heights as follows:\nFind approx deviations in male height and female heights from sample:\n\n\ndf%>%\n  group_by(not_male)%>%\n  summarise(genmean = mean(HLTH.Height, na.rm = TRUE))\n\n\n# A tibble: 3 x 2\n  not_male genmean\n  <chr>      <dbl>\n1 Male        1.78\n2 Not_Male    1.65\n3 <NA>        1.69\n\n# difference \ndf%>%\n  summarise(mean = mean(HLTH.Height, na.rm = TRUE))\n\n\n      mean\n1 1.698797\n\nPlug in expected values for male Id:\n\n\ncoef(model_theory)[[1]] + # intercept at average height\n  coef(model_theory)[[2]]* 8.3 + #increase in average male height over sample average in cm\n  coef(model_theory)[[3]]* 0 # code for male id = 0\n\n\n[1] 153870.2\n\nAnd for not-male Id:\n\n\ncoef(model_theory)[[1]] + coef(model_theory)[[2]]* - 4.7  + coef(model_theory)[[3]]*1\n\n\n[1] 125973.8\n\nThese are the equivalent expectations to the stratified models.\nEither way you cut it, we find that women (and others who do not identify as male) are are expected to make -2.8349981^{4} less in household income than men.\nMultiple regression with more than than two covariates\nNote that regression allows us to stratify across other segments of a population by adding even more co-variates.\nLet’s add education to the model. In the NZAVS education Edu is a 10-level factor. However, for now, we’ll think of it as numeric. A standard deviation of Edu is 2.5441461 out of 0 to 10. Adding edu_s to the model we find:\n\n\nmodel_theory3 <- lm(income ~ height_cm_c + not_male + edu_s, data = df)\nsjPlot::tab_model(model_theory3)\n\n\n\n \n\n\nincome\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n147759.81\n\n\n136605.32 – 158914.29\n\n\n<0.001\n\n\nheight_cm_c\n\n\n1101.24\n\n\n331.45 – 1871.03\n\n\n0.005\n\n\nnot_male [Not_Male]\n\n\n-17251.89\n\n\n-32584.57 – -1919.22\n\n\n0.027\n\n\nedu_s\n\n\n21228.03\n\n\n15726.56 – 26729.50\n\n\n<0.001\n\n\nObservations\n\n\n1710\n\n\nR2 / R2 adjusted\n\n\n0.053 / 0.051\n\n\nWe write the model equation as follows:\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(model_theory3,  use_coefs = FALSE)\n\n\n\\[\n\\operatorname{income} = \\alpha + \\beta_{1}(\\operatorname{height\\_cm\\_c}) + \\beta_{2}(\\operatorname{not\\_male}_{\\operatorname{Not\\_Male}}) + \\beta_{3}(\\operatorname{edu\\_s}) + \\epsilon\n\\]\n\nAnd plugging in the values:\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(model_theory3,  use_coefs = TRUE)\n\n\n\\[\n\\operatorname{\\widehat{income}} = 147759.81 + 1101.24(\\operatorname{height\\_cm\\_c}) - 17251.89(\\operatorname{not\\_male}_{\\operatorname{Not\\_Male}}) + 21228.03(\\operatorname{edu\\_s})\n\\]\n\nDo height differences predict difference greater income differences ? To assess this we add an interaction term. NOTE: we should always center our interaction terms for the same reason that we should center polynomials: otherwise the multi-collinearity renders the model unstable\nMultiple regression with interactions\n\n\n# model\nmodel_theory4 <- lm(income ~ height_cm_c * not_male, data = df)\n\n\n\nNote that this model is equivalent to:\n\n\nmodel_theory4 <- lm(income ~ height_cm_c + not_male + not_male:height_cm_c, data = df)\n\n\n\nWe write the model equation as follows:\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(model_theory4,  use_coefs = FALSE)\n\n\n\\[\n\\operatorname{income} = \\alpha + \\beta_{1}(\\operatorname{height\\_cm\\_c}) + \\beta_{2}(\\operatorname{not\\_male}_{\\operatorname{Not\\_Male}}) + \\beta_{3}(\\operatorname{height\\_cm\\_c} \\times \\operatorname{not\\_male}_{\\operatorname{Not\\_Male}}) + \\epsilon\n\\]\n\nAnd plugging in the values:\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(model_theory4,  use_coefs = TRUE)\n\n\n\\[\n\\operatorname{\\widehat{income}} = 134509.3 + 2331.4(\\operatorname{height\\_cm\\_c}) - 5311.89(\\operatorname{not\\_male}_{\\operatorname{Not\\_Male}}) - 1618.13(\\operatorname{height\\_cm\\_c} \\times \\operatorname{not\\_male}_{\\operatorname{Not\\_Male}})\n\\]\n\nThe * in the model is merely shorthand for the two main effects height_cm_c + not_male \\(+\\) their interaction not_male:height_cm_c.\nLots graph the coefficients:\n\n\nsjPlot::plot_model(model_theory4)\n\n\n\n\nWhoooah what just happened?! There’s huge uncertainty about the main effect of male-id – it is no longer a reliable predictor in this model.\nIs the interaction messing up the model? We can look for mutli-collinearity using the following code from the performance package.\n\n\nz<-performance::check_collinearity(model_theory4)\nz ## looks ok\n\n\n# Check for Multicollinearity\n\nLow Correlation\n\n                 Term  VIF Increased SE Tolerance\n          height_cm_c 4.33         2.08      0.23\n             not_male 1.94         1.39      0.51\n height_cm_c:not_male 2.87         1.69      0.35\n\nplot(z) ## looks ok\n\n\n\n\nAs indicated in the graph, the problem isn’t multi-collinearity.\nDoes this mean that income is really predicted by height, and gender is a red herring?\nI have seen regression models interpreted that way. However this is confused. The confusion mounts when we compare the expected means of the population by stratifying on genderidentification:\n\n\nmodelbased::estimate_means(model_theory4)\n\n\nnot_male |     Mean |      SE |               95% CI\n----------------------------------------------------\nMale     | 1.34e+05 | 6903.13 | [1.21e+05, 1.48e+05]\nNot_Male | 1.29e+05 | 4312.74 | [1.21e+05, 1.38e+05]\n\np-values are uncorrected.\n\nHowever, our model has compared male-ids and not-male ids at equivalent levels of height. However, we know that non-male-id’s tend to be shorter.\nWherever you have interactions, it is essential to graph your results. This is so important I’m going to write it again: wherever you have interactions, it is essential to graph the results. Tables are inscrutable. We need probe our model by graphing its predictions. Recall that we can do this using the ggeffects package.\nHere is a graph comparing men/non male at different levels of height.\n\n\npp1 <- plot(ggeffects::ggpredict(model_theory4, terms = c(\"not_male\",\"height_cm_c\")))\npp1\n\n\n\n\nThe interpretation is now clear. Greater height predicts much greater income for males and non_males. However the importance of and equivalent change in height differs for non-males, which is much lower. There is a non-linearity in the predicted effects of height by gender. Or put another way, gender moderates income by height.\n\n\nterms = c(\"not_male\",\"height_cm_c\")\n\n\n\nOr equivalently, height moderates income by gender. We can graph this equivalent interpretation by reversing the order of our syntax. This gives us the same interpretation outcomes but visualised with income on the x-axis:\n\n\nterms = c(\"height_cm_c\",\"not_male\")\n\n\n\n\n\nx <- ggeffects::ggpredict(model_theory4, terms = c(\"height_cm_c\",\"not_male\"))\npp2 <- plot( x )\npp2\n\n\n\n\nMy preferred method for graphing is to include all the data points:\n\nadd.data = TRUE,\n\nThis allows us to see what happening in our dataset:\n\n\npp3 <- plot( x,\n      add.data = TRUE, \n      jitter = 0.2, \n      dot.alpha =.2,\n      ) + scale_y_continuous(limits = c(0,5e+5))  + \n  theme_classic()\n\npp3\n\n\n\n\nThere is a non-linearity in our model. The model predicts that, on average, short men are expected to make much less than short women. Among non male-ids, height differences are not a reliable predictor of household income. By contrast among male-ids, height differences are a reliable predictor. non-male-ids tend to be shorter than men by about 13cm.\nSample averages:\n\n\ndf%>%\n  summarise(mean(HLTH.Height, na.rm = TRUE))\n\n\n  mean(HLTH.Height, na.rm = TRUE)\n1                        1.698797\n\nSample differences by gender-id:\n\n\ndf%>%\n  group_by(not_male)%>%\n  summarise(mean(HLTH.Height, na.rm = TRUE))\n\n\n# A tibble: 3 x 2\n  not_male `mean(HLTH.Height, na.rm = TRUE)`\n  <chr>                                <dbl>\n1 Male                                  1.78\n2 Not_Male                              1.65\n3 <NA>                                  1.69\n\nLet’s plug in the values for male-id and not male-id at the population average for each population:\n\n\n# this is how to quickly generate the equation\nequatiomatic::extract_eq(model_theory4,  use_coefs = TRUE)\n\n\n\n\\[\n\\operatorname{\\widehat{income}} = 134509.3 + 233.14(\\operatorname{height\\_cm\\_c}) - 5311.89(\\operatorname{not\\_male}_{\\operatorname{Not\\_Male}}) - 161.81(\\operatorname{height\\_cm\\_c} \\times \\operatorname{not\\_male}_{\\operatorname{Not\\_Male}})\n\\] To get the expected average for the male-id population we could compute the regression equation as follows\n\n\ncoef(model_theory4)[[1]] + # intercept about 170 cm\n  coef(model_theory4)[[2]] * 80 + # male-id are 8 cm taller than sample average # note we include this even though the coefficient is unreliable\n  coef(model_theory4)[[3]]* 0 + # male-id are coded as zero  + \n  coef(model_theory4)[[4]]* 80 * 0 # 8cm difference * male-id are coded as zero  (which zeros this out)\n\n\n[1] 321021.6\n\nFor the female-id population we compute the regression equation as follows\n\n\ncoef(model_theory4)[[1]] + # intercept about 170 cm\n  coef(model_theory4)[[2]] * -50 + # not male-id are 5 cm shorter than sample average # \n  coef(model_theory4)[[3]]* 1 + # not male-id are coded as 1  + \n  coef(model_theory4)[[4]] * -50 # 5cm shorter * male-id are coded as zero  (which zeros this out)\n\n\n[1] 93533.57\n\nCompare these estimates with the model in which we did not have the interaction but only the additive predictors of male-id and height.\nWe can do this quickly using the modelbased package.\n\n\nmodelbased::estimate_means(model_theory2)\n\n\nnot_male |     Mean |      SE |               95% CI\n----------------------------------------------------\nMale     | 1.54e+05 | 4654.86 | [1.45e+05, 1.63e+05]\nNot_Male | 1.25e+05 | 3535.09 | [1.18e+05, 1.32e+05]\n\np-values are uncorrected.\n\nWe find that the estimates are similar.\nHow do we select a model?\nWhich model should we prefer? Answer: it depends on your question!\nWe’ll come back to this point when we focus on the uses of regression for causal inference (week 9). For now, you should now that there are no canned methods for selecting a model.\nHowever, because reviewers will ask, you can use the AIC or BIC information criteria to select a model. Recall that a decrease in the absolute values of either statistic offers a reason to prefer one model over the other.\n\n\nperformance::compare_performance(model_theory, \n                                 model_theory2,\n                                 model_theory3,\n                                 model_theory4)\n\n\n# Comparison of Model Performance Indices\n\nName          | Model |       AIC |       BIC |    R2 | R2 (adj.) |      RMSE |     Sigma\n-----------------------------------------------------------------------------------------\nmodel_theory  |    lm | 45318.490 | 45340.316 | 0.020 |     0.019 | 1.169e+05 | 1.170e+05\nmodel_theory2 |    lm | 45457.405 | 45473.783 | 0.013 |     0.013 | 1.172e+05 | 1.173e+05\nmodel_theory3 |    lm | 44725.128 | 44752.349 | 0.053 |     0.051 | 1.153e+05 | 1.155e+05\nmodel_theory4 |    lm | 45316.366 | 45343.648 | 0.023 |     0.021 | 1.168e+05 | 1.169e+05\n\nWe can graph the models along different criteria:\n\n\nxx <- performance::compare_performance(model_theory, \n                                 model_theory2,\n                                 model_theory3,\n                                 model_theory4)\n\nplot(xx)\n\n\n\n\nWe find that model three performed the best. Recall that this is the model that included education:\n\n\nmodel_theory3 <- lm(income ~ height_cm_c + not_male + edu_s, data = df)\n\n\n\nWhat if we were to include an interaction with height and male-id?\n\n\nmodel_theory6 <- lm(income ~ height_cm_c * not_male + edu_s, data = df)\n\n\n\nThere’s no improvement in this model. After adjusting for education, height, and male-id, we do not see an improvement from including a non-linear adjustment for the height effect for the different male-id factors:\n\n\nperformance::compare_performance(model_theory3,model_theory6)\n\n\n# Comparison of Model Performance Indices\n\nName          | Model |       AIC |       BIC |    R2 | R2 (adj.) |      RMSE |     Sigma\n-----------------------------------------------------------------------------------------\nmodel_theory3 |    lm | 44725.128 | 44752.349 | 0.053 |     0.051 | 1.153e+05 | 1.155e+05\nmodel_theory6 |    lm | 44723.874 | 44756.540 | 0.054 |     0.052 | 1.152e+05 | 1.154e+05\n\nWhat about if we were to include age? REcall that a linear model can (and often should) include non-linear terms. We encountered this point when we were discussing polynomials and splines. We can include a spline term for age using the bs command from the splines package.\n\n\nlibrary(\"splines\")\nmodel_theory7 <- lm(income ~ bs(age_10_c) + height_cm_c * not_male + edu_s, data = df)\nparameters::parameters(model_theory7)\n\n\nParameter                         | Coefficient |       SE |                95% CI |   t(1702) |      p\n-------------------------------------------------------------------------------------------------------\n(Intercept)                       |    88679.91 | 26433.28 | [ 36834.77, 1.41e+05] |      3.35 | < .001\nage_10_c [1st degree]             |    1.06e+05 | 61189.54 | [-14209.40, 2.26e+05] |      1.73 | 0.084 \nage_10_c [2nd degree]             |    70138.47 | 27538.88 | [ 16124.85, 1.24e+05] |      2.55 | 0.011 \nage_10_c [3rd degree]             |     -179.26 | 43887.04 | [-86257.49, 85898.96] | -4.08e-03 | 0.997 \nheight_cm_c                       |     1752.16 |   614.11 | [   547.67,  2956.65] |      2.85 | 0.004 \nnot_male [Not_Male]               |   -16438.03 |  8293.88 | [-32705.32,  -170.75] |     -1.98 | 0.048 \nedu_s                             |    21199.41 |  2834.48 | [ 15639.98, 26758.84] |      7.48 | < .001\nheight_cm_c * not_male [Not_Male] |    -1256.77 |   792.77 | [ -2811.67,   298.14] |     -1.59 | 0.113 \n\nAs judged by the AIC, this model has an improved fit. However as judged by the BIC, this model has reduced fit. This happened because the BIC penalises the extra parameters.\nWe can graph this outcome as follows:\n\n\nza<-performance::compare_performance(model_theory3, model_theory7) # age, benefit but only if polynomial\nplot(za)\n\n\n\n\nWhy might we include age? We might be interested in the predicted comparisons for age among, here for the population that is set to zero in our model (male-id’s who are shorter than average male height by about 83 cms, and have an sample average education). Age here has been converted to 2 x decade units.\n\n\nplot( ggeffects::ggpredict(model_theory7, terms = c(\"age_10_c\")) ) \n\n\n\n\nWe can see here that the interaction term has shifted because have added more variables. However, this is because the population we are predicting here is slightly different from the population before … the change might have occurred merely because we have added more terms or, as we shall come to understand in Week 9, the change might have occurred because adding indicators produce new understanding.\n\n\nplot( ggeffects::ggpredict(model_theory7, terms = c(\"height_cm_c\",\"not_male\")) ) \n\n\n\n\nCan we estimate multiple outcomes at the same time?\nYes. I do this using the BRMS package.\n\n\nlibrary(brms)\nbf1(y1 ~ x)\nbf2(y2 ~ x)\n\nfit <- brms(bf1 + bf2, \n            set_rescor(rescor = TRUE), # allow estimation of residual correlations\n            data = data)\n\n\n\nWe will encounter multivariate regression again in future weeks.\nANOVA\nDon’t use it, but if you must. The following code can be useful.\nANOVA and T-tests\nYou can write these as linear models.\nThis is a one-way anova in which the grouping variable “not_male” is the condition and “income” is the outcome.\nAnova\n\n\n#anova\nm2 <- aov(income ~ not_male, data = df)\nparameters::parameters(m2)\n\n\nParameter | Sum_Squares |   df | Mean_Square |     F |      p\n-------------------------------------------------------------\nnot_male  |    3.24e+11 |    1 |    3.24e+11 | 23.52 | < .001\nResiduals |    2.39e+13 | 1734 |    1.38e+10 |       |       \n\nThis is how the report package says you should report. I’ve tweaked the wording because I cannot write “statistically significant” without gagging:\nThe ANOVA (formula: income ~ not_male) suggests that:\nThe main effect of not_male is statistically significant (F(1, 1734) = 23.52, p < .001; Eta2 = 0.01, 90% CI [5.87e-03, 0.02])\nEffect sizes were labelled following Field’s (2013) recommendations.\nI recommend the modelbased package, which comes as part of easystats to explore your model\nThese are the estimated means\n\n\nmodelbased::estimate_relation(m2)\n\n\n  not_male Predicted       SE   CI_low  CI_high\n1     Male  153753.1 4654.863 144623.3 162882.8\n2 Not_Male  125403.1 3535.087 118469.6 132336.6\n\nCompare this against the linear model:\n\n\nm2l <- lm(income ~ not_male, data = df)\nparameters::parameters(m2l)\n\n\nParameter           | Coefficient |      SE |                 95% CI | t(1734) |      p\n---------------------------------------------------------------------------------------\n(Intercept)         |    1.54e+05 | 4654.86 | [ 1.45e+05,  1.63e+05] |   33.03 | < .001\nnot_male [Not_Male] |   -28349.98 | 5845.05 | [-39814.07, -16885.89] |   -4.85 | < .001\n\nThis is how the report package says you should report as follows\nWe fitted a linear model (estimated using OLS) to predict income with not_male (formula: income ~ not_male). The model explains a statistically significant proportion of variance (R2 = 0.01, F(1, 1734) = 23.52, p < .001, adj. R2 = 0.01). The model’s intercept, corresponding to not_male = 0, is at 1.54e+05 (95% CI [1.45e+05, 1.63e+05], t(1734) = 33.03, p < .001). Within this model:\nThe effect of not_male [Not_Male] is significantly negative (beta = -28349.98, 95% CI [-39814.07, -16885.89], t(1734) = -4.85, p < .001; Std. beta = -0.24, 95% CI [-0.34, -0.14])\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset.\nThese are the estimated means, which are identical to the ANOVA.\n\n\nmodelbased::estimate_relation(m2l)\n\n\n  not_male Predicted       SE   CI_low  CI_high\n1     Male  153753.1 4654.863 144623.3 162882.8\n2 Not_Male  125403.1 3535.087 118469.6 132336.6\n\nI’m not goint to spend any more time with ANOVA. This isn’t because I’m dimissive of ANOVA. It can be a useful framework for certain questions. However, it is never going to produce different answers than you would obtain in a linear regression framework. Moreover the linear regression framework is much more flexible, and can be extending However in case you are required to formulate your regression model, I’ve included some R syntax for you here.\nOne-way ANOVA\nSyntax\n\n\naov(Y ~ Grp, data = data)\n\n\n\nAssumptions:\nnormal distribution of the of the DV’s within each group\nhomogeneity of variances within each group\nrandom sample from the population\nindependent observations\nTwo-way ANOVA\nSyntax\n\n\naov(Y ~ Grp * Male, data = data)\n\n\n\nOr this model can be written\n\n\naov(Y ~ Grp + Male + Grp:Male, data = data)\n\n\n\nnormal distribution of the of the DV’s within each group\nhomogeneity of variances within each group\nrandom sample from the population\nindependent observations\nMANOVA\nThis model can be written:\n\n\n# MANOVA test\nmodel<- manova(cbind(Y1, Y2) ~ GRP, data = data)\nsummary(model)\n\n\n\nAppendix A: LaTeX tables\nFor advanced users, if you wish to write in \\(\\LaTeX\\) you can create a table in many way, for example copying and/pasting the output of the following code into your \\(\\LaTeX\\) document:\n\n\nparameters::parameters(model_simple)%>%\n kable( booktabs = F, \"latex\")%>%\n  print()\n\n\n\n\\begin{tabular}{l|r|r|r|r|r|r|r|r}\n\\hline\nParameter & Coefficient & SE & CI & CI\\_low & CI\\_high & t & df\\_error & p\\\\\n\\hline\n(Intercept) & -17.579095 & 6.7584402 & 0.95 & -31.167850 & -3.990340 & -2.601058 & 48 & 0.0123188\\\\\n\\hline\nspeed & 3.932409 & 0.4155128 & 0.95 & 3.096964 & 4.767853 & 9.463990 & 48 & 0.0000000\\\\\n\\hline\n\\end{tabular}\n\nThe package I tend to go to for \\(\\LaTeX\\) is the texreg package:\n\n\ntexreg::texreg(list(model_simple),\n           custom.model.names = c(\"Cars ...\"),\n           caption = \"Breaking distance as predicted by speed\",\n           sideways = F,\n           scalebox = .5,\n           #fontsize= \"footnotesize\",\n           label = \"tab:model_simple\",\n           ci.force.level = 0.95, bold = 0.05,\n           settingstars = 0,\n           booktabs = TRUE,\n           custom.note =\"\")\n\n\n\n\\usepackage{graphicx}\n\\usepackage{booktabs}\n\n\\begin{table}\n\\begin{center}\n\\scalebox{0.5}{\n\\begin{tabular}{l c}\n\\toprule\n & Cars ... \\\\\n\\midrule\n(Intercept) & $\\mathbf{-17.58}^{*}$ \\\\\n            & $(6.76)$              \\\\\nspeed       & $\\mathbf{3.93}^{***}$ \\\\\n            & $(0.42)$              \\\\\n\\midrule\nR$^2$       & $0.65$                \\\\\nAdj. R$^2$  & $0.64$                \\\\\nNum. obs.   & $50$                  \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\caption{Breaking distance as predicted by speed}\n\\label{tab:model_simple}\n\\end{center}\n\\end{table}\n\n\n\n\n",
    "preview": "posts/7_1/op_A.png",
    "last_modified": "2021-04-23T15:50:24+12:00",
    "input_file": {},
    "preview_width": 1920,
    "preview_height": 1536
  },
  {
    "path": "posts/6__1/",
    "title": "An introduction to simulation",
    "description": {},
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      }
    ],
    "date": "2021-03-30",
    "categories": [],
    "contents": "\n\nContents\nRequired readings\nOverview\nLearning outcomes\nFunctions for simulation\nrnorm\nrunif\nrep\nseq\nCustom sequences\n\nWhy simulate?\nCreate noise to understand inference\nWe can use simulation to explore potential problems with a sample\nSimulate a relationship between two variables\nSimulate a non-linear relationship\nCreate fake factors\nSimulate a relationship between two factors\nIs imbalance in my study causing a problem?\n\nAcknowledgments\n\n\n\n\n\n# Attaching packages (red = needs update)\n⚠ insight     0.13.1.1   ⚠ bayestestR  0.8.3.1 \n⚠ performance 0.7.0.1    ⚠ parameters  0.12.0.1\n⚠ see         0.6.2.1    ⚠ effectsize  0.4.3.1 \n⚠ correlation 0.6.0.1    ✔ modelbased  0.5.9   \n✔ report      0.2.0      \nWarnings or errors in CRAN checks for package(s) 'bayestestR', 'parameters', 'effectsize', 'correlation'.\nRestart the R-Session and update packages in red with 'easystats::easystats_update()'.\n\nRequired readings\nOverview\nThis week we will:\nLearn how to use R to generate random numbers\nUse random numbers to simulate data\nRelate lessons from simulation to lessons from regression.\nLearning outcomes\nBy learning how to simulate data you will better understand what a regression model is doing.\nAdditionally, you will need to understand simulation to follow the seminars on causal inference and multilevel modelling.\nFunctions for simulation\nrnorm\nrnorm is a R’s random number generator. Within this function:\nn: specifies the number of observations that you will generate\nsd: specifies the value of the standard deviation\nmean: specifies the value of the mean\n\n\n# seed\nset.seed(123)\n# generate random numbers\nds <- rnorm(n = 1000,\n            mean = 0,\n            sd = 1)\ndplyr::glimpse(ds)\n\n\n num [1:1000] -0.5605 -0.2302 1.5587 0.0705 0.1293 ...\n\nWe can create a histogram:\n\n\np1 <- ggplot2::qplot(ds) + labs(title = \"1st random number list\")\nplot(p1)\n\n\n\n\nNote that R users frequently shorten the above code, which can be written:\n\n\nset.seed(123)\n# generate random numbers\nds2 <- rnorm(1000)\n\n# check whether the abbreviated simulated vector is the same as the long form vector\nall.equal( ds, ds2 )\n\n\n[1] TRUE\n\nWe used set.seed to ensure that the same random vector will be generated for our audience. We can also use set.seed to ensure that a different vector will be generated.\nHere we ise a different seed to produce a new random sample; we then check whether the new simulated sample differs from the previous random sample:\n\n\nset.seed(54321)\nds3 <- rnorm(1000)\n# dplyr::glimpse( ds3 ) # uncomment to glimpse at the data\n# better method\nidentical(ds, ds3)\n\n\n[1] FALSE\n\nWe can assess the average by-row difference:\n\n\n#check equality\nall.equal(ds , ds3)\n\n\n[1] \"Mean relative difference: 1.44105\"\n\nIndeed, these differences are large enough to detect visually\":\n\n\np2 <- ggplot2::qplot(ds3) + labs(title = \"2d random number list\")\n\n# plot two graphs, each with different random samples\np1 + p2 + \n  plot_annotation(\"Random samples\",  tag_levels = 'i')\n\n\n\n\nrunif\nWe use r uniform to generate continuous data within a point range\n\n\nset.seed(123)\n# 100 numbers between zero and 50\nds4 <- runif(n = 100, min = 0, max = 50)\ndplyr::glimpse(ds4)\n\n\n num [1:100] 14.4 39.4 20.4 44.2 47 ...\n\n# how long is the vector?\nlength(ds4)\n\n\n[1] 100\n\n# visualise how are the data distributed?\nhist(ds4, breaks = 100)\n\n\n\n\nrep\nHow can we generate random factors.\nFor this, R’s rep function, letters function, and LETTERS function make happy friends. Here’s how these functions may be combined:\nCreate lower case letters:\n\n\nletters[1:3]\n\n\n[1] \"a\" \"b\" \"c\"\n\nCreate upper case letters:\n\n\nLETTERS[4:10]\n\n\n[1] \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\"\n\nCreate sequences using each\n\n\nrep(letters[1:3], each = 3)\n\n\n[1] \"a\" \"a\" \"a\" \"b\" \"b\" \"b\" \"c\" \"c\" \"c\"\n\nCreate sequences using times\n\n\nrep( letters[1:3], times = 3 )\n\n\n[1] \"a\" \"b\" \"c\" \"a\" \"b\" \"c\" \"a\" \"b\" \"c\"\n\nCreate uneven sequences:\n\n\nrep( letters[1:3], times = c(3, 1, 4) )\n\n\n[1] \"a\" \"a\" \"a\" \"b\" \"c\" \"c\" \"c\" \"c\"\n\nCombine each + times:\n\n\nrep(letters[1:3], each = 2, times = 3)\n\n\n [1] \"a\" \"a\" \"b\" \"b\" \"c\" \"c\" \"a\" \"a\" \"b\" \"b\" \"c\" \"c\" \"a\" \"a\" \"b\" \"b\"\n[17] \"c\" \"c\"\n\nlength.out\n\n\nrep(letters[1:3], each = 2, length.out = 17)\n\n\n [1] \"a\" \"a\" \"b\" \"b\" \"c\" \"c\" \"a\" \"a\" \"b\" \"b\" \"c\" \"c\" \"a\" \"a\" \"b\" \"b\"\n[17] \"c\"\n\nNote length.out take priority over times – use length.out if you have a fixed vector length.\nseq\nCreate a vector of numbers of a specific length:\n\n\nseq(from = 1, to = 45, by = 1)\n\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22\n[23] 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44\n[45] 45\n\n17 unit steps:\n\n\nseq(from = 1, to = 45, by = 17)\n\n\n[1]  1 18 35\n\n17 steps:\n\n\nseq(from = 1, to = 45, length.out = 17)\n\n\n [1]  1.00  3.75  6.50  9.25 12.00 14.75 17.50 20.25 23.00 25.75 28.50\n[12] 31.25 34.00 36.75 39.50 42.25 45.00\n\nCustom sequences\nWe can use vectors within random number generation\n\n\nset.seed(123)\nvdf<-rnorm(n = 20, \n           mean = c(0, 500, 1000, 10000), \n           sd = c(5,50,100,1000))\n\n# we created a vector \n# dplyr::glimpse(vdf) # reveal to show structure\n\n# quick graph\nqplot(vdf, binwidth=4) # note the combined means + sds around them.\n\n\n\n\nWhy simulate?\nCreate noise to understand inference\nRecall the relationship between mother’s heights and daughters heights in the Pearson/Fox dataset:\n\n\n# recall this model\nexplore_md <- ggplot2::ggplot(data = md_df,\n                              aes(y = daughter_height,\n                                  x = mother_height)) +\n  geom_jitter(alpha = .2) +\n  labs(title = \"The relationship between mothers height and daughter's height\") +\n  ylab(\"Daughter's height\") +\n  xlab(\"Mother's height\") +\n  theme_classic()\n\n# plot\nexplore_md\n\n\n\n\nWhat would a random relationship look like?\nSimulation can help us to address this question.\n\n\n# average daughter height\nav_dh <- mean(md_df$daughter_height, na.rm = TRUE)\n\n# sd of daughter height\nsd_dh <- sd(md_df$daughter_height, na.rm = TRUE)\n\n# average mother height\nav_mh <- mean(md_df$mother_height, na.rm = TRUE)\n\n# sd of mother height\nsd_mh <- sd(md_df$mother_height, na.rm = TRUE)\n\n# number of obs\nN <- nrow(md_df) # 5524\n\n# fake data\n# simulate values for these parameters but do not relate the two parameters\nsim_dh = rnorm(N, av_dh, sd_dh)\nsim_mh = rnorm(N, av_mh, sd_mh)\n\n# create a datframe of the simulations\nsim_df_md <- data.frame(sim_dh, sim_mh)\n\n# graph the data\nfake_md <- ggplot2::ggplot(data = sim_df_md,\n                           aes(y = sim_dh, x = sim_mh)) +\n  geom_jitter(alpha = .2) +\n  geom_smooth(method = lm) +\n  theme_classic() +\n  labs(title = \"Fake data relationship between mothers height and daughter's height\") +\n  ylab(\"Daughter's height\") +\n  xlab(\"Mother's height\")\n\n\n# real data\nexplore_md <-ggplot2::ggplot(data = md_df, aes(y = daughter_height, x = mother_height)) + \n  geom_jitter(alpha = .2) + \n  labs(title = \"The relationship between mothers height and daughter's height\") +\n       ylab(\"Daughter's height\") +\n       xlab(\"Mother's height\") + theme_classic() + \n  geom_smooth(method = lm)\n\n# plot uncorrelated data against data plot\nlibrary(patchwork)\nfake_md + explore_md  + plot_annotation(tag_levels = \"a\")\n\n\n\n\nWhat would a postive linear relationship look like?\nSimulation can help us to address this question too.\n\n\nN <- nrow(md_df)\n# average mother height\nset.seed(123)\nmd_df$daughter_height_c = scale(md_df$daughter_height, scale = FALSE) # center but not scale\nmd_df$mother_height_c = scale(md_df$mother_height, scale = FALSE) # center but not scale\nmh_fake_c <- runif(N,\n  min = min(as.numeric(md_df$mother_height_c), na.rm=TRUE),\n  max = max(as.numeric(md_df$mother_height_c), na.rm = TRUE))\n\n# let's take the intercept as the average height of daughters\na <- rnorm(N, mean = , mean(md_df$daughter_height), sd = 5)\n# recall the beta for the model was .55,\nb <- rnorm(N,mean = .55, sd = .1)\n\n# now the outcome: this is just the linear model:\ndh_fake <-  a + b * mh_fake_c\n\nmd_fake <- data.frame(mh_fake_c, dh_fake)\n\nmod_fake <-lm(dh_fake ~ mh_fake_c, data = md_fake)\n\n# Simulated relationship \nsim_plot <- plot(\n  ggeffects::ggpredict(mod_fake,\n                       terms = c(\"mh_fake_c [all]\")),\n  add.data = TRUE,\n  dot.alpha = .2\n)  + labs(title = \"Simulated relationship\") +\n  xlab(\"simulated mother height\") +  ylab(\"simulated daughter height\")\n\n# measured relationship\nmod_real <-lm(daughter_height ~ mother_height, data = md_df)\n\n# Simulated relationship \nreal_plot <- plot(\n  ggeffects::ggpredict(mod_real,\n                       terms = c(\"mother_height [all]\")),\n  add.data = TRUE,\n  dot.alpha = .2\n)  + labs(title = \"Actual relationship\") +  ylab(\"simulated daughter height\")\n\n# graph both\nlibrary(patchwork)\nsim_plot + real_plot +\n  plot_annotation(\"Simulated Model and Data-based Model\",\n                  subtitle = \"Daughters heights predicted by mother's heights\")\n\n\n\n\nWhat do we learn from the real data that we cannot obtain from the fake data?\nHere’s a shortcut we will occasionally use to simulate a dependency\n\n\nsim_dh2 = rnorm(N, sim_mh)\n# quick plot\nplot(sim_dh2 ~ sim_mh) + title(main = \"Qucik simulation of a data dependency\")\n\n\n\ninteger(0)\n\nWe can quickly generate a negative relationship\n\n\nsim_dh3 = rnorm(N, -sim_mh)\n# quick plot\nplot(sim_dh3 ~ sim_mh) + title(main = \"Qucik simulation of a negative data dependency\")\n\n\n\ninteger(0)\n\nIncrease the standard deviation from 1 to 5\n\n\nsim_dh4 = rnorm(N, -sim_mh, sd = 5)\n# quick plot\nplot(sim_dh4 ~ sim_mh) + title(main = \"Qucik simulation of a data dependency with larger standard deviation\")\n\n\n\ninteger(0)\n\nWe can use simulation to explore potential problems with a sample\nWe might think there is a relationship when we know (owing to simulation) that there is no relationship.\nDo you see a linear relationship?\n\n\nset.seed(123)\n# no relationship between x and y\nx = rnorm(n = 10, mean = 0, sd = 1)\ny = rnorm(n = 10, mean = 0, sd = 1)\n\nbar_df <- data.frame(x,y)\n# Barely significant linear model? \nsummary(bad <-lm(y ~ x , data = bar_df))\n\n\n\nCall:\nlm(formula = y ~ x, data = bar_df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.33303 -0.64421 -0.02448  0.49596  1.41472 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)   0.1617     0.2852   0.567   0.5863  \nx             0.6287     0.3141   2.001   0.0803 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8988 on 8 degrees of freedom\nMultiple R-squared:  0.3336,    Adjusted R-squared:  0.2503 \nF-statistic: 4.006 on 1 and 8 DF,  p-value: 0.08034\n\nggplot2::ggplot(bar_df,aes(y,x)) + geom_point() + geom_smooth(method=lm)\n\n\n\n\nIs this a one off?\n\n\n\n\n\n\n\n\nGo Bayesian? Note that the default implies a reliable association\n\n\nbad_bayes <- brms::brm(y ~ x, data = bar_df, file = here::here(\"models\", \"bad_bayes\"))\nbayestestR::describe_posterior( bad_bayes )\n\n\n# Fixed effects\n\nParameter   | Median |        89% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS\n-------------------------------------------------------------------------------------------\n(Intercept) |   0.17 | [-0.37, 0.71] | 69.67% | [-0.10, 0.10] |    24.66% | 1.000 | 3014.46\nx           |   0.62 | [ 0.08, 1.21] | 95.70% | [-0.10, 0.10] |     0.93% | 1.001 | 2638.88\n\n# find the coefficient does not cross zero!\nplot( parameters::model_parameters( bad_bayes ) )\n\n\n\n\nWe can replicate a result many times, without relying on one seeded draw.\nThe are two steps.\nFirst we make our one off simulation into a function. We do this so that the simulation can be repeated many times.\nHere is a function:\n\n\n# function for simulating a relationship\nsimple_sim = function(mn, sd) {\n  # we will plug numbers in for 'mn' and 'sd'\n  x_out = rnorm(mn, sd) # random x\n  y_out = rnorm(mn, sd) # random y (uncorrelated)\n  dat = data.frame(x_out, y_out) # bind into a dataframe\n  lm(y_out ~ x_out, data = dat) # linear model\n}\n\n# try it out\nset.seed(123)\nm1<-simple_sim(10,1) # n = 10 \nsjPlot::tab_model(m1) # almost significant! \n\n\n\n \n\n\ny_out\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n0.53\n\n\n-0.48 – 1.55\n\n\n0.262\n\n\nx_out\n\n\n0.63\n\n\n-0.10 – 1.35\n\n\n0.080\n\n\nObservations\n\n\n10\n\n\nR2 / R2 adjusted\n\n\n0.334 / 0.250\n\n\nSecond, we use replicate to generate many outcomes from this function:\n\n\nsms = replicate(100, simple_sim(10,1), simplify = FALSE ) # make 100 examples\n# we set simplify to \"FALSE\" to recover a list\nsms[[100]] # here is the 100th outcome\n\n\n\nCall:\nlm(formula = y_out ~ x_out, data = dat)\n\nCoefficients:\n(Intercept)        x_out  \n    0.98366      0.08593  \n\nCombine purrr and broom to get the simulation\n\n\nlibrary(purrr)\nlibrary(broom)\n## all regressions\n# map(sms, coef)\n\nmap_dfr(sms, broom::tidy)\n\n\n# A tibble: 200 x 5\n   term        estimate std.error statistic   p.value\n   <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)   1.46       0.190    7.71   0.0000567\n 2 x_out        -0.248      0.180   -1.38   0.206    \n 3 (Intercept)   1.10       0.394    2.78   0.0238   \n 4 x_out         0.126      0.276    0.455  0.661    \n 5 (Intercept)   0.275      0.513    0.536  0.607    \n 6 x_out         0.323      0.358    0.901  0.394    \n 7 (Intercept)   1.52       0.974    1.57   0.156    \n 8 x_out        -0.0667     0.690   -0.0967 0.925    \n 9 (Intercept)   0.736      0.330    2.23   0.0561   \n10 x_out        -0.0971     0.366   -0.266  0.797    \n# … with 190 more rows\n\nHow many p.values are less than or equalt to p = .05?\n\n\nmapped<-map_dfr(sms, broom::tidy)%>%\n  filter(term == \"x_out\") # note we only want the coefficients not the intercept\n\n# In 5 cases we find p <=.05\nsum(mapped$p.value <=.05) / length(mapped$p.value) # we find 5% of the simulations yield \"significant values\"\n\n\n[1] 0.05\n\nIs this surprising?\nWhich proportion is negative and statistically significant?\n\n\nsum((mapped$estimate < 0) &  mapped$p.value <=.05 )/ length(mapped$estimate) # we find 5% of the simulations yield \"significant values\"\n\n\n[1] 0.02\n\nAnd which proportion is positive?\n\n\nsum((mapped$estimate > 0) &  mapped$p.value <=.05 )/ length(mapped$estimate) # we find 5% of the simulations yield \"significant values\"\n\n\n[1] 0.03\n\nWhat does this simulation suggest to you about science?\nSimulate a relationship between two variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulate a non-linear relationship\n\n\n\n\n\n\n\n\n\n\n#Polynomial\nN <- 1000\n\n# simulate weights\nweight <- runif(N, min = 60, max = 120)\nweight_c <- scale(weight, scale = FALSE)\n\n# simulate coefficients\na = rnorm(N, mean = 180 , 10)\nb1 = rnorm(N, mean = 2.2, .01)\nb2 = -rnorm(N, mean = .02, .001)\n\nheight <- a + b1 * weight_c  +  b2 * weight_c ^ 2\n\n# simulated height/ weight data\n\ndf1 <- data.frame(height, weight_c, weight)\n\nplot(height ~ weight)\n\n\n\n\nLet’s fit a linear model to the data and graph the results\n\n\nm1 <- lm(height ~ weight_c, data = df1)\n\n# graph model\nplot(ggeffects::ggpredict(m1, terms = c(\"weight_c [all]\")),\n     add.data = TRUE,\n     dot.alpha = .2)  + labs(title = \"simulated linear relationship\") +\n  xlab(\"simulated weight\") +  ylab(\"simulated height\")\n\n\n\nsjPlot::tab_model(m1)\n\n\n\n \n\n\nheight\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n174.20\n\n\n173.51 – 174.89\n\n\n<0.001\n\n\nweight_c\n\n\n2.20\n\n\n2.16 – 2.25\n\n\n<0.001\n\n\nObservations\n\n\n1000\n\n\nR2 / R2 adjusted\n\n\n0.918 / 0.918\n\n\nLet’s fit a non-linear model and graph the results\n\n\nm2 <-lm(height ~ weight_c + I(weight_c^2), data = df1)\n\nplot(ggeffects::ggpredict(m2, terms = c(\"weight_c [all]\")),\n     add.data = TRUE,\n     dot.alpha = .2) + labs( title = \"simulated linear relationship\") + \n  xlab(\"simulated weight\") +  ylab(\"simulated height\")\n\n\n\n\nLet’s fit a non-linear model using splines and graph the results\n\n\nm3 <-lm(height ~ bs(weight_c), data = df1)\n\nplot(ggeffects::ggpredict(m3, terms = c(\"weight_c\")),\n     add.data = TRUE,\n     dot.alpha = .2)  + labs(title = \"simulated linear relationship\") +\n  xlab(\"simulated weight\") +  ylab(\"simulated height\")\n\n\n\n\nCheck the linear model and perform model checks:\n\n\nperformance::check_model(m1)\n\n\n\n\nThe model looks OK.\nCheck quadratic model (polynomial = 2)\n\n\nperformance::check_model(m2)\n\n\n\n\nThis model looks better\nCheck splines model.\n\n\nperformance::check_model(m3)\n\n\n\n\nThe splines model also looks better.\nWe can compare model performance:\n\n\nperformance::compare_performance(m1, m2, m3)\n\n\n# Comparison of Model Performance Indices\n\nName | Model |      AIC |      BIC |    R2 | R2 (adj.) |   RMSE |  Sigma\n------------------------------------------------------------------------\nm1   |    lm | 7668.482 | 7683.205 | 0.918 |     0.918 | 11.160 | 11.171\nm2   |    lm | 7458.284 | 7477.915 | 0.934 |     0.934 | 10.036 | 10.051\nm3   |    lm | 7458.556 | 7483.095 | 0.934 |     0.934 | 10.028 | 10.048\n\nWhich do we prefer?\nCreate fake factors\nThe key thing to remember about regression with factors is that the intercept is intercept as the lowest category of the factor.\n\n\nN <- 200 # number of observations\n#group <- rep((0:1), length.out = 200) # 2 groups\ngroup <- rep(c(\"m\",\"n_m\"), each = N/2) #equivalent:\na <- rnorm(N, 150, 3) # intercept\nb1 <- rnorm(N, 20, 1) # coefficient of \"b\nsigma = rexp(N,1)# error term\noutcome <- rnorm(N, mean = a + b1 * (group == \"m\"), sigma)\n\ndf <-data.frame(outcome,group)\n#dplyr::glimpse(df)\n\n\n#model removing the intercept to show the difference\nms<-lm(outcome ~ group, data = df)\n\n# graph\nsjPlot::plot_model(ms)\n\n\n\n#table\nsjPlot::tab_model(ms)\n\n\n\n \n\n\noutcome\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n169.98\n\n\n169.38 – 170.58\n\n\n<0.001\n\n\ngroup [n_m]\n\n\n-19.79\n\n\n-20.63 – -18.94\n\n\n<0.001\n\n\nObservations\n\n\n200\n\n\nR2 / R2 adjusted\n\n\n0.915 / 0.915\n\n\nThe key thing to remember about regression with factors is that the intercept is intercept as the lowest category of the factor.\nTo see this we can remove the intercept by including -1 in the model. This recovers contrasts:\n\n\n#model removing the intercept to show the difference\nms2<-lm(outcome ~ -1 + group, data = df)\n\n# graph\nsjPlot::plot_model(ms2)\n\n\n\n# table\nsjPlot::tab_model(ms2)\n\n\n\n \n\n\noutcome\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\ngroup [m]\n\n\n169.98\n\n\n169.38 – 170.58\n\n\n<0.001\n\n\ngroup [n_m]\n\n\n150.19\n\n\n149.60 – 150.79\n\n\n<0.001\n\n\nObservations\n\n\n200\n\n\nR2 / R2 adjusted\n\n\n1.000 / 1.000\n\n\nSimulate a relationship between two factors\nSimulate two groups with mean = 6 and mean = 12\n\n\ncdf <- data.frame(group = rep(letters[1:2], length.out = 100), # 2 groups\n                  response = rnorm(n = 100, mean = c(3, 12), sd = 1)) # mean of 3 mean of\n\nhead(cdf)\n\n\n  group  response\n1     a  1.898622\n2     b 10.131812\n3     a  2.736358\n4     b 12.508020\n5     a  3.962040\n6     b 10.471951\n\nModel:\n\n\nm_gr<- lm(response ~ -1 +  group, data = cdf)\n\n\n\nResults\n\n\nsjPlot::tab_model(m_gr)\n\n\n\n \n\n\nresponse\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\ngroup [a]\n\n\n3.06\n\n\n2.78 – 3.34\n\n\n<0.001\n\n\ngroup [b]\n\n\n11.93\n\n\n11.66 – 12.21\n\n\n<0.001\n\n\nObservations\n\n\n100\n\n\nR2 / R2 adjusted\n\n\n0.988 / 0.987\n\n\nIs imbalance in my study causing a problem?\n\n\n### Is imbalance wrecking my inference? \nset.seed(123)\nN <- 120\ncells <-rep( letters[1:2], times = c(15, 105))\n\na <- rnorm(N, 2, 1)\nb1 <- rnorm(N, .2, .1)\nsigma <- rexp(N,1)\n\nout <- rnorm(N, mean = a + b1 * (cells == \"b\"), sigma)\ndfc<-data.frame(out,cells)\nsim_cells<-lm(out ~ cells, data = dfc)\n\nsjPlot::tab_model(sim_cells)\n\n\n\n \n\n\nout\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n2.21\n\n\n1.41 – 3.02\n\n\n<0.001\n\n\ncells [b]\n\n\n-0.12\n\n\n-0.98 – 0.74\n\n\n0.779\n\n\nObservations\n\n\n120\n\n\nR2 / R2 adjusted\n\n\n0.001 / -0.008\n\n\nThis isn’t too convincing. We need to replicate the model many times\n\n\n# Make a function for the simulation\nset.seed(12)\ntest_fun = function() {\n  N <- 120\n  cells <-rep( letters[1:2], times = c(110, 10))\n  a <- rnorm(N, 2, 1)\n  b1 <- rnorm(N, 1, .1)\n  sigma <- rexp(N, 1)\n  out <- rnorm(N, mean = a + b1 * (cells == \"b\"), sigma)\n  dfc <- data.frame(out, cells)\n  sim_cells <- lm(out ~ cells, data = dfc)\n  sim_cells\n}\n\nr_lm = replicate(20, test_fun(), simplify = FALSE )\nlength(r_lm)\n\n\n[1] 20\n\nWe can use the purrrand broom packages to generate many replicates of a model and summarise them, and ask: What percentage of simulations yield statistically significant results?\n\n\ntab_sim<-purrr::map_dfr(r_lm, broom::tidy)\nmout<-tab_sim %>%\n  dplyr::filter(term ==\"cellsb\")%>%\n  dplyr::mutate_if(is.numeric, round, 5)\n\n# calculate proportion\nsum(mout$p.value <= .05) / length(mout$p.value)\n\n\n[1] 0.45\n\nDoes increasing the cells the issue?\n\n\n# Make a function for the simulation\nset.seed(12)\ntest_fun = function(cell1, cell2) {\n  N <- 120\n  cells <-rep( letters[1:2], times = c(cell1, cell2))\n  a <- rnorm(N, 2, 1)\n  b1 <- rnorm(N, 1, .1)\n  sigma <- rexp(N, 1)\n  out <- rnorm(N, mean = a + b1 * (cells == \"b\"), sigma)\n  dfc <- data.frame(out, cells)\n  sim_cells <- lm(out ~ cells, data = dfc)\n  sim_cells\n}\n\n# balanced cells of 60 each\nsim_lm = replicate(20, test_fun(60,60), simplify = FALSE )\nlength(sim_lm)\n\n\n[1] 20\n\nWe can use the purrr package to generate many replicates of a model.\nThe simulation suggests that balances of 60/60 is good here.\n\n\n# summarise coefficients \ntab_sim2<-purrr::map_dfr(sim_lm, broom::tidy)\n\n# obtain only the treatment coefficient\nmout2<-tab_sim2 %>%\n  dplyr::filter(term ==\"cellsb\")%>%\n  dplyr::mutate_if(is.numeric, round, 5)\n\nsum(mout2$p.value <= .05) / length(mout2$p.value)\n\n\n[1] 0.95\n\nAcknowledgments\nMuch in my approach to teaching simulation owes to Ariel Muldoon. PLease check out Ariel’s wonderful R webpage here: https://aosmith.rbind.io\nTry out Ariel’s tutorial for simulation functions here\n\n\n\n",
    "preview": "posts/6__1/Lecture-6_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2021-04-10T13:10:32+12:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/5_1/",
    "title": "Elements of a linear model",
    "description": {},
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      }
    ],
    "date": "2021-03-23",
    "categories": [],
    "contents": "\n\nContents\n\n\n\n\nShow code\n\nknitr::include_graphics(\"op.png\")\n\n\n\n\n\n\nShow code\n\n# libraries\nlibrary(\"tidyverse\")\nlibrary(\"patchwork\")\nlibrary(\"brms\")\nlibrary(\"lubridate\")\nlibrary(\"splines\")\nif (!require(equatiomatic)) {\n  remotes::install_github(\"datalorax/equatiomatic\")\n  }\n# set theme\n# theme set\ntheme_set(theme_classic())\n\n\n\n\n\nShow code\n\n# Import data\n# read data\nnz_0 <- readr::read_csv2(url(\"https://raw.githubusercontent.com/go-bayes/psych-447/main/data/nz/nz.csv\"))\n\n# to relevel kessler 6 variables\nf<-c(\"None Of The Time\",\"A Little Of The Time\",\"Some Of The Time\",  \"Most Of The Time\", \"All Of The Time\")\n\n# get data into shape\nlibrary(\"tidyverse\")\nnz <- nz_0 %>%\n  dplyr::mutate_if(is.character, factor) %>%\n  select(\n    -c(\n      SWB.Kessler01,\n      SWB.Kessler02,\n      SWB.Kessler03,\n      SWB.Kessler04,\n      SWB.Kessler05,\n      SWB.Kessler06\n    )\n  ) %>%\n  dplyr::mutate(Wave = as.factor(Wave)) %>%\n  dplyr::mutate(FeelHopeless = forcats::fct_relevel(FeelHopeless, f)) %>%\n  dplyr::mutate(FeelDepressed = forcats::fct_relevel(FeelDepressed, f)) %>%\n  dplyr::mutate(FeelRestless = forcats::fct_relevel(FeelRestless, f)) %>%\n  dplyr::mutate(EverythingIsEffort = forcats::fct_relevel(EverythingIsEffort, f)) %>%\n  dplyr::mutate(FeelWorthless = forcats::fct_relevel(FeelWorthless, f)) %>%\n  dplyr::mutate(FeelNervous = forcats::fct_relevel(FeelNervous, f)) %>%\n  dplyr::mutate(Wave = as.factor(Wave)) %>%\n  dplyr::mutate(date = make_date(year = 2009, month = 6, day = 30) + TSCORE) %>%\n  dplyr::mutate(height_m = HLTH.Height * 100,\n         weight_kg =  HLTH.Weight) # better height vars\n\n\n\nOverview\nThis week we introduce regression.\nLearning outcomes\nBy learning regression, you will be better equipped to do psychological science and to evaluate psychological research.\nWhat is regression?\nBroadly speaking, a regression model is method for inferring the expected average features of a population, and the variance of a population, conditional on other features of the population as measured in a sample.\nWe’ll see that regression encompasses more than this definition, however, this definition makes a start.\nTo understand regression, then, we need to understand the following jargon words: population, sample, measurement, and inference.\nWhat is a population?\nIn science, a population is a hypothetical construct. It is the set of all potential members of a set of things. In psychological science that set is typically a collection of individuals. We want to understand “The population of all human beings?” or “The New Zealand adult population”; or “The population of undergraduates who may be recruited for IPRP in New Zealand.”\nWhat is a sample?\nA sample is a randomly realised sub-population from the larger abstract population that a scientific community hopes to generalise about.\nThink of selecting balls randomly from an urn. If pulled at random, the balls may inform us about the contents of the urn. For example, if we select one white ball and one black ball, we may infer that the balls in the urn are not all white or all black.\nWhat is “measurement?”\nA measure is tool or method for obtaining numerical descriptions of a sample. We often call measures “scales.” We can think of a bathroom weight scale as a tool and method for tracking body weight.\nA measurement is the numerical description we obtain from sensors such as statistical surveys, census data, twitter feeds, & etc.\nIn the course, we have encountered numerical scales, ordinal scales, and factors. The topic of measurement in psychological is, to say the least, very broad.\nFor now, it is important to keep in mind that, similar to bathroom scales, measures can be prone to error.\nAlso similar to bathroom scales, error prone scales may nevertheless be useful. We need to investigate the utility of error prone scales against the backdrop of specific interests and purposes.\nWhat is a parameter?\nIn regression, we combine measurements on samples with probability theory to guess about the properties of a population we will never observe. We call these properties “parameters.”\nWhat is statistical inference?\nThe bulk of statistical inference consists of educated guessing about population parameters.\nProbability distributions and statistical guessing\nInference is possible because the parameters of naturally occurring populations are structured by data generating processes that are approximated by probability distributions. A probability distribution is a mathematical function that describes the probability of a random event. Today we will be focusing on height.1\nToday we will be talking about the “normal” or “Gaussian distribution.” A very large number of data-generating processes in nature conform the normal distribution.\nLet’s consider some examples of randomly generated samples, which we will obtain using R’s rnorm function.\n100-person sample of heights\n\n\nShow code\n\nset.seed(123)\nsm<-rnorm(100, mean = 170, sd = 20)\nggplot2::qplot(sm, binwidth = 10)\n\n\n\n\n10-person sample of heights\n\n\nShow code\n\nset.seed(123)\nsubsm <-rnorm(10, mean = 170, sd = 20)\n\nggplot2::qplot(\n  subsm, binwidth = 10\n  )\n\n\n\n\n10000-person sample of heights\n\n\nShow code\n\nset.seed(123)\nlargesm <-rnorm(1e5, mean = 170, sd = 20)\nggplot2::qplot(\n  largesm, binwidth = 1\n  )\n\n\n\n\nHow can I use regression to infer a population parameter?\nWe can use R to investigate the average height of our imaginary population from which the preceding samples were randomly drawn. We do this in R by writing an “intercept-only” model as follows:\n\n\nShow code\n\nmodel <- lm(outcome ~ 1, data = datset)\nsummary(model)\n\n\n\nUsing the previous simulations:\nN = 10 random draws\n\n\n#write the model and get a nice table for it\nsjPlot::tab_model(\n  lm(sm ~ 1)\n)\n\n\n\n \n\n\nsm\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n171.81\n\n\n168.19 – 175.43\n\n\n<0.001\n\n\nObservations\n\n\n100\n\n\nR2 / R2 adjusted\n\n\n0.000 / 0.000\n\n\nN = 100 random draws\n\n\nsjPlot::tab_model(\n  lm(subsm ~ 1)\n)\n\n\n\n \n\n\nsubsm\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n171.49\n\n\n157.85 – 185.14\n\n\n<0.001\n\n\nObservations\n\n\n10\n\n\nR2 / R2 adjusted\n\n\n0.000 / 0.000\n\n\nN = 10,000 random draws\n\n\nShow code\n\nsjPlot::tab_model(\n  lm(largesm ~ 1)\n)\n\n\n\n \n\n\nlargesm\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n170.02\n\n\n169.90 – 170.14\n\n\n<0.001\n\n\nObservations\n\n\n100000\n\n\nR2 / R2 adjusted\n\n\n0.000 / 0.000\n\n\nWhat do we notice about the relationship between sample size the estimated population average?\n\n\nShow code\n\nsjPlot::tab_model(\n   lm(sm ~ 1),\n   lm(subsm ~ 1),\n   lm(largesm ~ 1)\n)\n\n\n\n \n\n\nsm\n\n\nsubsm\n\n\nlargesm\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\nEstimates\n\n\nCI\n\n\np\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n171.81\n\n\n168.19 – 175.43\n\n\n<0.001\n\n\n171.49\n\n\n157.85 – 185.14\n\n\n<0.001\n\n\n170.02\n\n\n169.90 – 170.14\n\n\n<0.001\n\n\nObservations\n\n\n100\n\n\n10\n\n\n100000\n\n\nR2 / R2 adjusted\n\n\n0.000 / 0.000\n\n\n0.000 / 0.000\n\n\n0.000 / 0.000\n\n\nRegression with a single co-variate\nDoes mother height predict daughter height? It seems so. By what how close are is the relationship?\nFrancis Galton is credited with inventing regression. Galton observed that the height of offspring tends to fall between parental height and the population average, what Galton termed: “regression to the mean.” Galton sought a method for educated guessing about heights, and this led to fitting a line of regression by a method called “least squares” (For a history see: here).\nThis following dataset is from “The heredity of height,” Karl Pearson and Alice Lee (1903)(Pearson and Lee 1903). I obtained the dataset from (Gelman, Hill, and Vehtari 2020a). Let’s use this dataset to investigate the relationship between a mother’s height and a daughter’s height.\n\n\nShow code\n\nmd_df <- data.frame(read.table(url(\"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/PearsonLee/data/MotherDaughterHeights.txt\"), header=TRUE))\n# Center mother's height for later example\nmd_df <- md_df %>%\n  dplyr::mutate(mother_height_c = as.numeric(scale(mother_height, center = TRUE, scale = FALSE)))\ndplyr::glimpse(md_df)\n\n\nRows: 5,524\nColumns: 3\n$ daughter_height <dbl> 52.5, 52.5, 53.5, 53.5, 55.5, 55.5, 55.5, 55…\n$ mother_height   <dbl> 59.5, 59.5, 59.5, 59.5, 59.5, 59.5, 59.5, 59…\n$ mother_height_c <dbl> -2.9987328, -2.9987328, -2.9987328, -2.99873…\n\nPearson and Lee collected 5,524 observations from mother/daughter height pairs. Let’s examine the data, first by plotting the relationship.\nWhat what is happening here?\n\n\nShow code\n\nexplore_md <-ggplot2::ggplot(data = md_df, aes(y = daughter_height, x = mother_height)) + \n  geom_jitter(alpha = .2) + \n  labs(title = \"The relationship between mothers height and daughter's height\") +\n       ylab(\"Daughter's height\") +\n       xlab(\"Mother's height\") + theme_classic()\nexplore_md\n\n\n\n\nIs there a linear predictive relationship between these two parameters? In regression we examine the line of best fit.\n\n\nShow code\n\nm1 <- lm(daughter_height ~ mother_height, data = md_df)\nsjPlot::tab_model(m1)\n\n\n\n \n\n\ndaughter_height\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n29.80\n\n\n28.25 – 31.35\n\n\n<0.001\n\n\nmother_height\n\n\n0.54\n\n\n0.52 – 0.57\n\n\n<0.001\n\n\nObservations\n\n\n5524\n\n\nR2 / R2 adjusted\n\n\n0.252 / 0.252\n\n\nWe can plot the coefficient; in a model with one predictor isn’t too informative. As we continue in the course, however, we’ll see that plotting coefficients can be easier than deciphering the numbers in tables. Here are two methods for plotting.\n\n\nShow code\n\nt_m1<-parameters::model_parameters(m1,  \n                                   ci = 0.95)\nmethod1 <- plot(t_m1) +\n  labs(title = \"The relationship between mothers height and daughter's height\") + \n  ylab(\"Daughter's height\") \n\nmethod2 <-sjPlot::plot_model(m1)\n\nlibrary(patchwork)\nmethod1 / method2 + plot_annotation(title = \"Comparision of two coefficeint plots\",\n                                    subtitle = \"a: parameters see; b: sjPlot\", \n                                    tag_levels = \"a\")\n\n\n\n\nHow do we interpret the regression model?\nLet’s write the equation out in mathematics. How do we read this?2\n\n\nShow code\n\nlibrary(\"equatiomatic\")\nextract_eq(m1,  use_coefs = FALSE)\n\n\n\\[\n\\operatorname{daughter\\_height} = \\alpha + \\beta_{1}(\\operatorname{mother\\_height}) + \\epsilon\n\\]\n\nThe math says that the expected daughter’s height in a population is predicted by the average height of the population when mother’s height is set to zero units (note, this is impossible - we’ll come back to this) plus \\(\\beta ~\\times\\) units of daughter’s height (inches) for each additional unit of mother’s height (inches)\nWe can plug the output of the model directly into the equation as follows:\n\n\nShow code\n\nlibrary(\"equatiomatic\")\nextract_eq(m1,  use_coefs = TRUE)\n\n\n\\[\n\\operatorname{\\widehat{daughter\\_height}} = 29.8 + 0.54(\\operatorname{mother\\_height})\n\\]\n\nGraph the relationship between mother’s and daughter’s heights\n\n\nlibrary(ggeffects)\ntoplot<-ggeffects::ggpredict(m1, terms = \"mother_height\")\n\nheightplot<-plot(toplot, add.data = TRUE, dot.alpha = .1, jitter = TRUE) +   theme_classic()\nheightplot + labs(title = \"Predicted values of daughter's height from the Pearson/Fox 1903 dataset\")\n\n\n\n\nRegression to predict beyond the range of a dataset\nJoyte Amge is the world’s shortest woman at 25 inches. Sandy Allen was the world’s tallest woman at 91 inches. What is be the expected heights of their daughter, and of every intermediary woman in between?\n\n\n# use the `expand.grid` command to create a sequence of points for mother's height\nndat<-expand.grid(mother_height = c(25:91)) \n\n# use the `predict` function to create a new response \npr<- predict(m1, type = \"response\", interval = \"confidence\", newdata =ndat)\n\n# have a look at the object\ndplyr::glimpse(pr)\n\n\n num [1:67, 1:3] 43.4 44 44.5 45.1 45.6 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:67] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ : chr [1:3] \"fit\" \"lwr\" \"upr\"\n\n# create a new dataframe for the new sequence of points for mother's height and the predicted data\nnewdata<-data.frame(ndat,pr)\nhead(newdata)\n\n\n  mother_height      fit      lwr      upr\n1            25 43.42183 42.49099 44.35266\n2            26 43.96676 43.06065 44.87288\n3            27 44.51170 43.63030 45.39310\n4            28 45.05664 44.19995 45.91332\n5            29 45.60157 44.76960 46.43355\n6            30 46.14651 45.33924 46.95378\n\nGraph the predicted results\n\n\nShow code\n\n# graph the expected results\npredplot<-ggplot(data = newdata, \n       aes(x= mother_height, y = fit))  + \n  geom_point() +  geom_errorbar(aes(ymin = lwr, ymax = upr), width = .1) + \n   expand_limits(x = c(20,91), y = c(0,81))  + theme_classic() + \n  labs(title = \"Predicted values for a broader population\")\n\n# plot the two graphs together (making the x and y axis at the same scale )\nlibrary(\"patchwork\")\n# rescale heightplot\n\n# old plot with the new axis and y axis scales, and remove points\n\nheightplot2<-plot(toplot, add.data = FALSE) +   theme_classic()\n\nnhp <- heightplot2 +  expand_limits(x = c(20,91), y = c(0,81) ) +  labs(title = \"Predicted values of daughter's height from the Pearson/Fox 1903 dataset\")\n\n# double graph\n nhp /predplot  + plot_annotation(title = \"What do you notie about these relationships?\", tag_levels = \"a\")\n\n\n\n\nA simple method for obtaining the predicted values form your fitted model is to obtain the ggeffects output without producing a graph.\n\n\nlibrary(ggeffects)\n\ntoplot<-ggeffects::ggpredict(m1, terms = \"mother_height\")\ntoplot\n\n\n# Predicted values of daughter_height\n# x = mother_height\n\n    x | Predicted |         95% CI\n----------------------------------\n52.50 |     58.41 | [58.15, 58.66]\n54.50 |     59.50 | [59.29, 59.70]\n57.50 |     61.13 | [60.99, 61.27]\n59.50 |     62.22 | [62.13, 62.32]\n61.50 |     63.31 | [63.25, 63.38]\n63.50 |     64.40 | [64.34, 64.47]\n65.50 |     65.49 | [65.40, 65.59]\n70.50 |     68.22 | [68.01, 68.42]\n\nNon-linear relationships\nLinear regression assumes linearity conditional on a model. Often your data will not be linear!\nConsider the following example:\n\n\n# Simulate nonlinear relationship between x and y\nb <- c(2, 0.75)\nset.seed(12)\nx <- rnorm(100)\nset.seed(12)\ny <- rnorm(100, mean = b[1] * exp(b[2] * x))\ndat1 <- data.frame(x, y)\n\not1 <-lm(y ~ x, data  = dat1)\n# performance::check_model(ot1)\n\n# Plot linear effect\nplot(ggeffects::ggpredict(ot1, terms = \"x\"), add.data =TRUE, dot.alpha = .4)\n\n\n\n\nNon-linear relationship as modelled by a polynomial regression:\n\n\nlibrary(splines)\not2 <-lm(y ~ x + I(x^2), data  = dat1)\nplot(ggeffects::ggpredict(ot2, terms = \"x\"), add.data =TRUE, dot.alpha = .4)\n\n\n\n\nHere is another approach:\n\n\nlibrary(splines)\not2.b <-lm(y ~ x + poly(x, 2), data  = dat1)\nplot(ggeffects::ggpredict(ot2.b, terms = \"x\"), add.data =TRUE, dot.alpha = .4)\n\n\n\n\nNon-linear relationship as modeled by a general additive model (spline)\n\n\nlibrary(splines)\n\not3 <-lm(y ~ bs(x), data  = dat1)\n\n#performance::check_model(ot2)\nplot(ggeffects::ggpredict(ot3, terms = \"x\"), add.data =TRUE, dot.alpha = .4)\n\n\n\n\nCentering\nAny linear transformation of a predictor is OK. Often we center (or center and scale) all indicators, which gives us an intercept that is meaninful (the expected population average when the other indicators are set their average).\n\n\nShow code\n\nlibrary(ggeffects)\n# original model\nm1 <- lm(daughter_height ~ mother_height, data = md_df)\nmc <-lm(daughter_height ~ mother_height_c, data=md_df)\nsjPlot::tab_model(m1,mc)\n\n\n\n \n\n\ndaughter_height\n\n\ndaughter_height\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n29.80\n\n\n28.25 – 31.35\n\n\n<0.001\n\n\n63.86\n\n\n63.80 – 63.92\n\n\n<0.001\n\n\nmother_height\n\n\n0.54\n\n\n0.52 – 0.57\n\n\n<0.001\n\n\n\n\n\n\n\n\nmother_height_c\n\n\n\n\n\n\n\n\n0.54\n\n\n0.52 – 0.57\n\n\n<0.001\n\n\nObservations\n\n\n5524\n\n\n5524\n\n\nR2 / R2 adjusted\n\n\n0.252 / 0.252\n\n\n0.252 / 0.252\n\n\nGraph model\n\n\nShow code\n\nplot(ggeffects::ggpredict(mc, terms = \"mother_height_c\"), add.data =TRUE, dot.alpha = .4)\n\n\n\n\nNote: when fitting a polynomial or any interaction, it is important to center your indicators. We’ll come back to this point in later lectures.\nModel evaluation\nA simple way to assess your model fit is to compare a model with one covariate with a simple intercept-only model and to assess improvement in either the AIC statistic or the BIC statistic. The BIC is similar to the AIC but adds a penalty for extra predictors. An absolute improvement in either statistic of n > 10 is considered to be a better model.\nWe can use the performance package to generate a table that compares fits.\n\n\nlibrary(performance)\n# intercept only\nionly <- lm(daughter_height ~ 1, data = md_df)\n\n# covariate added\ncovadded <- lm(daughter_height ~ mother_height, data = md_df)\n\n# evaluate\nperformance::compare_performance(ionly, covadded)\n\n\n# Comparison of Model Performance Indices\n\nName     | Model |       AIC |       BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n----------------------------------------------------------------------------\nionly    |    lm | 26299.969 | 26313.203 | 0.000 |     0.000 | 2.615 | 2.615\ncovadded |    lm | 24698.514 | 24718.365 | 0.252 |     0.252 | 2.262 | 2.262\n\nWhat was the model improvement?\n\n\nShow code\n\n# improved fit\nBIC(ionly)- BIC(covadded)\n\n\n[1] 1594.839\n\nGenerate a report\nThis is easy with the report package\nFor example:\n\n\nreport::report_statistics(covadded)\n\n\nbeta = 29.80, 95% CI [28.25, 31.35], t(5522) = 37.70, p < .001; Std. beta = 1.37e-14, 95% CI [-0.02, 0.02]\nbeta = 0.54, 95% CI [0.52, 0.57], t(5522) = 43.12, p < .001; Std. beta = 0.50, 95% CI [0.48, 0.52]\n\nOr if you want a longer report\n\n\nreport::report(covadded)\n\n\n\nThough use statistically significant in place of significant. This will avoid misleading your audience into thinking your result is important, when what you intend to communicate is that it is reliable.\nAssumptions of regression\nFrom Gelman and Hill (Gelman and Hill 2006)\nValidity\n\nThe most important is that the data you are analyzing should map to the research question you are trying to answer (Gelman, Hill, and Vehtari 2020b, 152)\n\nRepresentativeness\n\nA regression model is fit to data and is used to make inferences about a larger population, hence the implicit assumption in interpreting regression coefficients is that the sample is representative of the population. (Gelman, Hill, and Vehtari 2020b, 153)\n\nLinearity*\n\nThe most important mathematical assumption of the linear regression model is that its deterministic component is a linear function of the separate predictors: y = β0 + β1x1 + β2x2 +···. If additivity is violated, it might make sense to transform the data (for example, if y = abc, then log y = log a + log b + log c) or to add interactions. If linearity is violated, perhaps a predictor should be put in as 1/x or log(x) instead of simply linearly. Or a more complicated relationship could be expressed using a nonlinear function such as a spline or Gaussian process, (Gelman, Hill, and Vehtari 2020b, 153)\n\nIndependence of errors\n\nThe simple regression model assumes that the errors from the prediction line are independent, an assumption that is violated in time series, spatial, and multilevel settings (Gelman, Hill, and Vehtari 2020b, 153)\n\nEqual variance of errors\n\n…unequal variance does not affect the most important aspect of a regression model, which is the form of the predictors (Gelman, Hill, and Vehtari 2020b, 153)\n\nNormality of errors (statistical independence)\n\nThe regression assumption that is generally least important is that the errors are normally distributed. In fact, for the purpose of estimating the regression line (as compared to predicting individual data points), the assumption of normality is barely important at all. Thus, in contrast to many regression textbooks, we do not recommend diagnostics of the normality of re-gression residuals. (Gelman and Hill 2006, 46)\n\n\nA good way to diagnose violations of some of the assumptions just considered (importantly, linearity) is to plot the residuals versus fitted values or simply individual predictors.(Gelman and Hill 2006, 46)\n\nCommon confusions\nCausal inference is tricky\nPeople use the work “effect” but that is not what regression gives us (by default)\n“Normality assumption”\nAs Gelman and Hill note, the “normality” assumption is the least important. And the assumption pertains to the normality of residuals\nStatistical independence\nThis will be the main reason we do multi-level modelling: to condition on dependencies in the data.\nLevels (wrong population)\nWe sample from undergraduates, but infer about the human population.\nAcknowledgments\nRichard Mcelreath’s Statistical Rethinking (McElreath 2020)\nRegression and other stories (Gelman, Hill, and Vehtari 2020a)\nAppendix 1: Conceptual Background\nSome preliminaries about science.\nScience begins with a question\nScience begins with a question about the world. The first step in science, then, is to clarify what you want to know.\nBecause science is a social practice, you will also need to clarify why your question is interesting: so what?\nIn short, know your question.\nScientific model (or theory)\nSometimes scientists are interested in specific features of the world: how did virus x originate? Such a question might have a forensic interest: what constellation of events gave rise to a novel infectious disease?\nMore typically, scientists seek generalisations. How do infectious diseases evolve? How do biological organisms evolve? Such questions have applied and fundamental interests. How can we better prevent infectious disease? How did life originate?\nA scientific model is a proposal for how nature is structured (and unstructured). For example, the theory of evolution by natural selection proposes that life emerges from variation, inheritance, and differential reproduction/survival.\nTo evaluate a scientific model, scientists must make generalisations beyond individual cases. This is where statistics shines.\nWhat is statistics?\nMathematics is a logic of certainty.\nStatistics is a logic of uncertainty.\nA statistical model uses the logic of probability to make better guesses.\nApplications of statistical models in science\nScientific models seek to explain how nature is structured. Where scientific models conflict, we can combine statistical models with data-collection to evaluate the credibility of of one theoretical model over others. To do this, a scientific model must make distinct, non-trivial predictions about the world.\nIf the predictions are not distinct, the observations will not enable a shift in credibility for one theory over another. Consider the theory that predicts any observation. Such a theory would be better classified as a conspiracy theory; it is compatible with any evidence whatsoever.\n\nToday we introduce a statistical method called regression. We will focus on how regression helps both to evaluate, and to make, informed predictions about the structures of the world.\nAppendix 2: How your computer sees your data\nUnder the hood\nUnder the hood, your computer sees your data as consisting of vectors and matrices. An algorithm searches to estimate (or in the case of Bayesian inference, to “solve”) an optimization problem to obtain a location for the unobserved parameter; in the case we examined above, this parameter is the relationship between daughter heights and mother heights.\n\\[\\begin{bmatrix}\n\\textbf{y}\\\\\n\\textit{daughter's height}\\\\\n51.5\\\\\n52.5 \\\\\n53.0 \\\\\n\\vdots\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\textbf{intercept} \\\\\n1 \\\\\n1 \\\\\n1 \\\\\n1 \\\\\n\\vdots \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\textbf{x}\\\\\n\\textit{mother's height}\\\\\n59.5\\\\\n57.5 \\\\\n60.0 \\\\\n\\vdots\n\\end{bmatrix}\n\\begin{bmatrix}\n\\textbf{b}\\\\\n29.8 \\\\\n0.54\n\\end{bmatrix}\\]\n\n\n\nGelman, Andrew, and Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge university press.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020a. Regression and Other Stories. Cambridge University Press.\n\n\n———. 2020b. Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. CRC press.\n\n\nPearson, Karl, and Alice Lee. 1903. “On the Laws of Inheritance in Man: I. Inheritance of Physical Characters.” Biometrika 2 (4): 357–462.\n\n\nThe relationship of probability distributions and data-generating processes is complex, intriguing, and both historically and philosophically rich \\(\\dots\\). Because our interests are applied, we will hardly touch up this richness in this course, alas.↩︎\nLater, we’ll prefer a different way of writing regression equations in math. (Note: writing math isn’t math - it’s just encoding the model that we’ve written).↩︎\n",
    "preview": "posts/5_1/distill-preview.png",
    "last_modified": "2021-05-03T12:17:19+12:00",
    "input_file": {},
    "preview_width": 2500,
    "preview_height": 2500
  },
  {
    "path": "posts/4_1/",
    "title": "Consolidation of skills",
    "description": {},
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      }
    ],
    "date": "2021-03-16",
    "categories": [],
    "contents": "\n\nContents\nGet data\nPreamble\nData carpentry continued\nDifferent methods for selecting columns\nRe-leveling a factor\nCreating factors from numerical indicators\nUsing ifelse to create factors\nTransformations of indicators: scaling, centering, and logs\nPro tip 1:\nCreate and work with dates a date\nCreate a timeline\nSlice\nLags and leads using timeseries data\nPro tip 2\n\nData summary\nSummarise all your data\nThe skimr package\nTable1 & other canned table packages\nCreate a table using pipe functions\nBar graphs\nMissing data graphs\nBoxplots\nCorrelation graphs\nThe report package\nMeasures\nOrder of your Method section\n\nAppendix 1A Sampling Procedure – NZAVS Time 10 (2018; conducted from 18.06.2018-28.09.2019)\nAppendix 1B Sampling Procedure – NZAVS Time 11 (2019; conducted from 29.09.2019-17.10.2020)\nAppendix 2 Johannes’s mini-lecture on the papaja package\nAppendix 3 Style advice about research methods\n\n\n\n\nGet data\n\n\n#libraries\nif (!require(skimr)) install.packages('skimr')\nif (!require(lubridate)) install.packages('lubridate')\n\nif (!requireNamespace(\"devtools\")) {\n  install.packages(\"devtools\")\n}\nif (!require(easystats)) devtools::install_github(\"easystats/easystats\")\nif (!require(ggthemes)) install.packages('ggthemes')\nif (!require(pmdplyr)) install.packages(\"pmdplyr\")\nif (!require(kableExtra)) install.packages(\"kableExtra\")\n# this should be part of easystats but in case not:\nif (!require(report)) install.packages('report')\nif (!require(brms)) install.packages('brms')\nif (!require(lme4)) install.packages('lme4')\nif (!require(table1)) install.packages('table1')\nif (!require(modelsummary)) install.packages(\"modelsummary\")\nif (!require(naniar)) install.packages(\"naniar\")\nif (!require(ggraph)) install.packages(\"ggraph\")\nif (!require(gtsummary)) install.packages(\"gtsummary\")\n\n\n# load tidyverse\nlibrary(\"tidyverse\")\n\n# theme set\ntheme_set(theme_classic())\n\n# uncomment below and run this code\n# easystats::install_easystats_latest()\n\n\n\n\n\nnz_0 <- readr::read_csv2(url(\"https://raw.githubusercontent.com/go-bayes/psych-447/main/data/nz/nz.csv\"))\n\n# take all characters and make them factors\n# also get rid of duplicate rows\n# Note the convention of renaming dataframe when creating a new one:\n# ` nz <-nz_0 %>%... `\n\nf<-c(\"None Of The Time\",\"A Little Of The Time\", \"Some Of The Time\",  \"Most Of The Time\", \"All Of The Time\")\n\nnz <-nz_0 %>%\n  dplyr::mutate_if(is.character, factor) %>%\n  select(-c(SWB.Kessler01,SWB.Kessler02,SWB.Kessler03,SWB.Kessler04,SWB.Kessler05, SWB.Kessler06))%>%\n  dplyr::mutate(Wave = as.factor(Wave))%>%\n  mutate(FeelHopeless = forcats::fct_relevel(FeelHopeless,f))%>%\n  mutate(FeelDepressed = forcats::fct_relevel(FeelDepressed,f))%>%\n  mutate(FeelRestless = forcats::fct_relevel(FeelRestless,f))%>%\n  mutate(EverythingIsEffort = forcats::fct_relevel(EverythingIsEffort,f))%>%\n  mutate(FeelWorthless = forcats::fct_relevel(FeelWorthless,f))%>%\n  mutate(FeelNervous = forcats::fct_relevel(FeelNervous,f))\n\n# not used\n# nz <- haven::zap_formats(nz)\n# nz <- haven::zap_label(nz)\n# nz <- haven::zap_widths(nz)\n# nz <- haven::zap_labels(nz)\n\n\n\nPreamble\nOne of the advantages of R is that allows us to create highly effective workflows. Today, we’ll reinforce and extend the workflow skills that you’ve started to develop in previous weeks. Below we’ll be working with the nz dataset, which is a reduced, truncated, and jittered version of waves 10 and 11 of the New Zealand Attitudes and Values Study. This dataset is for teaching only, if you’d like to learn more about the study to which it belongs, go here or here.\nData carpentry continued\nDifferent methods for selecting columns\nSuppose we want to select all variables that start with Believe. We can do this in a number of ways.\nFirst there is explicit selection:\n\n\n# explicit selection \nnz %>%\n  select(\"Believe.God\", \"Believe.Spirit\")%>%\n    glimpse()\n\n\nRows: 4,126\nColumns: 2\n$ Believe.God    <fct> Not Believe God, Not Believe God, Believe God…\n$ Believe.Spirit <fct> Not Believe Spirit, Not Believe Spirit, Belie…\n\nWe can select all instances of a column that start with a certain name. For this you by using starts_with\n\n\nnz %>%\n  select(starts_with(\"Believe\"))%>%\n    glimpse()\n\n\nRows: 4,126\nColumns: 2\n$ Believe.God    <fct> Not Believe God, Not Believe God, Believe God…\n$ Believe.Spirit <fct> Not Believe Spirit, Not Believe Spirit, Belie…\n\nBy the same token, we can select all instances of a variable that ends with a certain string by using ends_with\n\n\nnz %>%\n  select(ends_with(\"conditions\"))%>%\n    glimpse()\n\n\nRows: 4,126\nColumns: 2\n$ NZ.Social.Conditions   <dbl> 7, 7, 2, 6, 5, 5, 2, 0, 9, 7, 3, 2, 2…\n$ NZ.Business.Conditions <dbl> 7, 8, 2, 6, 5, 5, 6, 5, 9, 7, 9, 5, 5…\n\nWe can cast a broader net and select all instances of a variable within a string by using contains\n\n\nnz %>%\n  select(contains(\"Believe\"))%>%\n    glimpse()\n\n\nRows: 4,126\nColumns: 3\n$ Religion.Believe.Cats <dbl> 4, 4, 1, 1, 1, 1, 1, NA, 3, 1, 4, 4, 4…\n$ Believe.God           <fct> Not Believe God, Not Believe God, Beli…\n$ Believe.Spirit        <fct> Not Believe Spirit, Not Believe Spirit…\n\nAs we can see, the net that we cast using contains was too broad. We don’t want the Religion.Believe.Cats.\nIn R, you can programme your way out of this corner as follows:\n\n\nnz %>%\n  select(contains(\"Believe\") &  -  Religion.Believe.Cats)%>%\n   glimpse()\n\n\nRows: 4,126\nColumns: 2\n$ Believe.God    <fct> Not Believe God, Not Believe God, Believe God…\n$ Believe.Spirit <fct> Not Believe Spirit, Not Believe Spirit, Belie…\n\nHowever, that’s inelegant; better to drop contains altogether and revert to another method.\nRe-leveling a factor\nDeath, taxes, and factors are consequence of living. Let’s look at the BigDoms variable in the nz, which is a factor identifying large religious denominations\n\n\nnz %>%\n  dplyr::select(BigDoms)%>%\n  table(useNA =\"ifany\")\n\n\n.\n Buddhist Christian    Muslim   Not_Rel TheOthers      <NA> \n       36      1204         9      2655       128        94 \n\nNote the use of ifany to print the NAs in this table. It’s almost never sensible to ignore missing values!\nSuppose we wanted to make “Not Rel” our base category for this factor. We could do so as follows:\n\n\n## suppose we want \"Not_Rel\" as the base category, and rearrange the other levels\nlibrary(forcats) # this is part of the tidyverse package. \nnz1<-nz %>%\n  dplyr::select(BigDoms, KESSLER6sum) %>%\n  dplyr::mutate(BigDoms =  \n                  forcats::fct_relevel(BigDoms, c(\"Not_Rel\",\"Christian\",\"Buddhist\",\"Muslim\",\"TheOthers\")))\n\n#inspect data\nnz1%>%\n  group_by(BigDoms)%>%\n  count()\n\n\n# A tibble: 6 x 2\n# Groups:   BigDoms [6]\n  BigDoms       n\n  <fct>     <int>\n1 Not_Rel    2655\n2 Christian  1204\n3 Buddhist     36\n4 Muslim        9\n5 TheOthers   128\n6 <NA>         94\n\nThe reordering makes for a more sensible model because the base category is now Not_Rel or not-religious. Hence comparisons are to this category.\n\n\nm0<- glm( KESSLER6sum ~ BigDoms, data = nz1 )\nparameters::model_parameters(m0)  %>%\n  print_html(caption = \"Model of Distress by Denomination with the base category is `No Religion'\")\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#pnzgigwjjn .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#pnzgigwjjn .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pnzgigwjjn .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#pnzgigwjjn .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#pnzgigwjjn .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pnzgigwjjn .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pnzgigwjjn .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#pnzgigwjjn .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#pnzgigwjjn .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#pnzgigwjjn .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#pnzgigwjjn .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#pnzgigwjjn .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pnzgigwjjn .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pnzgigwjjn .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#pnzgigwjjn .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#pnzgigwjjn .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#pnzgigwjjn .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#pnzgigwjjn .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pnzgigwjjn .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#pnzgigwjjn .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pnzgigwjjn .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#pnzgigwjjn .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#pnzgigwjjn .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pnzgigwjjn .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pnzgigwjjn .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#pnzgigwjjn .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pnzgigwjjn .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#pnzgigwjjn .gt_left {\n  text-align: left;\n}\n\n#pnzgigwjjn .gt_center {\n  text-align: center;\n}\n\n#pnzgigwjjn .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#pnzgigwjjn .gt_font_normal {\n  font-weight: normal;\n}\n\n#pnzgigwjjn .gt_font_bold {\n  font-weight: bold;\n}\n\n#pnzgigwjjn .gt_font_italic {\n  font-style: italic;\n}\n\n#pnzgigwjjn .gt_super {\n  font-size: 65%;\n}\n\n#pnzgigwjjn .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nModel of Distress by Denomination with the base category is `No Religion'\n    \n    Parameter\n      Coefficient\n      SE\n      95% CI\n      t(3991)\n      p\n    (Intercept)\n      5.38\n      0.08\n      (5.23, 5.54)\n      69.49\n      < .001\n    BigDoms (Christian)\n      -0.48\n      0.14\n      (-0.76, -0.21)\n      -3.47\n      < .001\n    BigDoms (Buddhist)\n      -0.97\n      0.67\n      (-2.28, 0.34)\n      -1.45\n      0.147 \n    BigDoms (Muslim)\n      1.17\n      1.33\n      (-1.43, 3.78)\n      0.88\n      0.378 \n    BigDoms (TheOthers)\n      0.18\n      0.36\n      (-0.53, 0.88)\n      0.49\n      0.621 \n    \n\nWe can see the results better using a coefficient graph, which visualises the information presented in the table.\n\n\nplot(parameters::model_parameters(m0) ) + labs(title = \"Comparison of Religious groups to secular people\", \nsubtitle = \"Christians are a little more chilled out, \\n Other denoms are less chilled out\")\n\n\n\n\nThe base category is the comparison class. Should we infer that “The Others” denomination causes greater distress? We’ll return to this, and related questions, in the upcoming weeks. For now let’s just leave it at “probably not.”\nCreating factors from numerical indicators\nIt is almost never a good idea to transform continuous data into categorical data. However, occassionally, you will need to do so. For example, we might want to break the KESSLER6 distress indicator into its medically diagnostic components for “mild distress,” “moderate distress,” and “severe distress.” We may achieve this task using the cut function as follows:\n\n\nnz <-nz %>%\n  dplyr::mutate(k6cats = cut(\n    KESSLER6sum,\n    breaks = c(-Inf, 5, 13, Inf),   # create Kessler 6 diagnostic categories\n    labels = c(\"Low Distress\", \"Moderate Distress\", \"Serious Distress\"), \n    right = TRUE\n  ))\ntable(nz$k6cats, useNA = \"ifany\")\n\n\n\n     Low Distress Moderate Distress  Serious Distress \n             2510              1400               177 \n             <NA> \n               39 \n\nUsing ifelse to create factors\nI prefer to maintain control over how I am making the categories. For example, in the previous example, I didn’t remember whether cut includes a value to the left or to the right. I had to look this up. However, I can use ifelse function to explicitly create the relevant categories:\n\n\nnz %>%\n  dplyr::mutate(k6cats1 =  as.factor(ifelse(\n    KESSLER6sum <= 5,\n    \"Low Distress\",\n    ifelse(KESSLER6sum <= 13,  \"Moderate Distress\", \"Serious Distress\")\n  ))) %>%\n  group_by(k6cats1) %>%\n  count()\n\n\n# A tibble: 4 x 2\n# Groups:   k6cats1 [4]\n  k6cats1               n\n  <fct>             <int>\n1 Low Distress       2510\n2 Moderate Distress  1400\n3 Serious Distress    177\n4 <NA>                 39\n\n#check this is the same as the previous method\nnz %>%\n  group_by(k6cats) %>%\n  count()\n\n\n# A tibble: 4 x 2\n# Groups:   k6cats [4]\n  k6cats                n\n  <fct>             <int>\n1 Low Distress       2510\n2 Moderate Distress  1400\n3 Serious Distress    177\n4 <NA>                 39\n\nWe can see that this method returns the same values as the cut method above.\nTransformations of indicators: scaling, centering, and logs\nThroughout this course, we’ll be standardising and centering indicators. Occasionally, we’ll need to perform log transformations. You’ll need to know how to do this.\nSuppose we want to standardise the Relid indicator. This will transform the Relid indicator into standard deviation units. In later seminars, we’ll explain why this transformation is useful. For now, this is how you do it:\n\n\nnz1 <- nz %>%\n  select(Relid)%>%\n  mutate(religousid_s = scale(Relid, scale = TRUE, center  = TRUE))\nhead(nz1)\n\n\n# A tibble: 6 x 2\n  Relid religousid_s[,1]\n  <dbl>            <dbl>\n1     0           -0.632\n2     0           -0.632\n3     0           -0.632\n4     0           -0.632\n5     0           -0.632\n6     0           -0.632\n\nWhat happened? The variable name for our standardised variable looks weird: religious_s[ ,1]\nThis isn’t a worry. We use the variable as we would any other and all is fine.1\n\n\nsjPlot::tab_model(lm(religousid_s ~ 1 , data = nz1))\n\n\n\n \n\n\nreligousid_s\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n0.00\n\n\n-0.03 – 0.03\n\n\n1.000\n\n\nObservations\n\n\n3963\n\n\nR2 / R2 adjusted\n\n\n0.000 / 0.000\n\n\nPro tip 1:\nTransform your data as the last step in your pipe workflow.\nThis is because if you filter cases, you’ll end up with a variable that isn’t measured standard deviations units\n\n\nnza <- nz %>%\n  select(Relid, BigDoms)%>%\n  mutate(religousid_s = scale(Relid, scale = TRUE, center  = TRUE)) \nnzb <- nz %>%\n  select(Relid, BigDoms)%>%\n  mutate(religousid_s = scale(Relid, scale = TRUE, center  = TRUE)) %>%\n  filter(BigDoms !=\"Not_Rel\")\n\n# compare\nsummary(nza$religousid_s)\n\n\n       V1         \n Min.   :-0.6315  \n 1st Qu.:-0.6315  \n Median :-0.6315  \n Mean   : 0.0000  \n 3rd Qu.: 0.9223  \n Max.   : 2.0877  \n NA's   :163      \n\n# with\nsummary(nzb$religousid_s)\n\n\n       V1         \n Min.   :-0.2431  \n 1st Qu.: 0.9223  \n Median : 1.3107  \n Mean   : 1.2819  \n 3rd Qu.: 2.0877  \n Max.   : 2.0877  \n NA's   :69       \n\nWhen we filter last, the mean value in the dataset is 1.28 – everything has changed!\n\n\nnz1 <- nz1 %>%\n  select(Relid)%>%\n  mutate(religousid_s = scale(Relid, scale = TRUE, center  = TRUE))\nhead(nz1)\n\n\n# A tibble: 6 x 2\n  Relid religousid_s[,1]\n  <dbl>            <dbl>\n1     0           -0.632\n2     0           -0.632\n3     0           -0.632\n4     0           -0.632\n5     0           -0.632\n6     0           -0.632\n\nor simply:\n\n\nnz1 <- nz1 %>%\n  select(Relid) %>%\n  mutate(religousid_s = scale(Relid))\n\nhead(nz1)\n\n\n\nTo center a variable we set scale = FALSE, center = TRUE\n\n\nnz1 <- nz %>%\n  mutate(religousid_c = scale(Relid, scale = FALSE, center  = TRUE))\n\n# inspect new indicator\nnz1%>%\n  select(Relid,religousid_c)%>%\n    glimpse()\n\n\nRows: 4,126\nColumns: 2\n$ Relid        <dbl> 0, 0, 0, 0, 0, 0, 7, 7, 2, 2, 0, 0, 0, 0, 0, 0,…\n$ religousid_c <dbl[,1]> <matrix[23 x 1]>\n\nWe use the log transformation for extreme values. We can create a new indicator by combining mutate and log as follows:\n\n\nnz1 <- nz %>%\n  mutate(charitydonate_log = log(CharityDonate + 1))\n\n# inspect new indicator\nnz1 %>%\n  select(CharityDonate,charitydonate_log)%>%\n    glimpse()\n\n\nRows: 4,126\nColumns: 2\n$ CharityDonate     <dbl> 180, 80, 300, 100, 4200, 3500, 400, 350, 5…\n$ charitydonate_log <dbl> 5.198497, 4.394449, 5.707110, 4.615121, 8.…\n\nNote that we have to add \\[+1\\] to the log transformation, as you will recall that the log of zero is undefined. You cannot obtain zero by raising it to the power of another number.\nCreate and work with dates a date\n\n\nnz <- nz %>%\n  dplyr::mutate(date = make_date(year = 2009, month = 6, day = 30) + TSCORE)  # first data of data collection in this study\n\n\n\nWe can analyze dates, for example, for how many minutes were data collected?\n\n\nnz %>%\n  select(date)%>%\n  summary()\n\n\n      date           \n Min.   :2018-01-02  \n 1st Qu.:2018-08-09  \n Median :2019-10-03  \n Mean   :2019-05-18  \n 3rd Qu.:2019-12-07  \n Max.   :2020-10-06  \n\nint<-lubridate::interval(ymd(\"2018-01-02\"), ymd(\"2020-10-06\"))\n\n#time in years\ntime_length(int, \"year\")\n\n\n[1] 2.759563\n\n#time in minutes\ntime_length(int, \"minutes\")\n\n\n[1] 1451520\n\nFun! So much so you have some homework that will work with dates.\nCreate a timeline\nHere we’re going to graph the number of responses each day for the years of data collection.\n\n\nlibrary(lubridate)\nlibrary(ggplot2)\n\n\ndatrep <- nz %>%\n  count(day = floor_date(date, \"day\"))%>%\n  dplyr::mutate(Year = factor(ifelse(\n    day < \"2018-01-01\",\n    2017,\n    ifelse(day < \"2019-01-01\", 2018,\n           ifelse(day < \"2020-01-01\", 2019, 2020))\n  ))) %>%\n  arrange(day)\n\n# create the graph\nggplot(datrep, aes(day, n)) +\n  geom_col(aes(fill = Year)) +\n  scale_x_date(date_labels = \"%b/%Y\")  +\n  xlab(\"Days\") + ylab(\"Count of Responses\") +\n  ggtitle(\"Our Dataset's Daily Counts\")  +\n  theme_classic()  +\n  scale_fill_viridis_d()\n\n\n\n\nNote that we can use the datrep dataframe that we created to explore aspects of data collection. For example we can arrange the dataset by day in descending order of participants sampled:\n\n\ndatrep%>%\n  arrange(desc(n))\n\n\n# A tibble: 607 x 3\n   day            n Year \n   <date>     <int> <fct>\n 1 2018-06-21   112 2018 \n 2 2018-06-22    93 2018 \n 3 2018-06-24    80 2018 \n 4 2018-06-20    67 2018 \n 5 2018-06-23    59 2018 \n 6 2018-06-26    58 2018 \n 7 2019-12-03    54 2019 \n 8 2018-06-25    52 2018 \n 9 2019-10-04    47 2019 \n10 2019-12-02    46 2019 \n# … with 597 more rows\n\nTake not of that code, you might need it for your workbook.\nWhat might we do with dates? Well we might ask, were there any inherently stressful days?\nTo see this, we can take average stress levels by day, and then see where the high average stress days fall.\n\n\ntn<-nz %>%\n  select(date,KESSLER6sum,Id) %>%\n  group_by(date)%>%\n  summarise(\n   av_distress =  mean(KESSLER6sum, na.rm = TRUE),\n   n = n_distinct(Id)\n  ) %>%\n  arrange(desc(av_distress))%>%\n  glimpse()\n\n\nRows: 607\nColumns: 3\n$ date        <date> 2018-12-16, 2020-07-06, 2018-11-13, 2019-01-05,…\n$ av_distress <dbl> 21.00000, 16.00000, 15.50000, 15.00000, 15.00000…\n$ n           <int> 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, …\n\nGraphing the densities reveals the following\n\n\ntn%>%\n  ggplot(., aes(date, av_distress)) + \n  geom_col(aes(fill =(n))) + scale_x_date(date_labels = \"%b/%Y\")  + theme_classic() + scale_fill_viridis_c()\n\n\n\n\nClearly the “stressful days” are an artifact of days with low numbers of participant respondents.\nLet’s see whether there are any stressful days of the week. We do this by creating a weekday variable using the wday function in the lubridate package. Let’s graph our results using a pipe %>% workflow:\n\n\nnz %>%\n  select(Id, date, KESSLER6sum) %>%\n  mutate(weekdays = wday(date, label = TRUE)) %>%\n  group_by(weekdays) %>%\n  summarise(\n    mn_k6 =  mean(KESSLER6sum, na.rm = TRUE),\n    sd_k6 =  sd(KESSLER6sum, na.rm = TRUE),\n    n_k6w = n()\n  ) %>%\n  mutate(\n    se_k6 = sd_k6 / sqrt(n_k6w),\n    lw_ci = mn_k6 - qt(1 - (0.05 / 2), n_k6w - 1) * se_k6,\n    up_ci = mn_k6 + qt(1 - (0.05 / 2), n_k6w - 1) * se_k6\n  ) %>%\n  ggplot(., aes(x = weekdays, y = mn_k6, colour = mn_k6)) +\n  geom_errorbar(aes(ymin = lw_ci, ymax = up_ci), width = .1) +\n  geom_point(size = 3)  +\n  scale_y_continuous(limits = c(0,7)) + \n  theme_classic() + scale_fill_viridis_d()\n\n\n\n\nDespite the variability over the two years of data collection, the bars of the graph overlap: we don’t find differences in distress by days.\n“Ok Boomer,” you ask, “what if we were to calculate distress by generational cohorts?”\nMy reply, I’m not a boomer, I’m a GenX-er. I’m keen to check it out:\n\n\nnz$hour\n\n\nNULL\n\nnz %>%\n  select(GenCohort, KESSLER6sum) %>%\n  group_by(GenCohort) %>%\n  summarise(\n    mn_k6 =  mean(KESSLER6sum, na.rm = TRUE),\n    sd_k6 =  sd(KESSLER6sum, na.rm = TRUE),\n    n_k6w = n()\n  ) %>%\n  mutate(\n    se_k6 = sd_k6 / sqrt(n_k6w),\n    lw_ci = mn_k6 - qt(1 - (0.05 / 2), n_k6w - 1) * se_k6,\n    up_ci = mn_k6 + qt(1 - (0.05 / 2), n_k6w - 1) * se_k6\n  ) %>%\n  ggplot(., aes(x = GenCohort, y = mn_k6, colour = GenCohort)) +\n  geom_errorbar(aes(ymin = lw_ci, ymax = up_ci), width = .1) +\n  geom_point(size = 3)  +\n  scale_y_continuous(limits = c(0, 7)) +\n  theme_classic() +\n  geom_hline(yintercept = 5,\n             colour = \"red\",\n             linetype = \"dashed\") +\n  scale_y_continuous(limits = c(0, 10)) +\n  theme(\n    legend.text = element_text(size = 6),\n    legend.title = element_text(size = 8),\n    axis.text.x = element_blank()\n  ) +\n  xlab(\"Birth Generation Cohort\") +\n  ylab(\"Kessler 6 Distress\") +\n  labs(title = \"Average Distress by Birth Cohort\",\n       subtitle = \"Red line indicates clinically moderate distress threshold\") +\n  scale_colour_viridis_d() \n\n\n\n\nLater, we’ll ask why you’re so stressed out.\nSlice\nDplyr’s slice function can be handy. Say we only want the first four rows\n\n\ndatrep%>%\n  arrange(desc(n)) %>%\n  slice(1:4)\n\n\n# A tibble: 4 x 3\n  day            n Year \n  <date>     <int> <fct>\n1 2018-06-21   112 2018 \n2 2018-06-22    93 2018 \n3 2018-06-24    80 2018 \n4 2018-06-20    67 2018 \n\nSay we only want the 1st row, the 3rd row, and the 20th row\n\n\ndatrep%>%\n  dplyr::arrange(desc(n)) %>%\n  dplyr::slice(c(1,3,20))\n\n\n# A tibble: 3 x 3\n  day            n Year \n  <date>     <int> <fct>\n1 2018-06-21   112 2018 \n2 2018-06-24    80 2018 \n3 2020-03-18    38 2020 \n\nLags and leads using timeseries data\nCreate a difference variable for change in Kessler 6\n\n\nlibrary(\"pmdplyr\")\ndf <-nz %>%\n  dplyr::filter(!is.na(KESSLER6sum))%>%\n  mutate(wave = as.numeric(Wave))%>%\n   mutate(lag_k6 = tlag(KESSLER6sum,\n    .i = Id, # id variable\n    .t = wave # time series variable, needs to be numeric\n  ))%>%\n  mutate(diff_k6 = lag_k6 - KESSLER6sum) %>%\n  select(Id,Wave,KESSLER6sum,diff_k6,Emp.JobSecure,Employed)%>%\n  arrange(desc(diff_k6)) \n\n\n\nWhat to do with this new variable. Well, we might explore whether employment security relates to distress change:\n\n\ndf %>%\n  filter(Wave == 2019) %>%\n  mutate(employed_employsecurity = as.factor(ifelse(Employed ==1, Emp.JobSecure,0)))%>%\n  ggplot(data = ., aes(x = diff_k6, fill = employed_employsecurity) )+\n   geom_histogram() + \n  xlab(\"Difference in K6 eleveation (cases above 5)\") + \n  ylab(\"Counts of cases\") + \n  labs(subtitle =\"No clear relationship between unemployment insecurity and distress change\")+\n  scale_fill_discrete(name=\"Employment Security 1-7\") + \n  scale_fill_viridis_d() + theme_classic() + \n  theme(legend.position = \"bottom\")\n\n\n\n\nAnd remarkably we don’t see much evidence in the cross-sectional analysis.\n\n\n# create data frame with new variable Zero is for the unemeployed. \ndfnew <- df %>%\n  filter(Wave == 2019) %>%\n  mutate(employed_employsecurity = as.numeric(ifelse(Employed == 1, Emp.JobSecure, 0)))%>%\nfilter(!is.na(employed_employsecurity))\n\nhead(dfnew)\n\n\n# A tibble: 6 x 7\n     Id Wave  KESSLER6sum diff_k6 Emp.JobSecure Employed\n  <dbl> <fct>       <dbl>   <dbl>         <dbl>    <dbl>\n1   165 2019            0      20            NA        0\n2  1936 2019            3      15            NA        0\n3  1037 2019           10      14             4        1\n4   722 2019            2      12             7        1\n5  1568 2019            8      12            NA        0\n6  1606 2019            7      12             7        1\n# … with 1 more variable: employed_employsecurity <dbl>\n\n# Graph\nggplot(dfnew, aes(y = diff_k6, employed_employsecurity)) +\n  geom_jitter(alpha = .2) +\n  geom_smooth(method = lm) +\n  xlab(\"employed_employsecurity\") +\n  ylab(\"Kessler 6 distress jumps over 5\") +\n  ggtitle(\"Jumps in distress change not related to employement insecurity\") +\n  scale_fill_viridis_d() + theme_classic()\n\n\n\n\nHowever, perhaps our indicator is misleading us. We can formally model the relationship between employment security and Kessler6 distress across two years\n\n\n# create dataframe with the variables we need\ndfnew2 <- df %>%\n  mutate(employed_employsecurity = as.numeric(ifelse(Employed == 1, Emp.JobSecure, 0))) %>%\n  filter(!is.na(employed_employsecurity)) %>%\n  dplyr::mutate(employsecurity_s = scale(employed_employsecurity))\n\n# multi-level model \n\nm00a<-lme4::lmer(KESSLER6sum ~  employsecurity_s * Wave + (1|Id), data = dfnew2)\nplot(ggeffects::ggpredict(m00a, terms=c(\"employsecurity_s\", \"Wave\")),\n     add.data = TRUE, jitter = 0.2, dot.alpha =.05) + geom_hline(yintercept = 5,\n             colour = \"red\",\n             linetype = \"dashed\") + \n  labs(title = \"There is a relationship between employment security and Kessler6 distress\")\n\n\n\n\nThis suggests a stable negative relationship between employment security and (low) distress. So is there are causal relationship? Not necessarily. Again, we return to casual inference in the upcoming weeks. For now, we want to alert you to an important lesson:\nPro tip 2\nDo not read too much into your descriptive analysis!\nThis is especially true when creating new variables. Just because you can make a variable doesn’t mean you should use it, or interpret it!\nPut differently, our workflow will require much more than descriptive statistics.\nData summary\nSummarise all your data\nThe skimr package\nThe skimmer package can be helpful in detecting problems. A drawback note that it is interpreting all factors as numbers).\nFor example. ( I won’t run the following code, you will do so for your homework).\n\n\nlibrary(\"skimr\")\nnz %>%\n  select(-date) %>% #not useful\n  dplyr::group_by(Wave) %>%\n  skim()\n\n\n\nHowever, I want to point out that skimr works with individual columns, and it accepts a tidy workflow.\n\n\nnz %>%\n  dplyr::group_by(Wave) %>%\n  select(KESSLER6sum,HLTH.SleepHours)  %>%\n  skim() \n\n\n\nTable 1: Data summary\n\n\n\n\n\n\nName\n\n\nPiped data\n\n\nNumber of rows\n\n\n4126\n\n\nNumber of columns\n\n\n3\n\n\n_______________________\n\n\n\n\nColumn type frequency:\n\n\n\n\nnumeric\n\n\n2\n\n\n________________________\n\n\n\n\nGroup variables\n\n\nWave\n\nVariable type: numeric\n\nskim_variable\n\n\nWave\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmean\n\n\nsd\n\n\np0\n\n\np25\n\n\np50\n\n\np75\n\n\np100\n\n\nhist\n\n\nKESSLER6sum\n\n\n2018\n\n\n28\n\n\n0.99\n\n\n5.14\n\n\n4.00\n\n\n0\n\n\n2\n\n\n4\n\n\n7\n\n\n24\n\n\n▇▆▂▁▁\n\n\nKESSLER6sum\n\n\n2019\n\n\n11\n\n\n0.99\n\n\n5.35\n\n\n3.97\n\n\n0\n\n\n2\n\n\n5\n\n\n7\n\n\n24\n\n\n▇▆▂▁▁\n\n\nHLTH.SleepHours\n\n\n2018\n\n\n103\n\n\n0.95\n\n\n6.92\n\n\n1.07\n\n\n3\n\n\n6\n\n\n7\n\n\n8\n\n\n11\n\n\n▁▆▇▅▁\n\n\nHLTH.SleepHours\n\n\n2019\n\n\n78\n\n\n0.96\n\n\n6.88\n\n\n1.09\n\n\n2\n\n\n6\n\n\n7\n\n\n8\n\n\n12\n\n\n▁▃▇▁▁\n\n\nTable1 & other canned table packages\nIn earlier seminars, we encountered the table1 package, which makes really great html tables:\n\n\nlibrary(table1)\n\ntable1::table1(~Age  +\n                 GenCohort +\n                 Male + \n                 Edu +\n                 Pol.Orient + \n                 Relid + \n                 BigDoms   | Wave, data = nz,\n               overall = FALSE)\n\n\n\n2018(N=2063)\n2019(N=2063)\nAge\n\n\nMean (SD)\n50.2 (13.4)\n50.9 (13.4)\nMedian [Min, Max]\n52.0 [18.0, 92.0]\n53.0 [19.0, 92.0]\nGenCohort\n\n\nGen Boombers: born >= 1946 & b.< 1961\n676 (32.8%)\n676 (32.8%)\nGen_Silent: born< 1946\n51 (2.5%)\n51 (2.5%)\nGenX: born >=1961 & b.< 1980\n915 (44.4%)\n915 (44.4%)\nGenY: born >=1980 & b.< 1996\n368 (17.8%)\n368 (17.8%)\nGenZ: born >= 1996\n53 (2.6%)\n53 (2.6%)\nMale\n\n\nMale\n755 (36.6%)\n752 (36.5%)\nNot_Male\n1305 (63.3%)\n1305 (63.3%)\nMissing\n3 (0.1%)\n6 (0.3%)\nEdu\n\n\nMean (SD)\n5.54 (2.73)\n5.71 (2.66)\nMedian [Min, Max]\n7.00 [0, 10.0]\n7.00 [0, 10.0]\nMissing\n77 (3.7%)\n50 (2.4%)\nPol.Orient\n\n\nMean (SD)\n3.58 (1.40)\n3.58 (1.37)\nMedian [Min, Max]\n4.00 [1.00, 7.00]\n4.00 [1.00, 7.00]\nMissing\n119 (5.8%)\n69 (3.3%)\nRelid\n\n\nMean (SD)\n1.69 (2.58)\n1.56 (2.57)\nMedian [Min, Max]\n0 [0, 7.00]\n0 [0, 7.00]\nMissing\n51 (2.5%)\n112 (5.4%)\nBigDoms\n\n\nBuddhist\n17 (0.8%)\n19 (0.9%)\nChristian\n624 (30.2%)\n580 (28.1%)\nMuslim\n4 (0.2%)\n5 (0.2%)\nNot_Rel\n1301 (63.1%)\n1354 (65.6%)\nTheOthers\n75 (3.6%)\n53 (2.6%)\nMissing\n42 (2.0%)\n52 (2.5%)\n\n\nUnfortunately, the table1 package only prints html tables.\nFor publications, I might use the modelsummary package\n\n\nlibrary(\"modelsummary\")\nnnz<-nz %>%\n  dplyr::select(Age, \n                Male,\n                BigDoms,\n                Edu,\n                GenCohort,\n                Relid,\n                Pol.Orient,\n                Wave)\nmodelsummary::datasummary_balance( ~ Wave, data=nnz, dinm=FALSE, output = 'table.tex')\n\n\n\nI’ll put the \\(LaTeX\\) output into my document because I generally prefer to write in \\(LaTeX\\)\nHowever if you want to print inline, you can simply use:\n\n\nlibrary(\"modelsummary\")\nnnz<-nz %>%\n  dplyr::select(Age, \n                Male,\n                BigDoms,\n                Edu,\n                GenCohort,\n                Relid,\n                Pol.Orient,\n                Wave)\nmodelsummary::datasummary_balance( ~ Wave, data=nnz, dinm=FALSE)\n\n\n\n\n\n\n2018 (N=2063)\n\n\n\n\n2019 (N=2063)\n\n\n\n\n\n\n\nMean\n\n\nStd. Dev.\n\n\nMean\n\n\nStd. Dev.\n\n\nAge\n\n\n\n\n50.2\n\n\n13.4\n\n\n50.9\n\n\n13.4\n\n\nEdu\n\n\n\n\n5.5\n\n\n2.7\n\n\n5.7\n\n\n2.7\n\n\nRelid\n\n\n\n\n1.7\n\n\n2.6\n\n\n1.6\n\n\n2.6\n\n\nPol.Orient\n\n\n\n\n3.6\n\n\n1.4\n\n\n3.6\n\n\n1.4\n\n\n\n\n\n\nN\n\n\n%\n\n\nN\n\n\n%\n\n\nMale\n\n\nMale\n\n\n755\n\n\n36.6\n\n\n752\n\n\n36.5\n\n\n\n\nNot_Male\n\n\n1305\n\n\n63.3\n\n\n1305\n\n\n63.3\n\n\nBigDoms\n\n\nBuddhist\n\n\n17\n\n\n0.8\n\n\n19\n\n\n0.9\n\n\n\n\nChristian\n\n\n624\n\n\n30.2\n\n\n580\n\n\n28.1\n\n\n\n\nMuslim\n\n\n4\n\n\n0.2\n\n\n5\n\n\n0.2\n\n\n\n\nNot_Rel\n\n\n1301\n\n\n63.1\n\n\n1354\n\n\n65.6\n\n\n\n\nTheOthers\n\n\n75\n\n\n3.6\n\n\n53\n\n\n2.6\n\n\nGenCohort\n\n\nGen Boombers: born >= 1946 & b.< 1961\n\n\n676\n\n\n32.8\n\n\n676\n\n\n32.8\n\n\n\n\nGen_Silent: born< 1946\n\n\n51\n\n\n2.5\n\n\n51\n\n\n2.5\n\n\n\n\nGenX: born >=1961 & b.< 1980\n\n\n915\n\n\n44.4\n\n\n915\n\n\n44.4\n\n\n\n\nGenY: born >=1980 & b.< 1996\n\n\n368\n\n\n17.8\n\n\n368\n\n\n17.8\n\n\n\n\nGenZ: born >= 1996\n\n\n53\n\n\n2.6\n\n\n53\n\n\n2.6\n\n\nCreate a table using pipe functions\nAbove we saw how to create a clunky table using table(x). However, R has lots of functionality to enable better.\n\n\nlibrary(kableExtra)\nnz %>%\n  select(k6cats, Wave) %>%\n  filter(!is.na(k6cats))%>%\n  group_by( Wave, k6cats) %>%\n  summarise(n = n())%>%\n  kbl(caption = \"Distress by Year\") %>%\n   kable_classic_2(c(\"striped\", \"hover\"), full_width = TRUE)%>%\n  collapse_rows()\n\n\n\nTable 2: Distress by Year\n\n\nWave\n\n\nk6cats\n\n\nn\n\n\n2018\n\n\nLow Distress\n\n\n1272\n\n\n2018\n\n\nModerate Distress\n\n\n675\n\n\n2018\n\n\nSerious Distress\n\n\n88\n\n\n2019\n\n\nLow Distress\n\n\n1238\n\n\n2019\n\n\nModerate Distress\n\n\n725\n\n\n2019\n\n\nSerious Distress\n\n\n89\n\n\nNote that we can use the pivot_wider function to spread the dataframe to enable a table that is easier to interpret.\nCredit where credit is due: I just learned about pivot_wider from Johannes and Thorven. I’m keen to get pivot_longer and pivot_wider into my vocabulary, and to do more things, like this:\n\n\nnz %>%\n  select(k6cats, Wave) %>%\n  filter(!is.na(k6cats))%>%\n  group_by( Wave, k6cats) %>%\n  summarise(n = n())%>%\n pivot_wider(names_from = Wave, values_from = n) %>%\n   kbl(caption = \"Distress counts by year\") %>%\n   kable_classic_2(c(\"striped\", \"hover\"), full_width = TRUE)\n\n\n\nTable 3: Distress counts by year\n\n\nk6cats\n\n\n2018\n\n\n2019\n\n\nLow Distress\n\n\n1272\n\n\n1238\n\n\nModerate Distress\n\n\n675\n\n\n725\n\n\nSerious Distress\n\n\n88\n\n\n89\n\n\nNice!\nBar graphs\nFor categorical data, in place of tables we can use bar graphs\nHere’s the table:\n\n\ntable(nz$BigDoms)\n\n\n\n Buddhist Christian    Muslim   Not_Rel TheOthers \n       36      1204         9      2655       128 \n\nHere’s the bar graph:\n\n\nggplot(nz) + \n  geom_bar(mapping = aes(x = BigDoms))\n\n\n\n\nNote that we can re-order the factor levels to produce a nicer output, using fct_infreq\n\n\nggplot(nz) + \n  geom_bar(mapping = aes(x = fct_infreq(BigDoms))  )\n\n\n\n\nMissing data graphs\nWhat do you notice about the patterns of missingness in this graph?\n\n\nlibrary(\"naniar\")\nnaniar::vis_miss(nz) #What do you notice? \n\n\n\n\nHere, we find all the problem cases:\n\n\ngg_miss_upset(nz)\n\n\n\n\nWhat explains these feature of missingess?\nBoxplots\nA box plot provides visual information for the following statistics:\nMinimum – (0p) min outlier\nMaximum – (100p) max outlier\nMedian – (50th p)\nFirst Quartile (Q1 or 25p)\nThird Quartile (Q3 or 75p)\nInterquartile range (IQR), whcih is the distance between Q1 and Q3\nOptional: the notch displays a confidence interval around the median. This is +/- 1.58 X IQR/sqrt(n). We use notches to compare differences between groups; overlap implies uncertainty about whether the medians differ.\nThere’s a simple explanation here\nWe can use base R to investigate differences in distress among big denominations:\n\n\n# using base R\nboxplot(KESSLER6sum ~ BigDoms, data = nz, notch = TRUE, col = c(\"cadetblue1\",\"orange\",\"red\",\"darkblue\",\"brown\"))\n\n\n\n\nHere’s a ggplot boxplot:\n\n\nggplot(data = nz, aes(x = KESSLER6sum, y = BigDoms, fill = BigDoms)) + \n  geom_boxplot(notch=TRUE) + scale_fill_viridis_d() + \n  ggtitle(\"If the notches don't overlap, there's likely a difference\") + \n  geom_jitter(alpha = .05)\n\n\n\n\nHere’s a ggplot2 boxplot with points overlaid, and jittered. This allows us to se the differences in sample sizes\n\n\nggplot(data = nz, aes(x = KESSLER6sum, y = BigDoms, fill = BigDoms)) + \n  geom_boxplot(notch=TRUE) + scale_fill_viridis_d() + \n  ggtitle(\"If the notches don't overlap, there's likely a difference\") + \n  geom_jitter(alpha = .07)\n\n\n\n\nWe could look at differences by wave:\n\n\nggplot(data = nz, aes(x = KESSLER6sum, y = BigDoms, fill = BigDoms)) + \n  geom_boxplot(notch=TRUE) + scale_fill_viridis_d() + \n   geom_jitter(alpha = .07) + \n  facet_grid(Wave ~ .) +\n  ggtitle(\"If the notches don't overlap, there's likely a difference\") \n\n\n\n\nCorrelation graphs\nJohannes will describe a method for making a correlation plot. Here is another method.\n\n\nbzsec<-nz%>%\n  select(\n    Your.Future.Security,\n    Standard.Living,\n    NZ.Economic.Situation,\n    NZ.Business.Conditions,\n    Emp.JobSecure,\n    CharityDonate,\n    Id\n  ) %>%\n  mutate_all(., as.numeric) %>% #make numeric \n  mutate(Id = as.factor(Id),\n         CharityDonate = log(CharityDonate + 1))# make Id a factor for the \n\n# make a correlation plot using the \"correlation\" package from easystates\n\nlibrary(correlation)\np1<-bzsec %>%\n  correlation(partial = FALSE, multilevel = TRUE ) %>%\n  plot()\n\n\n\nPrint summary\n\n\nbzsec %>%\n  correlation(partial = FALSE, multilevel = TRUE ) %>%\n  summary()\n\n\nParameter              | CharityDonate | Emp.JobSecure | NZ.Business.Conditions | NZ.Economic.Situation | Standard.Living\n-------------------------------------------------------------------------------------------------------------------------\nYour.Future.Security   |         0.05* |       0.24*** |                0.44*** |               0.31*** |         0.34***\nStandard.Living        |       0.09*** |       0.18*** |                0.22*** |               0.28*** |                \nNZ.Economic.Situation  |          0.03 |       0.11*** |                0.43*** |                       |                \nNZ.Business.Conditions |          0.03 |       0.14*** |                        |                       |                \nEmp.JobSecure          |         0.05* |               |                        |                       |                \n\nLet’s set multilevel to FALSE.\n\n\nlibrary(correlation)\np2<-bzsec %>%\n  select(-Id)%>% # get rid of grouping variable\n  correlation(partial = FALSE, multilevel = FALSE ) %>%\n  plot()\n#print summary\nbzsec %>%\n  select(-Id)%>% # get rid of grouping variable\n  correlation(partial = FALSE, multilevel = FALSE ) %>%\n  summary()\n\n\n# Correlation Matrix (pearson-method)\n\nParameter              | CharityDonate | Emp.JobSecure | NZ.Business.Conditions | NZ.Economic.Situation | Standard.Living\n-------------------------------------------------------------------------------------------------------------------------\nYour.Future.Security   |       0.19*** |       0.35*** |                0.52*** |               0.41*** |         0.52***\nStandard.Living        |       0.22*** |       0.28*** |                0.31*** |               0.36*** |                \nNZ.Economic.Situation  |       0.07*** |       0.15*** |                0.52*** |                       |                \nNZ.Business.Conditions |       0.08*** |       0.21*** |                        |                       |                \nEmp.JobSecure          |       0.09*** |               |                        |                       |                \n\np-value adjustment method: Holm (1979)\n\n\n\nlibrary(patchwork)\n# create a two panel plot\np1 / p2 + \n  plot_annotation(title = \"Plot of multilevel (a) and single-level (b) correlation\", tag_levels = 'a')\n\n\n\n\nWe can see an even greater correlations between the variables. This is because the model does not adjust for the repeated measures, which create dependencies in the data.\nThe report package\nThe reports package from the easystats group is powerful tool for saving tame. Before extolling its virtues, I’d like to point out two major limitations.\nFirst, the package is in development. Currently, it has lots of bugs.\nSecond, the package uses terminology that won’t work for all contexts and purposes. For example, it uses the term “significant” to describe p values that are below the traditional p = .05 threshold.\nIf you learn nothing else from this course, you should learn never to use “significant” to describe a p value. You may, if you like, use “statistically signficant” however it would be better altogether if you simply dropped p-values from data analysis. We’ll show you how. With those provisos in mind, consider some useful functionality from the report package.\n\n\n# create a demographic dataframe\nnz_demagraphics <- nz %>%\n  select(Age, GenCohort, Male, Edu, Pol.Orient, Relid, BigDoms, Wave)\n\n# now a nice way to save you time when reporting\npaste(\n  report::report_participants(\n    nz_demagraphics, \n    group = \"Wave\", \n    age = \"Age\",\n    sex = \"Male\",\n    education = \"Edu\",\n    spell_n = TRUE),\n  \"were recruited in the study by through enticement by lollipops. Those who did not volunteer were coerced.\"\n  )\n\n\n[1] \"For the 'Wave - 2018' group: Two Thousand, Sixty Three participants (Mean age = 50.2, SD = 13.4, range: [18, 92]; 0.0% females; Mean education = 5.5, SD = 2.7, range: [0, 10]) and for the 'Wave - 2019' group: Two Thousand, Sixty Three participants (Mean age = 50.9, SD = 13.4, range: [19, 92]; 0.0% females; Mean education = 5.7, SD = 2.7, range: [0, 10]) were recruited in the study by through enticement by lollipops. Those who did not volunteer were coerced.\"\n\nThe table function of report isn’t great yet. However it has some nice features. For example you should always report your session information, and doing so in tabluar form clarifies the elements\nTry running the following code on your own:\n\n\nr <- report_table(sessionInfo())\nr\n\n\n\nHere is another method, which you can try on your own\n\n\ncite_packages()\n\n\n\nHere’s a demographic table (try on your own)\n\n\nreport_table(nz_demagraphics)\n\n\n\nHere’s a data summary\n\n\nlibrary(\"report\")\nnz %>%\n  group_by(Wave)%>%\n  select(\n    \"Wave\", \n    \"Age\",\n    \"Male\",\n    \"Edu\",\n    \"Relid\",\n    \"Pol.Orient\",\n    \"KESSLER6sum\",\n    \"FeelHopeless\",\n    \"FeelDepressed\",\n    \"FeelRestless\",\n    \"EverythingIsEffort\",\n    \"FeelWorthless\",\n    \"FeelNervous\"\n    )%>%\n  report() %>% \n  summary()\n\n\nThe data contains 4126 observations, grouped by Wave, of the following variables:\n\n- 2018 (n = 2063):\n  - Age: Mean = 50.19, SD = 13.38, range: [18, 92]\n  - Male: 2 levels, namely Male (n = 755), Not_Male (n = 1305) and missing (n = 3)\n  - Edu: Mean = 5.54, SD = 2.73, range: [0, 10], 3.73% missing\n  - Relid: Mean = 1.69, SD = 2.58, range: [0, 7], 2.47% missing\n  - Pol.Orient: Mean = 3.58, SD = 1.40, range: [1, 7], 5.77% missing\n  - KESSLER6sum: Mean = 5.14, SD = 4.00, range: [0, 24], 1.36% missing\n  - FeelHopeless: 5 levels, namely None Of The Time (n = 1012), A Little Of The Time (n = 627), Some Of The Time (n = 325), Most Of The Time (n = 58), All Of The Time (n = 11) and missing (n = 30)\n  - FeelDepressed: 5 levels, namely None Of The Time (n = 1481), A Little Of The Time (n = 345), Some Of The Time (n = 156), Most Of The Time (n = 35), All Of The Time (n = 12) and missing (n = 34)\n  - FeelRestless: 5 levels, namely None Of The Time (n = 520), A Little Of The Time (n = 751), Some Of The Time (n = 585), Most Of The Time (n = 143), All Of The Time (n = 29) and missing (n = 35)\n  - EverythingIsEffort: 5 levels, namely None Of The Time (n = 523), A Little Of The Time (n = 827), Some Of The Time (n = 490), Most Of The Time (n = 159), All Of The Time (n = 32) and missing (n = 32)\n  - FeelWorthless: 5 levels, namely None Of The Time (n = 1469), A Little Of The Time (n = 348), Some Of The Time (n = 147), Most Of The Time (n = 48), All Of The Time (n = 19) and missing (n = 32)\n  - FeelNervous: 5 levels, namely None Of The Time (n = 537), A Little Of The Time (n = 804), Some Of The Time (n = 509), Most Of The Time (n = 148), All Of The Time (n = 28) and missing (n = 37)\n\n- 2019 (n = 2063):\n  - Age: Mean = 50.94, SD = 13.38, range: [19, 92]\n  - Male: 2 levels, namely Male (n = 752), Not_Male (n = 1305) and missing (n = 6)\n  - Edu: Mean = 5.71, SD = 2.66, range: [0, 10], 2.42% missing\n  - Relid: Mean = 1.56, SD = 2.57, range: [0, 7], 5.43% missing\n  - Pol.Orient: Mean = 3.58, SD = 1.37, range: [1, 7], 3.34% missing\n  - KESSLER6sum: Mean = 5.35, SD = 3.97, range: [0, 24], 0.53% missing\n  - FeelHopeless: 5 levels, namely None Of The Time (n = 961), A Little Of The Time (n = 660), Some Of The Time (n = 348), Most Of The Time (n = 67), All Of The Time (n = 8) and missing (n = 19)\n  - FeelDepressed: 5 levels, namely None Of The Time (n = 1399), A Little Of The Time (n = 403), Some Of The Time (n = 195), Most Of The Time (n = 47), All Of The Time (n = 7) and missing (n = 12)\n  - FeelRestless: 5 levels, namely None Of The Time (n = 501), A Little Of The Time (n = 794), Some Of The Time (n = 577), Most Of The Time (n = 158), All Of The Time (n = 17) and missing (n = 16)\n  - EverythingIsEffort: 5 levels, namely None Of The Time (n = 470), A Little Of The Time (n = 798), Some Of The Time (n = 572), Most Of The Time (n = 179), All Of The Time (n = 29) and missing (n = 15)\n  - FeelWorthless: 5 levels, namely None Of The Time (n = 1434), A Little Of The Time (n = 359), Some Of The Time (n = 193), Most Of The Time (n = 51), All Of The Time (n = 12) and missing (n = 14)\n  - FeelNervous: 5 levels, namely None Of The Time (n = 540), A Little Of The Time (n = 824), Some Of The Time (n = 539), Most Of The Time (n = 122), All Of The Time (n = 25) and missing (n = 13)\n\nNotes:\nMore about the report package: here\nThis package is brought to you by easystats\nMeasures\nWhen reporting your study, it is extremely important to include information about your measure. For example:\nWe measure psychological distress using the Kessler-6 scale (R. C. Kessler et al. 2002), which exhibits strong diagnostic concordance for moderate and severe psychological distress in large, cross-cultural samples Prochaska et al. (2012). Participants rated during the past 30 days, how often did… (a) “\\(\\dots\\) you feel hopeless”; (b) “\\(\\dots\\) you feel so depressed that nothing could cheer you up”; (c) \\(\\dots\\) you feel restless or fidgety”; (d)“\\(\\dots\\) you feel that everything was an effort”; (e) “\\(\\dots\\) you feel worthless”; (f) “\\(\\dots\\) you feel nervous?” Ordinal response alternatives for the Kessler-6 are: “None of the time”; “A little of the time”; “Some of the time”; “Most of the time”; “All of the time.”\nWe report sample descriptive statistics for indicators of personal Kessler-6 distress below in Table1.\nTable 1\n\n\nlibrary(gtsummary)\ntb1 <-nz %>%\n  dplyr::select(\n    KESSLER6sum,\n    FeelHopeless,\n    FeelDepressed,\n    FeelRestless,\n    EverythingIsEffort,\n    FeelWorthless,\n    FeelNervous,\n    Wave,\n  ) %>%\n  gtsummary::tbl_summary(\n    by = Wave,\n    statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\",\n      all_categorical() ~ \"{n} / {N} ({p}%)\"\n    ),\n    digits = all_continuous() ~ 2,\n    missing_text = \"(Missing)\"\n  )%>%\n  bold_labels() \ntb1\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#khxjlfirnb .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#khxjlfirnb .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#khxjlfirnb .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#khxjlfirnb .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#khxjlfirnb .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#khxjlfirnb .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#khxjlfirnb .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#khxjlfirnb .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#khxjlfirnb .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#khxjlfirnb .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#khxjlfirnb .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#khxjlfirnb .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#khxjlfirnb .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#khxjlfirnb .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#khxjlfirnb .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#khxjlfirnb .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#khxjlfirnb .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#khxjlfirnb .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#khxjlfirnb .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#khxjlfirnb .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#khxjlfirnb .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#khxjlfirnb .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#khxjlfirnb .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#khxjlfirnb .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#khxjlfirnb .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#khxjlfirnb .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#khxjlfirnb .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#khxjlfirnb .gt_left {\n  text-align: left;\n}\n\n#khxjlfirnb .gt_center {\n  text-align: center;\n}\n\n#khxjlfirnb .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#khxjlfirnb .gt_font_normal {\n  font-weight: normal;\n}\n\n#khxjlfirnb .gt_font_bold {\n  font-weight: bold;\n}\n\n#khxjlfirnb .gt_font_italic {\n  font-style: italic;\n}\n\n#khxjlfirnb .gt_super {\n  font-size: 65%;\n}\n\n#khxjlfirnb .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nCharacteristic\n      2018, N = 2,0631\n      2019, N = 2,0631\n    KESSLER6sum\n      5.14 (4.00)\n      5.35 (3.97)\n    (Missing)\n      28\n      11\n    FeelHopeless\n      \n      \n    None Of The Time\n      1,012 / 2,033 (50%)\n      961 / 2,044 (47%)\n    A Little Of The Time\n      627 / 2,033 (31%)\n      660 / 2,044 (32%)\n    Some Of The Time\n      325 / 2,033 (16%)\n      348 / 2,044 (17%)\n    Most Of The Time\n      58 / 2,033 (2.9%)\n      67 / 2,044 (3.3%)\n    All Of The Time\n      11 / 2,033 (0.5%)\n      8 / 2,044 (0.4%)\n    (Missing)\n      30\n      19\n    FeelDepressed\n      \n      \n    None Of The Time\n      1,481 / 2,029 (73%)\n      1,399 / 2,051 (68%)\n    A Little Of The Time\n      345 / 2,029 (17%)\n      403 / 2,051 (20%)\n    Some Of The Time\n      156 / 2,029 (7.7%)\n      195 / 2,051 (9.5%)\n    Most Of The Time\n      35 / 2,029 (1.7%)\n      47 / 2,051 (2.3%)\n    All Of The Time\n      12 / 2,029 (0.6%)\n      7 / 2,051 (0.3%)\n    (Missing)\n      34\n      12\n    FeelRestless\n      \n      \n    None Of The Time\n      520 / 2,028 (26%)\n      501 / 2,047 (24%)\n    A Little Of The Time\n      751 / 2,028 (37%)\n      794 / 2,047 (39%)\n    Some Of The Time\n      585 / 2,028 (29%)\n      577 / 2,047 (28%)\n    Most Of The Time\n      143 / 2,028 (7.1%)\n      158 / 2,047 (7.7%)\n    All Of The Time\n      29 / 2,028 (1.4%)\n      17 / 2,047 (0.8%)\n    (Missing)\n      35\n      16\n    EverythingIsEffort\n      \n      \n    None Of The Time\n      523 / 2,031 (26%)\n      470 / 2,048 (23%)\n    A Little Of The Time\n      827 / 2,031 (41%)\n      798 / 2,048 (39%)\n    Some Of The Time\n      490 / 2,031 (24%)\n      572 / 2,048 (28%)\n    Most Of The Time\n      159 / 2,031 (7.8%)\n      179 / 2,048 (8.7%)\n    All Of The Time\n      32 / 2,031 (1.6%)\n      29 / 2,048 (1.4%)\n    (Missing)\n      32\n      15\n    FeelWorthless\n      \n      \n    None Of The Time\n      1,469 / 2,031 (72%)\n      1,434 / 2,049 (70%)\n    A Little Of The Time\n      348 / 2,031 (17%)\n      359 / 2,049 (18%)\n    Some Of The Time\n      147 / 2,031 (7.2%)\n      193 / 2,049 (9.4%)\n    Most Of The Time\n      48 / 2,031 (2.4%)\n      51 / 2,049 (2.5%)\n    All Of The Time\n      19 / 2,031 (0.9%)\n      12 / 2,049 (0.6%)\n    (Missing)\n      32\n      14\n    FeelNervous\n      \n      \n    None Of The Time\n      537 / 2,026 (27%)\n      540 / 2,050 (26%)\n    A Little Of The Time\n      804 / 2,026 (40%)\n      824 / 2,050 (40%)\n    Some Of The Time\n      509 / 2,026 (25%)\n      539 / 2,050 (26%)\n    Most Of The Time\n      148 / 2,026 (7.3%)\n      122 / 2,050 (6.0%)\n    All Of The Time\n      28 / 2,026 (1.4%)\n      25 / 2,050 (1.2%)\n    (Missing)\n      37\n      13\n    \n        \n          1\n          \n           \n          Mean (SD); n / N (%)\n          \n      \n    \n\nNote that you can use the gtsummary package to create in-line referencing. For example: Average Kessler-6 distress in 2018 was 5.14 (4.00) and in 2019 was 5.35 (3.97).\nOrder of your Method section\nThe following is a brief guide to describing your method. We’ll be returning to report writing in future weeks. For now, I just want to put this on the table for you. The advice is just a guide.\nHeading\nInclude\nParticipants\nParticipant or subject characteristics\nSampling procedures\nSample size and power\n\nMaterials\nPrimary and secondary measures\nQuality of measurements\n\nProcedure\nData collection methods\nResearch design (e.g., experimental, correlational, or descriptive)\nData processing and diagnostics (e.g., outlier removal)\nData analysis strategy (e.g., comparison or regression tests)\n\nBelow are the sampling procedures from the New Zealand Attitudes and Values Study, from where the nz teaching dataset was drawn.\nAppendix 1A Sampling Procedure – NZAVS Time 10 (2018; conducted from 18.06.2018-28.09.2019)\nThe Time 10 (2018) NZAVS contained responses from 47,951 participants (18,010 retained from one or more previous wave. The sample retained 2,964 participants from the Time 1 (2009) sample (a retention rate of 45.5%). The sample retained 14,049 participants from Time 9 (2017; a retention rate of 82.3% from the previous year). Participants who provided an email address were first emailed and invited to complete an online version if they preferred. Participants who did not complete the online version (or did not provide an email) were then posted a copy of the questionnaire, with a second postal follow-up two months later. We staggered the time of contact, so that participants who had completed the previous wave were contacted approximately one year after they last completed the questionnaire. We offered a prize draw for participation (five draws each for $1000 grocery vouchers, $5000 total prize pool). All participants were posted a Season’s Greetings card from the NZAVS research team and informed that they had been automatically entered into a bonus seasonal grocery voucher prize draw. Participants were also emailed an eight-page newsletter about the study.\nTo boost sample size and increase sample diversity for subsequent waves, a booster sample was conducted by selecting people from the New Zealand electoral roll. As with previous booster samples, sampling was conducted without replacement (i.e., people included in previous sample frames were identified and removed from the 2018 roll). The sample frame consisted of 325,000 people aged from 18-65 randomly selected from the 2018 New Zealand Electoral Roll, who were currently residing in New Zealand (one can be registered to vote in New Zealand but living overseas). The electoral roll contained ~3,250,000 registered voters. The New Zealand Electoral Roll contains participants’ date of birth (within a one-year window), and we limited our frame to people who 65 or younger, due to our aim of retaining participants longitudinally. We concurrently advertised the survey on Facebook via a $5000 paid promotion of a link to a YouTube video describing the NZAVS and the large booster sample we were conducting. The advertisement targeted men and women aged 18-65+ who lived in New Zealand and ran for 14 days. This paid promotion reached 147,296 people, with 4,721 link clicks (i.e., clicking to watch the video), according to Facebook. The goal of the paid promotion was twofold: (a) to increase name recognition of the NZAVS during the period in which questionnaires were being posted, and (b) to help improve retention by potentially reaching previous participants who happened to see the advertisement. A total of 29,293 participants who were contained in our sample frame completed the questionnaire (response rate = 9.2% when adjusting for the 98.2% accuracy of the 2018 electoral roll). A further 648 participants completed the questionnaire, but were unable to be matched to our sample frame (for example, due to a lack of contact information) or were unsolicited opt-ins. Informal analysis indicates that unsolicited opt-ins were often the partners of existing participants.\nAppendix 1B Sampling Procedure – NZAVS Time 11 (2019; conducted from 29.09.2019-17.10.2020)\nThe Time 11 wave was conducted during COVID-19 pandemic. Procedures thus differed in that there was an increased focus on online deliver using email reminders and extensive Facebook advertising, no Christmas card, and incomplete phoning of non-respondents.\nThe Time 11 (2019) NZAVS contained responses from 42,684 participants (36,522 retained from one or more previous wave. The sample retained 2,506 participants from the Time 1 (2009) sample (a retention rate of 38.4%). The sample retained 34,782 participants from Time 10 (2018; a retention rate of 72.5% from the previous year). Participants who provided an email address were first emailed and invited to complete an online version if they preferred. Participants who did not complete the online version (or did not provide an email) were then posted a copy of the questionnaire, with a second postal follow-up two months later. We staggered the time of contact, so that participants who had completed the previous wave were contacted approximately one year after they last completed the questionnaire. A second reminder email was sent approximately four months following the first email attempt. We offered a prize draw for participation (five draws each for $1000 grocery vouchers, $5000 total prize pool). Participants were also emailed an eight-page newsletter about the study. As in past years, three attempts were made to phone non-respondents using each available cell and landline number. However, due to the university closure during COVID-19 lockdowns, phoning attempts were made for only 54% of the phoning pool (11,687 from a total of 21,636 non-respondents who provided at least one phone number).\nTwo additional forms of recruitment were also introduced during Time 11. The first was a large information box in the questionnaire (taking a full page on the paper version), which asked people: ‘Do you have a partner who would also like to join the NZAVS?’ with additional details for how partners might join the study (see questionnaire for the full text). The second was a Facebook advertisement. The advertisement targeted men and women aged 18-65+ who lived in New Zealand and ran from and 4th April 2020 – 4th July 2020 (overlapping with New Zeeland’s first lockdown period and recovery), and again from 18th August 2020 – 4th September (during the second Auckland lockdown). Given the unprecedented nature of the COVID-19 lockdowns, we thought it important to maximise sampling during these periods. The goal of the Facebook advertisement was threefold: (a) to increase name recognition of the NZAVS and remind people to complete the paper/online version already posted/emailed to them, (b) to help improve retention by potentially reaching previous lost participants who happened to see the advertisement, and (c) to recruit new participants (and also the partners of existing participants) while people were at home with some possibly having more free time during lockdown. This last goal was indirect and not explicitly stated it in the advertisement.\nThe Facebook advertisement read as follows: “Participate in the New Zealand Attitudes and Values Study. Complete the 2020 Questionnaire online” with the body of text: “If you are part of the NZAVS, but have not heard from us in the last year, then please consider completing the 2020 questionnaire online. The study is more important than ever as we aim to understand the impact of COVID-19 on mental health, wellbeing and resilience in our communities. We wish you all the best at this time and hope you keep well and stay safe.” This paid promotion reached 883,969 people, with 37,850 link clicks (i.e., clicking the link for the Qualtrics survey) according to Facebook. A total of 6106 people continued complete the questionnaire and provide full contact details, and were thus included in the dataset (4734 were new participants opting in to the study, and 1372 were previously ‘lost’ participants).\nAppendix 2 Johannes’s mini-lecture on the papaja package\nLecture\nPapaja R markdown template\nAppendix 3 Style advice about research methods\nAPA style advice here\n\n\n\nKessler, R C, G Andrews, L J Colpe, E Hiripi, D K Mroczek, S L T Normand, E E Walters, and A M Zaslavsky. 2002. “Short Screening Scales to Monitor Population Prevalences and Trends in Non-Specific Psychological Distress.” Psychol. Med. 32 (6): 959–76.\n\n\nKessler, Ronald C, Jennifer Greif Green, Michael J Gruber, Nancy A Sampson, Evelyn Bromet, Marius Cuitan, Toshi A Furukawa, et al. 2010. “Screening for Serious Mental Illness in the General Population with the K6 Screening Scale: Results from the WHO World Mental Health (WMH) Survey Initiative.” Int. J. Methods Psychiatr. Res. 19 Suppl 1 (June): 4–22.\n\n\nProchaska, Judith J, Hai-Yen Sung, Wendy Max, Yanling Shi, and Michael Ong. 2012. “Validity Study of the K6 Scale as a Measure of Moderate Mental Distress Based on Mental Health Treatment Need and Utilization.” Int. J. Methods Psychiatr. Res. 21 (2): 88–97.\n\n\nNotice, the intercept here is zero. This because we centered the new indicator at zero, and we wrote a model that is estimating the population average for this outcome (an intercept-only model). Don’t worry if you don’t know what an intercept is, we’ll get to regression in a few weeks.↩︎\n",
    "preview": "posts/4_1/op.png",
    "last_modified": "2021-04-26T21:20:40+12:00",
    "input_file": {},
    "preview_width": 10241,
    "preview_height": 8450
  },
  {
    "path": "posts/3_1/",
    "title": "Visualisation",
    "description": {},
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      }
    ],
    "date": "2021-03-09",
    "categories": [],
    "contents": "\n\nContents\nData visualisation with ggplot2\nIntroduction\nCreating a graph\nUsing ggplot 2 to highlight elements of interest.\nFacets\nUnderstanding your data through graphs\nTransforming data\nRevisiting logical operators\nCommand filter: keeps rows matching criteria\nTask\nCommand select: picks columns by column name\nCommand arrange reorders rows\nCommand mutate add new variable name\nCommand summarise reduce variables to values\nMultiple pipe operators\nOther functions\n\n\n\nData visualisation with ggplot2\n\n\n\nIntroduction\nIn this lecture we’ll first introduce you to the ggplot2 package, and vocabulary, for creating graphs in R. We’ll mostly follow the approach described in the book “R for data science,” which can be found here.\nWe’ll then turn to data-wrangling using the dplyr package.\nBoth ggplot2 and dplyr can be found in library(tidyverse)\nCreating a graph\nStep 1, load tidyverse:\n\n\nlibrary(\"tidyverse\")\n\n\n\nStep 2, Make sure your dataset is loaded. We’ll start with the mpg dataset\n\n\n#inspect the mpg dataset\nhead(mpg)\n\n\n# A tibble: 6 x 11\n  manufacturer model displ  year   cyl trans   drv     cty   hwy fl   \n  <chr>        <chr> <dbl> <int> <int> <chr>   <chr> <int> <int> <chr>\n1 audi         a4      1.8  1999     4 auto(l… f        18    29 p    \n2 audi         a4      1.8  1999     4 manual… f        21    29 p    \n3 audi         a4      2    2008     4 manual… f        20    31 p    \n4 audi         a4      2    2008     4 auto(a… f        21    30 p    \n5 audi         a4      2.8  1999     6 auto(l… f        16    26 p    \n6 audi         a4      2.8  1999     6 manual… f        18    26 p    \n# … with 1 more variable: class <chr>\n\nStep 3. Inspect the\"Negative relationship between highway fuel efficiency and a cars engine size (which is given by the variable displ).\n\n\n# Create graph\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  labs(title = \"Negative relationship between engine displacement and fuel efficiency.\")\n\n\n\n\nA basic problem with this graph is that we don’t know what it is representing. To avoid this problem, it is useful to get into the habit of adding titles to your graphs, and also of using informative axis labels. We do this by adding additional layers.\n\n\n# Create graph and add title\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  labs(title = \"Negative relationship between engine displacement and fuel efficiency.\") + \n  xlab(\"Engine displacement in (units)\") + \n  ylab(\"Highway miles per liter\")\n\n\n\n\nLet’s walk through the logic of the ggplot2 “grammar”:\nFirst we call the data\n\n\n# here we are calling up the data\nggplot(data = mpg)\n\n\n\nNext, we add a layer of points, by calling the relevant columns and rows of this dataset\n\n\n# Here, we add a layer of points, by calling the relevant columns and rows of this dataset\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy))\n\n\n\n\nThen we add the title\n\n\n# Create graph and add title\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  labs(title =  \"Negative relationship between engine displacement and fuel efficiency.\")\n\n\n\n\nThen we add the labels\n\n\n# Create graph and add title\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  labs(title =\"Negative relationship between engine displacement and fuel efficiency.\")   + \n  xlab(\"Engine displacement in (units)\") + \n  ylab(\"Highway miles per liter\") \n\n\n\n\nWe can change the axis starting positions:\n\n\n# Create graph and add title\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  labs(title =\"Negative relationship between engine displacement and fuel efficiency.\")   + \n  xlab(\"Engine displacement in (units)\") + \n  ylab(\"Highway miles per liter\") + expand_limits(x = 0, y = 0)\n\n\n\n\nThe generic method for adding layers is as follows:\n\nggplot(data = <DATA>) + \n  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))\n\nUsing ggplot 2 to highlight elements of interest.\nHere we can use the “color =” option.1\n\n\n# Which cases interest you in this graph?\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, color = class)) \n\n\n\n\nHere’s a shape command\n\n\n# Which cases interest you in this graph?\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, shape = class)) \n\n\n\n\nHere’s a size command\n\n\n# Which cases interest you in this graph?\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, size = cty)) \n\n\n\n\nHere’s the fill command\n\n\n# Which cases interest you in this graph?\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, fill = cty)) \n\n\n\n\nHere’s the alpha command\n\n\n# Which cases interest you in this graph?\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, alpha  = .1)) \n\n\n\n\nHere’s the alpha command combined with the fill command\n\n\n# Which cases interest you in this graph?\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, alpha = cty, size = cty)) \n\n\n\n\nFacets\nWe can create multiple graphs using facets\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, color = class)) + \n   facet_wrap(~ class, nrow = 2)\n\n\n\n\nWe use facet_grid for graphing the Negative relationship between two variables.\nNote the difference betwen these two graphs:\nHere the focus is on the negative relationship between class and the x variable, displacement\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, color = class)) +\n  facet_grid(class ~ .)  + theme(legend.position = \"none\") \n\n\n\n\nHere the focus is on the relationship betwen class and the y variable, highway milage.\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, color = class)) +\n  facet_grid(. ~ class) + theme(legend.position = \"none\") \n\n\n\n\nWe can focus on Negative relationship between class and the x and y variables simultaneously. Here we add the ’year` indicator and we do not see much of an improvement in highway milage for the different classes, adjusting for displacement:\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, color = class)) +\n  facet_grid(class ~ year) + theme(legend.position = \"bottom\") +\n  labs(title =\"Negative relationship between engine displacement and fuel efficiency by class.\") + \n  xlab(\"Engine displacement in (units)\") + \n  ylab(\"Highway miles per liter\") \n\n\n\n\nUnderstanding your data through graphs\nWe can create a graph of relationships:\n\n\n# set better theme\ntheme_set(theme_classic())\nggplot(data = mpg) +\n  geom_smooth(mapping = aes(x = displ, y = hwy)) + \n  labs(title =\"Negative relationship between engine displacement and fuel efficiency.\") +\n  xlab(\"Engine displacement in (units)\") +\n  ylab(\"Highway miles per liter\") \n\n\n\n\nAdd points as a layer\n\n\nggplot(data = mpg) +\n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  geom_smooth(mapping = aes(x = displ, y = hwy)) +\n  theme(legend.position = \"bottom\") +\n  labs(title =\"Negative relationship between engine displacement and fuel efficiency.\") +\n  xlab(\"Engine displacement in (units)\") +\n  ylab(\"Highway miles per liter\") \n\n\n\n\nWe can write this more compactly, by including the mapping with the data layer\n\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth()\n\n\n\n\nThen we can include mappings for specific layers\n\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(color = class)) + \n  geom_smooth()\n\n\n\n\nWe can add a grouping factor e.g. for “drv”, thus creating multiple lines\n\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, group = drv)) + \n  geom_point(aes(color = class)) + \n  geom_smooth()\n\n\n\n\nWe can replace the smooths with linear models\n\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, linetype = drv)) + \n  geom_point(aes(color = class)) + \n  geom_smooth(method = \"lm\")\n\n\n\n\nTransforming data\nFirst we’ll get the flights data\n\n\nlibrary(nycflights13)\nhead(flights)\n\n\n# A tibble: 6 x 19\n   year month   day dep_time sched_dep_time dep_delay arr_time\n  <int> <int> <int>    <int>          <int>     <dbl>    <int>\n1  2013     1     1      517            515         2      830\n2  2013     1     1      533            529         4      850\n3  2013     1     1      542            540         2      923\n4  2013     1     1      544            545        -1     1004\n5  2013     1     1      554            600        -6      812\n6  2013     1     1      554            558        -4      740\n# … with 12 more variables: sched_arr_time <int>, arr_delay <dbl>,\n#   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>\n\nNext we’ll create some data frames to help us illustrate points\n\n\ndf <- data.frame(\ncolour = c(\"blue\", \"black\", \"blue\", \"blue\", \"black\"), value = 1:5)\nhead(df)\n\n\n  colour value\n1   blue     1\n2  black     2\n3   blue     3\n4   blue     4\n5  black     5\n\nRevisiting logical operators\nRecall our logical operators. These will be essential for data wrangling\n\n\nknitr::include_graphics(\"logic.png\")\n\n\n\n\nCommand filter: keeps rows matching criteria\nKeep only blue rows:\n\n\ndf%>%\nfilter(colour == \"blue\")\n\n\n  colour value\n1   blue     1\n2   blue     3\n3   blue     4\n\nKeep only values 1 and 4\n\n\ndf%>%\n  filter (value %in% c(1,4))\n\n\n  colour value\n1   blue     1\n2   blue     4\n\nKeep values 1 through 4\n\n\ndf %>%\n  filter (value %in% c(1:4))\n\n\n  colour value\n1   blue     1\n2  black     2\n3   blue     3\n4   blue     4\n\nAnother way to do the same\n\n\ndf %>%\n  filter (value != 5)\n\n\n  colour value\n1   blue     1\n2  black     2\n3   blue     3\n4   blue     4\n\nTask\nHow can we find all flights that left in January?\n\n\nhead(flights)\n\n\n# A tibble: 6 x 19\n   year month   day dep_time sched_dep_time dep_delay arr_time\n  <int> <int> <int>    <int>          <int>     <dbl>    <int>\n1  2013     1     1      517            515         2      830\n2  2013     1     1      533            529         4      850\n3  2013     1     1      542            540         2      923\n4  2013     1     1      544            545        -1     1004\n5  2013     1     1      554            600        -6      812\n6  2013     1     1      554            558        -4      740\n# … with 12 more variables: sched_arr_time <int>, arr_delay <dbl>,\n#   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>\n\n\n\nflights%>%\n  dplyr::filter(month ==1)\n\n\n# A tibble: 27,004 x 19\n    year month   day dep_time sched_dep_time dep_delay arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>\n 1  2013     1     1      517            515         2      830\n 2  2013     1     1      533            529         4      850\n 3  2013     1     1      542            540         2      923\n 4  2013     1     1      544            545        -1     1004\n 5  2013     1     1      554            600        -6      812\n 6  2013     1     1      554            558        -4      740\n 7  2013     1     1      555            600        -5      913\n 8  2013     1     1      557            600        -3      709\n 9  2013     1     1      557            600        -3      838\n10  2013     1     1      558            600        -2      753\n# … with 26,994 more rows, and 12 more variables:\n#   sched_arr_time <int>, arr_delay <dbl>, carrier <chr>,\n#   flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n#   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>\n\nFlights delayed by more than 15 mintutes that arrived on time\n\n\nflights%>%\n  dplyr::filter (dep_delay >15 & arr_delay <=0)\n\n\n# A tibble: 4,314 x 19\n    year month   day dep_time sched_dep_time dep_delay arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>\n 1  2013     1     1     1025            951        34     1258\n 2  2013     1     1     1033           1017        16     1130\n 3  2013     1     1     2052           2029        23     2349\n 4  2013     1     1     2107           2040        27     2354\n 5  2013     1     2      727            645        42     1024\n 6  2013     1     2     1004            945        19     1251\n 7  2013     1     2     1031           1015        16     1135\n 8  2013     1     2     1500           1430        30     1741\n 9  2013     1     2     1737           1720        17     1908\n10  2013     1     2     1831           1815        16     2130\n# … with 4,304 more rows, and 12 more variables:\n#   sched_arr_time <int>, arr_delay <dbl>, carrier <chr>,\n#   flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n#   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>\n\nCommand select: picks columns by column name\nSelect the colour column\n\n\ndf%>%\n  dplyr::select ( colour )\n\n\n  colour\n1   blue\n2  black\n3   blue\n4   blue\n5  black\n\nAnother way?\n\n\ndf%>%\n  dplyr::select ( !value )\n\n\n  colour\n1   blue\n2  black\n3   blue\n4   blue\n5  black\n\nor\n\n\ndf%>%\n  dplyr::select ( -c(value ))\n\n\n  colour\n1   blue\n2  black\n3   blue\n4   blue\n5  black\n\nCommand arrange reorders rows\n\n\ndf %>%\n  arrange(value)\n\n\n  colour value\n1   blue     1\n2  black     2\n3   blue     3\n4   blue     4\n5  black     5\n\n\n\ndf %>%\n  arrange(desc(value))\n\n\n  colour value\n1  black     5\n2   blue     4\n3   blue     3\n4  black     2\n5   blue     1\n\nTask: how would we order flights by departure data and time ?\n\n\nflights %>%\n  arrange(month, day, dep_time)\n\n\n# A tibble: 336,776 x 19\n    year month   day dep_time sched_dep_time dep_delay arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>\n 1  2013     1     1      517            515         2      830\n 2  2013     1     1      533            529         4      850\n 3  2013     1     1      542            540         2      923\n 4  2013     1     1      544            545        -1     1004\n 5  2013     1     1      554            600        -6      812\n 6  2013     1     1      554            558        -4      740\n 7  2013     1     1      555            600        -5      913\n 8  2013     1     1      557            600        -3      709\n 9  2013     1     1      557            600        -3      838\n10  2013     1     1      558            600        -2      753\n# … with 336,766 more rows, and 12 more variables:\n#   sched_arr_time <int>, arr_delay <dbl>, carrier <chr>,\n#   flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n#   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>\n\nTask which flights have the greated difference between departure delay and arrival delay?\n\n\nflights%>%\n  arrange(desc(dep_delay - arr_delay))\n\n\n# A tibble: 336,776 x 19\n    year month   day dep_time sched_dep_time dep_delay arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>\n 1  2013     6    13     1907           1512       235     2134\n 2  2013     2    26     1000            900        60     1513\n 3  2013     2    23     1226            900       206     1746\n 4  2013     5    13     1917           1900        17     2149\n 5  2013     2    27      924            900        24     1448\n 6  2013     7    14     1917           1829        48     2109\n 7  2013     7    17     2004           1930        34     2224\n 8  2013    12    27     1719           1648        31     1956\n 9  2013     5     2     1947           1949        -2     2209\n10  2013    11    13     2024           2015         9     2251\n# … with 336,766 more rows, and 12 more variables:\n#   sched_arr_time <int>, arr_delay <dbl>, carrier <chr>,\n#   flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n#   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>\n\nNot this could be written briefly as this:\n\n\narrange(flights, desc(dep_delay - arr_delay))\n\n\n# A tibble: 336,776 x 19\n    year month   day dep_time sched_dep_time dep_delay arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>\n 1  2013     6    13     1907           1512       235     2134\n 2  2013     2    26     1000            900        60     1513\n 3  2013     2    23     1226            900       206     1746\n 4  2013     5    13     1917           1900        17     2149\n 5  2013     2    27      924            900        24     1448\n 6  2013     7    14     1917           1829        48     2109\n 7  2013     7    17     2004           1930        34     2224\n 8  2013    12    27     1719           1648        31     1956\n 9  2013     5     2     1947           1949        -2     2209\n10  2013    11    13     2024           2015         9     2251\n# … with 336,766 more rows, and 12 more variables:\n#   sched_arr_time <int>, arr_delay <dbl>, carrier <chr>,\n#   flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n#   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>\n\nCommand mutate add new variable name\n\n\ndf %>%\n  mutate(double_value = 2 * value)\n\n\n  colour value double_value\n1   blue     1            2\n2  black     2            4\n3   blue     3            6\n4   blue     4            8\n5  black     5           10\n\nOrder flights by greatest difference between departure delay and arrival delay?\n\n\nflights %>%\n  mutate(diff_dep_arr = dep_delay - arr_delay)%>%\n  select(flight,diff_dep_arr)%>%\n  arrange(desc(diff_dep_arr))\n\n\n# A tibble: 336,776 x 2\n   flight diff_dep_arr\n    <int>        <dbl>\n 1   4377          109\n 2     51           87\n 3     51           80\n 4   1465           79\n 5     51           76\n 6    673           74\n 7   1532           74\n 8   1284           73\n 9    612           73\n10    427           72\n# … with 336,766 more rows\n\nCommand summarise reduce variables to values\nSum all values in the df dataset\n\n\ndf %>%\n  summarise (total = sum(value))\n\n\n  total\n1    15\n\nSummaries the values by colour groups, and give the number of items per colour group\n\n\ndf %>%\n  group_by(colour) %>%\n  summarise(total = sum(value),\n            n = n())\n\n\n# A tibble: 2 x 3\n  colour total     n\n  <chr>  <int> <int>\n1 black      7     2\n2 blue       8     3\n\nUseful summary functions are:\nmin(x)\nmax(x)\nmean(x)\nn\nn_distinct\nsum(x)\nsum(x > 10)\nmean(x > 10)\nsd(x)\nvar(x)\nTask, how many flights flew on Christmas?\n\n\nhead(flights)\n\n\n# A tibble: 6 x 19\n   year month   day dep_time sched_dep_time dep_delay arr_time\n  <int> <int> <int>    <int>          <int>     <dbl>    <int>\n1  2013     1     1      517            515         2      830\n2  2013     1     1      533            529         4      850\n3  2013     1     1      542            540         2      923\n4  2013     1     1      544            545        -1     1004\n5  2013     1     1      554            600        -6      812\n6  2013     1     1      554            558        -4      740\n# … with 12 more variables: sched_arr_time <int>, arr_delay <dbl>,\n#   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>\n\n\n\nflights %>%\n  filter( month == 12, day == 25)%>%\n  summarise (n = n())\n\n\n# A tibble: 1 x 1\n      n\n  <int>\n1   719\n\nCalculate average delay:\n\n\nflights %>%\n  summarise(delay = mean(dep_delay, na.rm = TRUE))\n\n\n# A tibble: 1 x 1\n  delay\n  <dbl>\n1  12.6\n\n\n\nsummarise(flights, delay = mean(dep_delay, na.rm = TRUE))\n\n\n# A tibble: 1 x 1\n  delay\n  <dbl>\n1  12.6\n\nMultiple pipe operators\nHere we:\nGroup flights by destination.\nSummarise to compute distance, average delay, and number of flights.\nRemove Honolulu airport, because it is so far away\n\n\ndelays <- flights %>% \n  group_by(dest) %>% \n  summarise(\n    count = n(),\n    dist = mean(distance, na.rm = TRUE),\n    delay = mean(arr_delay, na.rm = TRUE)\n  ) %>% \n  filter(dest != \"HNL\")\nhead(delays)\n\n\n# A tibble: 6 x 4\n  dest  count  dist delay\n  <chr> <int> <dbl> <dbl>\n1 ABQ     254 1826   4.38\n2 ACK     265  199   4.85\n3 ALB     439  143  14.4 \n4 ANC       8 3370  -2.5 \n5 ATL   17215  757. 11.3 \n6 AUS    2439 1514.  6.02\n\n\n\nflights %>% \n  filter(!is.na(dep_delay), !is.na(arr_delay)) %>% # not cancelled\n   group_by(tailnum) %>% # group by unique aircraft\n  summarise(\n    delay = mean(arr_delay, na.rm = TRUE),\n    n = n()\n  ) %>%\n  ggplot(mapping = aes(x = n, y = delay)) + \n  geom_point(alpha = 1/10)  + \n  labs(title = \"Variation in average delay by tailnumber \") \n\n\n\n\nOther functions\nSuppose you only wanted to keep your mutated variables, in this case you can use transmute\n\n\nnew_flights <-transmute(flights,\n  gain = dep_delay - arr_delay,\n  hours = air_time / 60,\n  gain_per_hour = gain / hours\n)\nhead(new_flights)\n\n\n# A tibble: 6 x 3\n   gain hours gain_per_hour\n  <dbl> <dbl>         <dbl>\n1    -9  3.78         -2.38\n2   -16  3.78         -4.23\n3   -31  2.67        -11.6 \n4    17  3.05          5.57\n5    19  1.93          9.83\n6   -16  2.5          -6.4 \n\nTo learn more, go to https://dplyr.tidyverse.org/\n\nRemoving the axis and labels here just to keep the code compact↩︎\n",
    "preview": "posts/3_1/op.jpg",
    "last_modified": "2021-04-23T15:50:24+12:00",
    "input_file": {}
  },
  {
    "path": "posts/2_1/",
    "title": "Coding basics",
    "description": {},
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      },
      {
        "name": "Johannes Karl",
        "url": "https://johannes-karl.com"
      }
    ],
    "date": "2021-03-02",
    "categories": [],
    "contents": "\n\nContents\nTo do:\nFundamentals of R\nHow to use R as calculator\nInspecting data\ncheck head of dataset sing head\ncheck data types using str\nnames\nview rownames\ntable (and use of $)\nchange column names\n\nBasic data structures\nvectors of numbers ( and use of c and i:x )\nvectors of characters\ndataframes (2 dimensional square arrays of vectors)\nrename columns of a data frame\nmatrix\nlists\n\nClasses in R\nnumeric and integer\nfactors\n\nIndexing in R\ncolumns\nrows\nrows and columns\nselection by negation\n\nBasic data wrangling in R\nuse of $ and [i:x]\n\nIndexing for logical operations\ndefinitions\nevaluation using logical operators\n\nThe basic structure of R commands\nmean\nsd\nsummary\nCoding\nInstalling package\n\nRolling your own code\nCoding etiquette\n\nusing R!\ndata summary\nmodel\nresults\ngraph predicted effects\nWhat is the advantage of this graph?\ntry another model\nAppendix: # symbol is for commenting code\nRounding\n\n\nTo do:\nA good, and free introduction to R for Data Science Read chapters: 2-8 (they are short chapters.)\nFundamentals of R\nA console runs all your code in R\nA source page runs all your code in R.\nA working directory is where R will look for raw data and other material.\nIn R-studio, (for starters) you can can use the file tab to import and save your material.\nSimilarly, in R-studio, (for starters) you can can use install packages by clicking the Install tab in the package pane (generally lower right pane) to install packagees.\nHow to use R as calculator\nWe can use R as a calculator. You can run any mathematical operation you would normally use by entering it into the console:\n\n\n## Addition\nx <- 3 + 2\nx\n\n\n[1] 5\n\n\n## Subtraction\nx <-  3 - 2\nx\n\n\n[1] 1\n\n\n## Multiplication\nx <-  3 * 2\nx\n\n\n[1] 6\n\n\n## Division\nx <-  3 / 2\nx\n\n\n[1] 1.5\n\n\n## Modulus (Remainder from division)\nx <-  3 %% 2\nx\n\n\n[1] 1\n\n\n## Exponentiation\nx = 3 ^ 2\nx\n\n\n[1] 9\n\n\n## Integer Division (Number of times denominator fits in numerator)\nx = 3 %/% 2\nx\n\n\n[1] 1\n\nInspecting data\nIn a moment, we’ll teach you how to import data into R. For now, let’s work with a dataset that is already present in your R environment, the iris dataset.\nHere are some useful commands for inspecting data\ncheck head of dataset sing head\n\n\n# the top rows and columns of the dataset\nhead(iris)\n\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\ncheck data types using str\n\n\nstr(iris)\n\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nnames\n\n\n#names of the columns\nnames(iris)\n\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\"\n[4] \"Petal.Width\"  \"Species\"     \n\nview rownames\n\n\n# view rownames\nrownames(iris)\n\n\n  [1] \"1\"   \"2\"   \"3\"   \"4\"   \"5\"   \"6\"   \"7\"   \"8\"   \"9\"  \n [10] \"10\"  \"11\"  \"12\"  \"13\"  \"14\"  \"15\"  \"16\"  \"17\"  \"18\" \n [19] \"19\"  \"20\"  \"21\"  \"22\"  \"23\"  \"24\"  \"25\"  \"26\"  \"27\" \n [28] \"28\"  \"29\"  \"30\"  \"31\"  \"32\"  \"33\"  \"34\"  \"35\"  \"36\" \n [37] \"37\"  \"38\"  \"39\"  \"40\"  \"41\"  \"42\"  \"43\"  \"44\"  \"45\" \n [46] \"46\"  \"47\"  \"48\"  \"49\"  \"50\"  \"51\"  \"52\"  \"53\"  \"54\" \n [55] \"55\"  \"56\"  \"57\"  \"58\"  \"59\"  \"60\"  \"61\"  \"62\"  \"63\" \n [64] \"64\"  \"65\"  \"66\"  \"67\"  \"68\"  \"69\"  \"70\"  \"71\"  \"72\" \n [73] \"73\"  \"74\"  \"75\"  \"76\"  \"77\"  \"78\"  \"79\"  \"80\"  \"81\" \n [82] \"82\"  \"83\"  \"84\"  \"85\"  \"86\"  \"87\"  \"88\"  \"89\"  \"90\" \n [91] \"91\"  \"92\"  \"93\"  \"94\"  \"95\"  \"96\"  \"97\"  \"98\"  \"99\" \n[100] \"100\" \"101\" \"102\" \"103\" \"104\" \"105\" \"106\" \"107\" \"108\"\n[109] \"109\" \"110\" \"111\" \"112\" \"113\" \"114\" \"115\" \"116\" \"117\"\n[118] \"118\" \"119\" \"120\" \"121\" \"122\" \"123\" \"124\" \"125\" \"126\"\n[127] \"127\" \"128\" \"129\" \"130\" \"131\" \"132\" \"133\" \"134\" \"135\"\n[136] \"136\" \"137\" \"138\" \"139\" \"140\" \"141\" \"142\" \"143\" \"144\"\n[145] \"145\" \"146\" \"147\" \"148\" \"149\" \"150\"\n\nhead(iris)\n\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\ntable (and use of $)\n\n\n# create a table\ntable(iris$Species)\n\n\n\n    setosa versicolor  virginica \n        50         50         50 \n\nchange column names\n\n\n# change column names\n# create new dataset for \nirisdat2 <- iris\n# chage names of columns\nnames(irisdat2)[] <- c(\"s_l\", \"s_w\", \"p_l\", \"p_w\", \"sp\")\n#inspect\nhead(irisdat2)\n\n\n  s_l s_w p_l p_w     sp\n1 5.1 3.5 1.4 0.2 setosa\n2 4.9 3.0 1.4 0.2 setosa\n3 4.7 3.2 1.3 0.2 setosa\n4 4.6 3.1 1.5 0.2 setosa\n5 5.0 3.6 1.4 0.2 setosa\n6 5.4 3.9 1.7 0.4 setosa\n\nBasic data structures\nvectors of numbers ( and use of c and i:x )\n\n\ngo_vector <- c(1:5)\ngo_vector\n\n\n[1] 1 2 3 4 5\n\nvectors of characters\n\n\ngo_vector2 <- c(\"hello\", \"world\")\ngo_vector2\n\n\n[1] \"hello\" \"world\"\n\n\n\nas.vector(irisdat2$s_l)\n\n\n  [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8\n [14] 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0\n [27] 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4\n [40] 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4\n [53] 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6\n [66] 6.7 5.6 5.8 6.2 5.6 5.9 6.1 6.3 6.1 6.4 6.6 6.8 6.7\n [79] 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 5.5\n [92] 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3\n[105] 6.5 7.6 4.9 7.3 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5\n[118] 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 6.2 6.1 6.4 7.2\n[131] 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8\n[144] 6.8 6.7 6.7 6.3 6.5 6.2 5.9\n\ndataframes (2 dimensional square arrays of vectors)\n2 x dimensional “square” array with equal column and row lengths. Can contain data with multiple formats characters, facotors, integers, etc.\n\n\nyuk <- data.frame(c(\"the\", \"enumeration\", \"of\", \"the\", \"constitution\"), 6:10)\nyuk\n\n\n  c..the....enumeration....of....the....constitution..\n1                                                  the\n2                                          enumeration\n3                                                   of\n4                                                  the\n5                                         constitution\n  X6.10\n1     6\n2     7\n3     8\n4     9\n5    10\n\nrename columns of a data frame\n\n\nnames(yuk)[] <- c(\"short\", \"best\")\nyuk\n\n\n         short best\n1          the    6\n2  enumeration    7\n3           of    8\n4          the    9\n5 constitution   10\n\nmatrix\nSame as a dataframe but can only contain one format (e.g. numbers or characters)\n\n\nyok <- as.matrix(yuk)\nyok\n\n\n     short          best\n[1,] \"the\"          \" 6\"\n[2,] \"enumeration\"  \" 7\"\n[3,] \"of\"           \" 8\"\n[4,] \"the\"          \" 9\"\n[5,] \"constitution\" \"10\"\n\nlists\nArrays with constraints on “squareness” or data types.\n\n\nlok <- list(yok, yuk)\nlok\n\n\n[[1]]\n     short          best\n[1,] \"the\"          \" 6\"\n[2,] \"enumeration\"  \" 7\"\n[3,] \"of\"           \" 8\"\n[4,] \"the\"          \" 9\"\n[5,] \"constitution\" \"10\"\n\n[[2]]\n         short best\n1          the    6\n2  enumeration    7\n3           of    8\n4          the    9\n5 constitution   10\n\nClasses in R\nnumeric and integer\nnumeric means number\n\n\nis.numeric(4.2)\n\n\n[1] TRUE\n\ninteger means a number that is not a fraction\n\n\nis.integer(4.2)\n\n\n[1] FALSE\n\nNote the default here:\n\n\nis.integer(4)\n\n\n[1] FALSE\n\n\n\nis.integer(as.integer(4))\n\n\n[1] TRUE\n\nWe’ll need to ensure that certain numbers are integers later on, when we are estimating poisson models and/or doing bayesian data analysis.\ncharacters\nCharacters are strings:\n\n\n# this is a character\nis.character(\"chapeau\")\n\n\n[1] TRUE\n\n# this is not\nis.character(4)\n\n\n[1] FALSE\n\nfactors\nA factor is a category. It can be ordered (e.g. an ordinal scale) or unordered (say a participant in a study, or a wave in a longitidunal study)\n\n\nstr(iris)\n\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nIt’s really important to check that ordered categories are really ordered categories in your dataset.\nThere was is a famous retraction recently where a group found that religion was associated with immorality, however the countries in the the study had been coded as numbers, not as factors. The study’s effect entirely disappeared once this error was corrected!\nIndexing in R\ncolumns\n\n\n# select second column of \"yuk\"\nyuk[, 2]\n\n\n[1]  6  7  8  9 10\n\nrows\n\n\n# select second row of yuk\nyuk[2, ]\n\n\n        short best\n2 enumeration    7\n\nrows and columns\n\n\n#select first row and first column of yuk\nyuk[1, 2]\n\n\n[1] 6\n\nselection by negation\n\n\n# negate the first column of yuk\nyuk[, -1]\n\n\n[1]  6  7  8  9 10\n\n\n\n# negate the second column of yuk\nyuk[,-2]\n\n\n[1] \"the\"          \"enumeration\"  \"of\"          \n[4] \"the\"          \"constitution\"\n\nBasic data wrangling in R\nc\n\n\n# select only the first and second cols of iris\niris_short2 <- iris[ ,c( 1, 2 ) ]\nhead(iris_short2)\n\n\n  Sepal.Length Sepal.Width\n1          5.1         3.5\n2          4.9         3.0\n3          4.7         3.2\n4          4.6         3.1\n5          5.0         3.6\n6          5.4         3.9\n\n-c\n\n\n# select all columns but the first and second of iris\niris_short <- iris[ ,-c( 1, 2 ) ]\nhead(iris_short)\n\n\n  Petal.Length Petal.Width Species\n1          1.4         0.2  setosa\n2          1.4         0.2  setosa\n3          1.3         0.2  setosa\n4          1.5         0.2  setosa\n5          1.4         0.2  setosa\n6          1.7         0.4  setosa\n\ncbind\n\n\n# for use with dataframes and matrices -- note that srings a are c\nyokyuk<-cbind(yok,yuk)\nyokyuk\n\n\n         short best        short best\n1          the    6          the    6\n2  enumeration    7  enumeration    7\n3           of    8           of    8\n4          the    9          the    9\n5 constitution   10 constitution   10\n\nstr(yokyuk)\n\n\n'data.frame':   5 obs. of  4 variables:\n $ short: chr  \"the\" \"enumeration\" \"of\" \"the\" ...\n $ best : chr  \" 6\" \" 7\" \" 8\" \" 9\" ...\n $ short: chr  \"the\" \"enumeration\" \"of\" \"the\" ...\n $ best : int  6 7 8 9 10\n\nrbind\n\n\nrbind(yuk[,],yok[2:3])\n\n\n         short best\n1          the    6\n2  enumeration    7\n3           of    8\n4          the    9\n5 constitution   10\n6  enumeration   of\n\nuse of $ and []\n\n\n#select the fifth row of the column\niris_short$Petal.Width[5]\n\n\n[1] 0.2\n\nuse of $ and [i:x]\n\n\n#select the 5th-25th row of the column\niris_short$Petal.Width[5:25]\n\n\n [1] 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3\n[15] 0.3 0.3 0.2 0.4 0.2 0.5 0.2\n\nIndexing for logical operations\ndefinitions\n== means “equals to”\n!= means “not equals to”\n> means “greater than”\n< means “less than”\n>=means “greater than or equal”\n<= means “less than or equal”\n! means “not”\n& means “and”\n| means “or”!\nis.na means “is missing” (missing values are coded in R as NA)\n> -9999 == 666 > TRUE !!! :)\nevaluation using logical operators\ncreate dataframe\n\n\n# create data frame\ndf<-data.frame( x = c(1:10),y = c(11:20) )\n\n\n\nevaluate cases\n\n\n#evaluate cases in y that greater  than 15\ndf[,\"y\"] > 15\n\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n[10]  TRUE\n\nsum instances\n\n\n# count these cases\nsum(df[,\"y\"] > 15)\n\n\n[1] 5\n\nsum instances with a different operator\n\n\n# count cases greater than or equal to 15\nsum(df[,\"y\"] >= 15)\n\n\n[1] 6\n\nanother methods\n\n\n# another approach\nsum(df$y >= 15)\n\n\n[1] 6\n\nusing the or function\n\n\n# combine operators\nsum(df$y >= 15 | df$y <=11)\n\n\n[1] 7\n\ngo meta\n\n\n# go \"meta\"\nsum(df$y >= 15 | df$y <= 11) == sum(df$x >=5 | df$x <=1 )\n\n\n[1] TRUE\n\ngo meta-meta!\n\n\n# go meta-meta\nsum(sum(df$y >= 15 | df$y <= 11) == sum(df$x >=5 | df$x <=1 ))\n\n\n[1] 1\n\nuse operators to modify data\n\n\n# using assignment to modify data\ndf$x[df$x >=5 ] <- NA\ndf\n\n\n    x  y\n1   1 11\n2   2 12\n3   3 13\n4   4 14\n5  NA 15\n6  NA 16\n7  NA 17\n8  NA 18\n9  NA 19\n10 NA 20\n\nusing is.na and !is.na\n\n\nsum(is.na(df$x))\n\n\n[1] 6\n\n\n\nsum(!is.na(df$x))\n\n\n[1] 4\n\n\n\nsum(is.na(df$x)) + sum(!is.na(df$x)) \n\n\n[1] 10\n\nThe basic structure of R commands\nThe four main elements of every R code are:\nobjects,\nfunctions,\narguments\noperators.\nFigure 1 provides a simple example, that produces a new object which contains the mean of variable x.\n\n\n\nFigure 1: The Basic Syntax of R\n\n\n\nmean\nThe function mean generates the arithmetic mean of an input object:\n\n\n# a function to assess the mean of a Sepal.Length\nmean(iris$Sepal.Length)\n\n\n[1] 5.843333\n\nsd\nThe function sd gives us the standard deviation:\n\n\n# standard deviation of Sepal.Length\nsd(iris$Sepal.Length)\n\n\n[1] 0.8280661\n\nsummary\n\n\n# summary of the \"Sepal Length\" column\nsummary(iris$Sepal.Length)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  4.300   5.100   5.800   5.843   6.400   7.900 \n\n\n\n# summary of the Iris data set\nsummary(iris)\n\n\n  Sepal.Length    Sepal.Width     Petal.Length  \n Min.   :4.300   Min.   :2.000   Min.   :1.000  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600  \n Median :5.800   Median :3.000   Median :4.350  \n Mean   :5.843   Mean   :3.057   Mean   :3.758  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100  \n Max.   :7.900   Max.   :4.400   Max.   :6.900  \n  Petal.Width          Species  \n Min.   :0.100   setosa    :50  \n 1st Qu.:0.300   versicolor:50  \n Median :1.300   virginica :50  \n Mean   :1.199                  \n 3rd Qu.:1.800                  \n Max.   :2.500                  \n\nCoding\nThe object needs to be specified inside of the function brackets as the x argument, in this case we define x = df .\nLast, we assign the result of this function for later us via the <- operator to an object which we decided to call object.\nIn other words, we create a new object that can be further manipulated and contains information about the mean of a previously created object “x”. This structure represents the foundation of most operations in R.\nInstead calling the mean function as above one could manually add all values of x dividing it by the number of x values.\nNevertheless, this would be very cumbersome.\nFor this reason, functions (pre-assembled lines of code) exist to reduce the amount of coding necessary.\nThese functions can be bundled into packages. R’s capacity for creating packages is main appeal of R as a statistical tool because community developed functions are available from a central repository called CRAN in the form of packages.\nThese packages can be installed in R with the command install.packages(“package name”).\nIt is important that you only need to install a package once on your machine, expect if you want to upgrade the package. Generally speaking you regularly want to upgrade your packages, but keep a permanent note in your code which version of a package you used when it was initially written.\nInstalling package\ninstall these packages (we’ll be using them later)\n\n\ninstall.packages(\"devtools\") # installing packages\n\n\n\n\n\ninstall.packages(\"remotes\") # installing packages\n\n\n\n\n\ninstall.packages(\"tidyverse\") ## data wrangling and visualisation\n\n\n\n\n\ninstall.packages(\"lme4\") # multilevel modelling\n\n\n\n\n\ninstall.packages(\"patchwork\") # arranging multiple graphs\n\n\n\n\n\nlibrary(devtools)\ndevtools::install_github(\"strengejacke/sjPlot\") # plots and tables\n\n\n\n\n\ninstall.packages(\"papaja\")  # writing APA documents\n\n\n\n\n\ninstall.packages(\"table1\") # summary tables\n\n\n\nextra credit\n\n\ndevtools::install_github(\"easystats/easystats\")\n\n\n\n\n\ndevtools::install_github(\"strengejacke/ggeffects\")\n\n\n\nsuper extra credit\n\n\nif (!requireNamespace(\"remotes\")) {\n  install.packages(\"remotes\")\n}\nremotes::install_github(\"paul-buerkner/brms\")\n\n\n\n\n\ndevtools::install_github(\"stan-dev/cmdstanr\")\n\n\n\nRolling your own code\nLet’s use R to write a function. Recall that a factorial for a number \\(n\\) is the product of all positive inters less than or equal to \\(n\\). Thus the factorial for 5 = \\[1 \\times 2 \\times 3 \\times 4 \\times 5\\]\nIn R we can write a function:\n\n\n# create a function to perform the factorial operation \ngo_factorial <- function(x) {\n  y <- 1\n  for (i in 1:x) {\n    y <- y * ((1:x)[i])\n  }\n  print(y)\n}\n\n\n\nLet’s try it out\n\n\n# test of the `go_factorial` function\ngo_factorial(5)\n\n\n[1] 120\n\nLet’s see if this is the number that R’s factorial function produces:\n\n\n# R's native factorial function\nfactorial(5)\n\n\n[1] 120\n\nWe can use R’s == relational operator to evaluate whether the two functions are the same\n\n\n# are the two functions equivalent for factorial five\ngo_factorial(5) == factorial(5)\n\n\n[1] 120\n[1] TRUE\n\nFor more information about relational operators type the following into your console:\n\n\n?`==`\n\n\n\nWe can make more complicated functions:\n\n\n# function for factorial that throws warnings when the data that are entered are not appropriate. \ngo_bayes_factorial <- function (x) {\n  # check is the number is negative, positive or zero\n  if (x  < 0) {\n    print(\"not even Ashley Bloomfield could make a factorial for a negative number\")\n  } else if (x == 0) {\n    print(\"the factorial of zero is defined as 1\")\n  } else {\n    for (i in 1:x)\n      y <- 1\n    for (i in 1:x) {\n      y <- y * ((1:x)[i])\n    }\n    print(y)\n  }\n}\n\n\n\nWe’ll come back to functions later. It’s useful to look at an example of a function so that you can see that R is much more than a calcultor. It is a tool to empower you for doing data anlysis in new and creative ways.\nCoding etiquette\nKeep your code legible and annotate\nWhy is this bad code?\n\n\ndf1<-data.frame(a=rnorm(10,1,1),b=rnorm(10,4,8),c=rnorm(10,8,1),d=rnorm(10,7,2))\n\n\n\nWhy is this better code?\n\n\n\n# Create a data frame with four columns of randomly generated numbers specifying different means and standard deviations \ndf1 <- data.frame(\n  a = rnorm( 10, mean = 1, sd = 1 ),\n  b = rnorm( 10, mean = 4, sd = 8 ),\n  c = rnorm( 10, mean = 8, sd = 1 ),\n  d = rnorm( 10, mean = 7, sd = 2 )\n)\n\n\n\nusing R!\ndata summary\n\n\n# basic summary\nsummary(iris)\n\n\n  Sepal.Length    Sepal.Width     Petal.Length  \n Min.   :4.300   Min.   :2.000   Min.   :1.000  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600  \n Median :5.800   Median :3.000   Median :4.350  \n Mean   :5.843   Mean   :3.057   Mean   :3.758  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100  \n Max.   :7.900   Max.   :4.400   Max.   :6.900  \n  Petal.Width          Species  \n Min.   :0.100   setosa    :50  \n 1st Qu.:0.300   versicolor:50  \n Median :1.300   virginica :50  \n Mean   :1.199                  \n 3rd Qu.:1.800                  \n Max.   :2.500                  \n\n\n\ntable1::table1(~ Sepal.Length   + Sepal.Width   + Petal.Length  + Petal.Width |Species, data = iris  )\n\n\n\nsetosa(N=50)\nversicolor(N=50)\nvirginica(N=50)\nOverall(N=150)\nSepal.Length\n\n\n\n\nMean (SD)\n5.01 (0.352)\n5.94 (0.516)\n6.59 (0.636)\n5.84 (0.828)\nMedian [Min, Max]\n5.00 [4.30, 5.80]\n5.90 [4.90, 7.00]\n6.50 [4.90, 7.90]\n5.80 [4.30, 7.90]\nSepal.Width\n\n\n\n\nMean (SD)\n3.43 (0.379)\n2.77 (0.314)\n2.97 (0.322)\n3.06 (0.436)\nMedian [Min, Max]\n3.40 [2.30, 4.40]\n2.80 [2.00, 3.40]\n3.00 [2.20, 3.80]\n3.00 [2.00, 4.40]\nPetal.Length\n\n\n\n\nMean (SD)\n1.46 (0.174)\n4.26 (0.470)\n5.55 (0.552)\n3.76 (1.77)\nMedian [Min, Max]\n1.50 [1.00, 1.90]\n4.35 [3.00, 5.10]\n5.55 [4.50, 6.90]\n4.35 [1.00, 6.90]\nPetal.Width\n\n\n\n\nMean (SD)\n0.246 (0.105)\n1.33 (0.198)\n2.03 (0.275)\n1.20 (0.762)\nMedian [Min, Max]\n0.200 [0.100, 0.600]\n1.30 [1.00, 1.80]\n2.00 [1.40, 2.50]\n1.30 [0.100, 2.50]\n\n\n\n\n# plot relationship (what is happening here? )\nplot( Sepal.Length   ~ Sepal.Width , data = iris )\n\n\n\n\nmodel\n\n\nlibrary(\"tidyverse\")  # plotting\nlibrary(\"ggeffects\")  # plotting\nlibrary(\"ggplot2\")  # plotting\nlibrary(\"patchwork\") # arrange multiple plots\nlibrary(\"sjPlot\")  # tables and plots\n\n# basic model\nm1<- lm(Sepal.Length ~ Sepal.Width, data = iris)\nsummary(m1)\n\n\n\nCall:\nlm(formula = Sepal.Length ~ Sepal.Width, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.5561 -0.6333 -0.1120  0.5579  2.2226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   6.5262     0.4789   13.63   <2e-16 ***\nSepal.Width  -0.2234     0.1551   -1.44    0.152    \n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8251 on 148 degrees of freedom\nMultiple R-squared:  0.01382,   Adjusted R-squared:  0.007159 \nF-statistic: 2.074 on 1 and 148 DF,  p-value: 0.1519\n\nresults\n\n\n# better summary method\nsjPlot::tab_model(m1)\n\n\n\n \n\n\nSepal.Length\n\n\nPredictors\n\n\nEstimates\n\n\nCI\n\n\np\n\n\n(Intercept)\n\n\n6.53\n\n\n5.58 – 7.47\n\n\n<0.001\n\n\nSepal.Width\n\n\n-0.22\n\n\n-0.53 – 0.08\n\n\n0.152\n\n\nObservations\n\n\n150\n\n\nR2 / R2 adjusted\n\n\n0.014 / 0.007\n\n\n\n\n# plot the coefficients\nsjPlot::plot_model(m1)\n\n\n\n\ngraph predicted effects\n\n\n# plot the predicted relationship of Sepal Width on Sepal Length\np1 <- ggeffects::ggpredict(m1, terms = \"Sepal.Width\")\nplot(p1)\n\n\n\n\nWhat is the advantage of this graph?\n\n\npp1 <- plot(p1,\n            add.data = TRUE,\n            dot.alpha = .8,\n            jitter = .2)\npp1\n\n\n\n\ntry another model\n\n\nhead(iris)\n\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\nsummary (m2 <- lm(Petal.Length ~ Petal.Width, data = iris)) \n\n\n\nCall:\nlm(formula = Petal.Length ~ Petal.Width, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.33542 -0.30347 -0.02955  0.25776  1.39453 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.08356    0.07297   14.85   <2e-16 ***\nPetal.Width  2.22994    0.05140   43.39   <2e-16 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4782 on 148 degrees of freedom\nMultiple R-squared:  0.9271,    Adjusted R-squared:  0.9266 \nF-statistic:  1882 on 1 and 148 DF,  p-value: < 2.2e-16\n\n\n\npp2<-plot(\n  p2 <- ggeffects::ggpredict(m2, terms = \"Petal.Width\"),\n  add.data = TRUE,\n  dot.alpha = .8,\n  jitter = .2\n) \npp2\n\n\n\n\n\n\n## arange plots\nlibrary(patchwork)\npp1 / pp2 + plot_annotation(title = \"two plots\", tag_levels = \"i\")\n\n\n\n\nAppendix: # symbol is for commenting code\nIn case you haven’t figured it out yet, the hash symbol # is for commenting:\n\n\nr_comments <- 200 # here I am creating the variable for the number of time Jack says R is great\n\njill_roll <- 199 # here I'm creating a variable for the number of times Jill rolls here eyes\n\noutcome <- log(r_comments) * sqrt(jill_roll) * pi # here I am illustrating some functions in r using the variables I just created\n\noutcome # print outcome\n\n\n[1] 234.8088\n\nRounding\nIt is often useful to round numbers:\n\n\nround(outcome, digits = 2) # illustrate the useful `round` function.\n\n\n[1] 234.81\n\n\n\n\n## to be continued\n```{.r .distill-force-highlighting-css}\n\n\n",
    "preview": "posts/2_1/syntax.png",
    "last_modified": "2021-04-23T15:50:24+12:00",
    "input_file": {},
    "preview_width": 1285,
    "preview_height": 478
  },
  {
    "path": "posts/1_1/",
    "title": "Course basics",
    "description": "Goals: (1) Download Rstudio (2) Get Git (3) Teach you the essentials of Rmarkdown (4) Integrate (1)-(3).",
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      },
      {
        "name": "Johannes Karl",
        "url": "https://johannes-karl.com"
      }
    ],
    "date": "2021-02-23",
    "categories": [],
    "contents": "\n\nContents\nTo do:\nDownload R\nDownload R-Studio desktop\nRead about Rmarkdown\nRecommended reading\nWho is this course for?\nHow will you benefit from this course?\n\nOur approach to teaching and learning\nWhat is R?\nIn a nutshell\nHistory\nPurpose\n\nWhat is R Studio?\nThe IDE\nA quick walk through R Studio\n\nGitHub\nWhat is Git/GitHub?\nInstall Git\nCreate a repository\nNext copy the location\nThen open a new project in Rstudio as a GitHub project\n\nThen open an Rmarkdown document, write and save it\nThen commit your Rmarkdown document by including a message, and “pushing” to GitHub\nNext commit!\nExtra information\n\nRMarkdown\nWhat is Rmarkdown?\nWhy is Rmarkdown useful?\nExtra information\nTips and tricks (JB)\nFinal thought: why quantitative psychology has to change (Why can’t I use SPSS, JK)\n\nFinal thought\nLecture slides\n\nTo do:\nDownload R\nR is freely available for download at: https://www.r-project.org/ Please make sure that you have a current version of R-studio desktop on your machine\n\n\n\nDownload R-Studio desktop\nRstudio desktop is also freely available for download at:\nhttps://rstudio.com/products/rstudio/download/#download\nPlease make sure that you have the current version of R-studio desktop on your machine\n\n\n\nRead about Rmarkdown\nRead Danielle Navarro’s brief account of Rmarkdown here\nRecommended reading\nThis is a thorough rmarkdown workshop. You might quickly feel lost. Don’t worry about. We only expect you to acquire the basics this week.\nRmarkdown workshop\n\n\n\n\n\n\n\n\n\nWho is this course for?\nFor those of you who always wanted to learn R but never thought they could, this course is for you.\nHow will you benefit from this course?\nYou’ll learn how to use R, and Github, and we’ll teach you the fundamentals of statistics with a focus thinking not on rules.\nYou’ll learn how to learn – that is, how to obtain the resources you need to address a problem at hand.\nBy the end of the course, you’ll know how to:\nData skills:\nperform your data analysis in R\ndocument your analysis and collaborate in GitHub\ncreate a publication-ready article, with tables and graphs\ncreate a free personal website on github.\nStatistical skills:\nlearn the importance of knowing your question\nlearn how to collect data that bears on your question\nlearn how to explore your data visually\nlearn how to avoid common modelling pitfalls\nlearn how to improve your inference using multi-level models\nOur approach to teaching and learning\n\n\nThis course is designed to provide you with basic understanding, useful tips, and some guide rails for learning. Our main task is to give you the confidence, and the inspiration, for independent learning.\nWhat is R?\nIn a nutshell\nR is a free programming language and software environment for statistical computing (for download links see here: Windows, Mac).\nHistory\nR is the brainchild of Ross Ihaka and [Robert Gentleman](https://en.wikipedia.org/wiki/Robert_Gentleman_(statistician). It was created at the University of Auckland, where Ross Ihaka remains a professor of statistics.\nPurpose\nR was conceived to be a flexible language for data analysis usable by researchers. Since the initial beta release of R in 2000 the language has gained substantial popularity inside and outside of academia (have a look at this blog post for an interesting analysis). New versions of R are released periodically and can be downloaded and installed to replace the older R version.\nWhat is R Studio?\nThe IDE\nThe are many ways for using R on your computer. For the purposes of getting started, we will be using the Integrated Development Environment (IDE): R Studio.\nR Studio provides an interface with a number of user-friendly options, including a separate console and editor that has various help and syntax-auto-complete functions, and various tools for plotting, history, data visualization, debugging and work space management. It is important to remember that R and R Studio are not the same thing.\n\nA quick walk through R Studio\n\n\nGitHub\nWhat is Git/GitHub?\nGithub is a version control system. It is similar to Google docs, though for code. It is useful for collaboration because code easily breaks. It is only rarely possible to simultaneously work in real time on the same code because it will eventually break. Where and how is not easy to assess.\nA second function of GitHub is that it allows us to reconstruct histories of analysis. This is critical for open and reproducible science. This is the main function that we will be examining here.\nA third function, which pertains to single users, is that when writing code you can rewind and recover from your mistakes. This will save you a whole lot of time in the end.\nNote that GitHub has an interface with Rstudio. You will be using GitHub with Rstudio throughout this course.\nInstall Git\nWe suggested installing the educational version because this will allow you to have private repositories.\nIf you haven’t done that, but want to get started you can open a free account and retrospectively add your educational account later.\nPRO TIP Pick a user name that will be OK for professional purposes. If in doubt use your name.\nDirections for installing Git can be found http://github.com\nCreate a repository\nFirst create a repository on GitHub\n\n\n\nNext copy the location\n\n\n\nThen open a new project in Rstudio as a GitHub project\n\n\n\nThen open an Rmarkdown document, write and save it\nFirst, make sure that Rmarkdown is installed:\n\n\n# run this code\nif (!requireNamespace(\"devtools\"))\n  install.packages('devtools')\ndevtools::install_github('rstudio/rmarkdown')\n\n\ntinytex (0.31 -> 0f690c2ae...) [GitHub]\nhighr   (0.8  -> 0.9         ) [CRAN]\n\n  There is a binary version available but the source version\n  is later:\n      binary source needs_compilation\nhighr    0.8    0.9             FALSE\n\n\n  \n   checking for file ‘/private/var/folders/qr/nfnc9ry90c16g3fbwm55lbj00000gq/T/RtmpaSW9p7/remotes22611df7aff7/yihui-tinytex-0f690c2/DESCRIPTION’ ...\n  \n✓  checking for file ‘/private/var/folders/qr/nfnc9ry90c16g3fbwm55lbj00000gq/T/RtmpaSW9p7/remotes22611df7aff7/yihui-tinytex-0f690c2/DESCRIPTION’\n\n  \n─  preparing ‘tinytex’:\n\n  \n   checking DESCRIPTION meta-information ...\n  \n✓  checking DESCRIPTION meta-information\n\n  \n─  checking for LF line-endings in source and make files and shell scripts\n\n  \n─  checking for empty or unneeded directories\n\n  \n─  building ‘tinytex_0.31.3.tar.gz’\n\n  \n   \n\n  \n   checking for file ‘/private/var/folders/qr/nfnc9ry90c16g3fbwm55lbj00000gq/T/RtmpaSW9p7/remotes22615db742ee/rstudio-rmarkdown-eb55b2e/DESCRIPTION’ ...\n  \n✓  checking for file ‘/private/var/folders/qr/nfnc9ry90c16g3fbwm55lbj00000gq/T/RtmpaSW9p7/remotes22615db742ee/rstudio-rmarkdown-eb55b2e/DESCRIPTION’\n\n  \n─  preparing ‘rmarkdown’:\n\n  \n   checking DESCRIPTION meta-information ...\n  \n✓  checking DESCRIPTION meta-information\n\n  \n─  checking for LF line-endings in source and make files and shell scripts\n\n  \n─  checking for empty or unneeded directories\n\n  \n   Removed empty directory ‘rmarkdown/tools’\n\n  \n─  building ‘rmarkdown_2.7.10.tar.gz’\n\n  \n   \n\n\nNext, create a document\n\n\n\nMake sure you save your document\nPress ⌘ + S  is the command for “save”\nThen commit your Rmarkdown document by including a message, and “pushing” to GitHub\nNote that we don’t want want to push .Rproj files to GitHub (this will mess up your collaborations), so I edited my .gitignore file.\nTypically you won’t want to be pushing large html files back and forth to GitHub (that can cause GitHub to freeze).\nYou can edit your gitingore file by adding a * like so:\n/*.html\nsee: https://git-scm.com/docs/gitig\nNext commit!\n\n\n\nVoila!\nExtra information\nJB’s recommendations for using Git and Rstudio\nThis is a very good tutorial on github and Rstudio: link\nVideo link\nA very brief setup video for Mac Users Link\nJK’s recommendations for using Git and Rstuio\nsetup\nRMarkdown\nWhat is Rmarkdown?\nIn the example above we breezed through Rmarkdown without exampling it. What is Rmarkdown?\nRmarkdown is a format for combining data-analysis with ordinary writing using a simple markup language.\nThe Rmarkdown code we used to write the opening paragraph looks like this.\n\ndiv.blue{ background-color:#e6f0ff}\n\n## To do\nRead Danielle Navarro's brief account of \nRmarkdown [here](https://slides.djnavarro.net/starting-rmarkdown/#8)\n\nThe:\n\n##\n\nmakes a heading. Then we write as we ordinarily would write:\n\nRead Danielle Navarro’s brief account of Rmarkdown\n\nand we include a link by typing\n\n[here](https://slides.djnavarro.net/starting-rmarkdown/#8)\n\nThink of rmarkdown as writing in word but without having to use your mouse all the time, and you can write up your analysis while writing in a one0stop shop.\nRmarkdown is just an efficient method for composing text without having to reach for your mouse, and a way of documenting and reporting your analysis\nWhy is Rmarkdown useful?\nRmarkdown merges two very powerful ideas: 1. R as a coding based tool to make your analysis repeatable; 2. markdown an approach to writing text that allows for the direct embedding of code output.\nThis is an immensely powerful approach that can be used for everything, from writing research papers, to writing complex technical documentation. This website is written Rmarkdown.\nYou will be creating a website similar to Johannes Karl’swebsite and Joseph Bulbulia’s websiteand you will do this by written using Rmarkdown).\nYou might think that writing in R markdown is only a nice technical trick for people really into coding, but in reality it addresses a central problem of statistical analysis.\nThe majority of errors in quantitative research papers (some meta-researchers indicate values as high as 80%) are human errors in transcribing values from the statistical software they are using to the final document (for a marginally entertaining story around this issue see this post).\nExtra information\ncoding tips Rmarkdown website\nJB’s recommendation for a very short introduction to Rmarkdown: https://rpubs.com/bpbond/626346\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTips and tricks (JB)\nOne day, someone might ask you to collaborate in \\(\\LaTeX\\) (pronounced “Lay-Tek”). \\(\\LaTeX\\) is a document preparation system developed by Leslie Lamport in the 1980s that uses \\(\\TeX\\), a typesetting system that Donald Knuth developed in the 1970s to create mathematical documents. Writing in LaTeX is only a little more complicated than writing in markdown. For example, instead of writing # Heading, ## Subheading, ## Subsubheading, you would write \\section{Heading} \\subsection{Subheading}, \\subsubsection{Subsubheading}. However, the principles of mouseless composition that make Rmarkdown so nice, also make LaTeX nice. Rmarkdown shares features for bibliographic referencing with LaTeX that we’ll cover in later weeks. For now, since we are teaching you about Rmarkdown, we thought it’d be useful to teach about LaTeX too. Stay tuned for more.\nFinal thought: why quantitative psychology has to change (Why can’t I use SPSS, JK)\nQuantitative psychology has long struggled with replicability of it’s results both in substantive and also statistical areas. Concerns around these topics have already been raised on works by authors such as Joseph Banks Rhine the founder of modern parapsychology in the 1930s. Numerous authors, even at the time criticized both methods of the experiment and of the analysis [@gulliksenExtraSensoryPerceptionWhat1938]. In modern times, Deryl Bem’s article “Feeling the Future” that reported evidence in favor of Extra Sensory Perception revived this debate and led to an increased uptake of Open Science methods. Importantly, this is not only an issue in psychology, but instead affects all quantitative fields such as biology, chemistry, and physics. Out of the many issues that are addressed as part of the open science movement (if you are interested in getting active in it have a look at ANZORN) we will focus mostly on aspects of reproducability in analysis.\nUntil recently IBMs SPSS (Statistical Package for the Social Sciences), which originally launched in 1968 dominated the research space in psychology. If you never had the fortune of working with SPSS this is what it looked like:\n\n\n\nSPSS presented the user with a GUI (Graphical User Interface) through which they could run tests on their data. The big issue was that each statistical test has many different options researchers can choose (you will often hear people talk about researcher degrees of freedom) and a GUI makes it very difficult to accurately record every small setting a researcher has chosen. As a work around researchers could either store their output of the analysis which recorded some settings, but even for moderately complex analysis this output could stretch in the hundredth of pages. Alternatively, researchers could save the underlying code that SPSS used, but this was also very clunky and extremely arcane to understand. To give you a sense of scope below you see a snippet from a widely used analysis in SPSS aimed at examining the similarity of factor structures across groups. This code has a total of 130 lines that researchers would have needed to largely enter by hand and double check for any potential coding errors.\n\n\n\nAdditionally, some changes made by researchers were extremely difficult to account for. For example, when a researcher re-coded a variable say reversing its direction there was no way of knowing that this had taken place if you later looked at the data set. Together with the rise in complex analysis in psychology this has led to a steady decline in the use of SPSS and most psychology departments, as well as private, and governmental stake holder now require a certain fluency in R or similar coding based languages.\nFinal thought\nR, Rstudio, GitHub, R-markdown \\(\\dots\\) these are just tools that fit our task\nOur main task in this course is to develop statistical intuition and workflows that will enable you to do better science.\nLecture slides\nClick here to go to the lecture slides.\n\n\n\nfitvids('.shareagain', {players: 'iframe'});\n\n\n\n\n",
    "preview": "posts/1_1/Rlogo.png",
    "last_modified": "2021-04-23T15:50:24+12:00",
    "input_file": {},
    "preview_width": 724,
    "preview_height": 561
  },
  {
    "path": "posts/1_2/",
    "title": "R basics",
    "description": "Some fundamentals",
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      },
      {
        "name": "Johannes Karl",
        "url": "https://johannes-karl.com"
      }
    ],
    "date": "2021-02-23",
    "categories": [],
    "contents": "\n\nContents\nFundamentals of RUsing R as calculator\nThe basic structure of R commands\nRecommended reading\n\n\nFundamentals of R\nA consoleruns all your code in R\nA source page runs all your code in R.\nA working directory is where R will look for raw data and other material.\nIn R-studio, (for starters) you can can use the file tab to import and save your material.\nSimilarly, in R-studio, (for starters) you can can use install packages by clicking the Install tab in the package pane (generally lower right pane) to install packagees.\nUsing R as calculator\nWe can use R as a calculator. You can run any mathematical operation you would normally use by entering it into the console:\n\n\n## Addition\nx = 3 + 2\nx\n\n\n[1] 5\n\n## Subtraction\nx = 3 - 2\nx\n\n\n[1] 1\n\n## Multiplication\nx = 3 * 2\nx\n\n\n[1] 6\n\n## Division\nx = 3 / 2\nx\n\n\n[1] 1.5\n\n## Modulus (Remainder from division)\nx = 3 %% 2\nx\n\n\n[1] 1\n\n## Exponentiation\nx = 3 ^ 2\nx\n\n\n[1] 9\n\n## Integer Division (Number of times denominator fits in numerator)\nx = 3 %/% 2\nx\n\n\n[1] 1\n\nThe basic structure of R commands\nWhile using R as calculator might be interesting, it does not get us very far in analysing our data.\nTo really unlock the full potential of R we first need to understand the basic structure of most R code and learn some terms.\nThe four main elements of every R code are:\nobjects,\nfunctions,\narguments\noperators.\nFigure 1 provides a simple example, that produces a new object which contains the mean of variable x.\n\n\n\nFigure 1: The Basic Syntax of R\n\n\n\nThe function mean generates the arithmetic mean of an input object.\nThe object needs to be specified inside of the function brackets as the x argument, in this case we define x = df .\nLast, we assign the result of this function for later us via the <- operator to an object which we decided to call object.\nIn other words, we create a new object that can be further manipulated and contains information about the mean of a previously created object “x”. This structure represents the foundation of most operations in R.\nInstead calling the mean function as above one could manually add all values of x dividing it by the number of x values.\nNevertheless, this would be very cumbersome.\nFor this reason, functions (pre-assembled lines of code) exist to reduce the amount of coding necessary.\nThese functions can be bundled into packages. R’s capacity for creating packages is main appeal of R as a statistical tool because community developed functions are available from a central repository called CRAN in the form of packages.\nThese packages can be installed in R with the command install.packages(“package name”).\nIt is important that you only need to install a package once on your machine, expect if you want to upgrade the package. Generally speaking you regularly want to upgrade your packages, but keep a permanent note in your code which version of a package you used when it was initially written.\nRecommended reading\nAn introduction to R and Rstudio\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-19T18:35:55+13:00",
    "input_file": {}
  },
  {
    "path": "posts/1_3/",
    "title": "Set up",
    "description": "The purpose of this week is to get you set up to write in R markdown",
    "author": [
      {
        "name": "Joseph Bulbulia",
        "url": "https://josephbulbulia.netlify.app"
      },
      {
        "name": "Johannes Karl",
        "url": "https://johannes-karl.com"
      }
    ],
    "date": "2021-02-23",
    "categories": [],
    "contents": "\n\nContents\nTO DO\nMarkdown is a format for writing\nRmarkdown and You\nHow to keep track of everything\nSome useful sites\n\nTO DO\nRead Daniell Navarro’s brief account of Rmarkdown here\nMarkdown is a format for writing\nRmarkdown is a format for combing code with ordinary writing.\nThe Rmarkdown code we used to write the opening paragraph looks like this.\n\ndiv.blue{ background-color:#e6f0ff}\n\n## TO DO\nRead Danielle Navarro's brief account of \nRmarkdown [here](https://slides.djnavarro.net/starting-rmarkdown/#8)\n\nThe:\n\n##\n\nmakes a heading. We write as ordinary,\n\nRead Danielle Navarro’s brief account of Rmarkdown\n\nand we include a link by typing\n\n[here](https://slides.djnavarro.net/starting-rmarkdown/#8)\n\nThink of rmarkdown as writing in word but without having to use your mouse all the time. The really great thing about Rmarkdown is that you can write document and do the analysis in a single stop shop. Figure 1 shows Rmarkdown in the rconsole (upper left).\n\n\n\nFigure 1: Screenshot of Rmarkdown document (upper left)\n\n\n\nRmarkdown and You\nRmarkdown merges two very powerful ideas: 1. R as a coding based tool to make your analysis repeatable; 2. markdown an approach to writing text that allows for the direct embedding of code output.\nThis is an immensely powerful approach that can be used for everything, from writing research papers, to writing complex technical documentation. This website is written Rmarkdown.\nYou will be creating a website similar to Johannes Karl’swebsite and Joseph Bulbulia’s websiteand you will do this by written using Rmarkdown).\nYou might think that writing in R markdown is only a nice technical trick for people really into coding, but in reality it addresses a central problem of statistical analysis.\nThe majority of errors in quantitative research papers (some meta-researchers indiate values as high as 80%) are human errors in transcribing values from the statistical software they are using to the final document (for a marginally entertaining story around this issue see this post).\nHow to keep track of everything\nNow that we have our repeatable code, our repeatable document, the last thing we need is a transparent way to document what we are doing and share with others. For that we come to our last tool that in a similar confusing way to R and Rstudio is split in to parts; git and Github.\nSome useful sites\ncoding tips Rmarkdown website\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-19T18:36:56+13:00",
    "input_file": {}
  }
]
